name: Agents Gate Followups

on:
  workflow_run:
    workflows: ["Gate"]
    types: [completed]
  pull_request:
    types:
      - labeled
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to force retry'
        required: true
        type: number
      force_retry:
        description: 'Force retry even if gate is cancelled/deferred'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  pull-requests: write
  actions: write
  models: read

concurrency:
  group: >-
    agents-gate-followups-${{ github.event.workflow_run.pull_requests[0].number ||
      github.event.pull_request.number ||
      github.event.inputs.pr_number ||
      github.run_id }}
  cancel-in-progress: false


env:
  WRITE_TOKEN: >-
    ${{ secrets.AGENTS_AUTOMATION_PAT ||
        secrets.ACTIONS_BOT_PAT ||
        secrets.SERVICE_BOT_PAT ||
        github.token }}

jobs:
  evaluate:
    name: Evaluate keepalive loop
    if: vars.USE_CONSOLIDATED_WORKFLOWS == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    environment: agent-standard
    outputs:
      pr_number: ${{ steps.evaluate.outputs.pr_number }}
      pr_ref: ${{ steps.evaluate.outputs.pr_ref }}
      head_sha: ${{ steps.evaluate.outputs.head_sha }}
      action: ${{ steps.evaluate.outputs.action }}
      reason: ${{ steps.evaluate.outputs.reason }}
      gate_conclusion: ${{ steps.evaluate.outputs.gate_conclusion }}
      iteration: ${{ steps.evaluate.outputs.iteration }}
      max_iterations: ${{ steps.evaluate.outputs.max_iterations }}
      failure_threshold: ${{ steps.evaluate.outputs.failure_threshold }}
      tasks_total: ${{ steps.evaluate.outputs.tasks_total }}
      tasks_unchecked: ${{ steps.evaluate.outputs.tasks_unchecked }}
      keepalive_enabled: ${{ steps.evaluate.outputs.keepalive_enabled }}
      autofix_enabled: ${{ steps.evaluate.outputs.autofix_enabled }}
      has_agent_label: ${{ steps.evaluate.outputs.has_agent_label }}
      agent_type: ${{ steps.evaluate.outputs.agent_type }}
      task_appendix: ${{ steps.evaluate.outputs.task_appendix }}
      trace: ${{ steps.evaluate.outputs.trace }}
      prompt_mode: ${{ steps.evaluate.outputs.prompt_mode }}
      prompt_file: ${{ steps.evaluate.outputs.prompt_file }}
      start_ts: ${{ steps.timestamps.outputs.start_ts }}
      security_blocked: ${{ steps.security_gate.outputs.blocked }}
      security_reason: ${{ steps.security_gate.outputs.reason }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}

      - name: Capture timestamps
        id: timestamps
        run: echo "start_ts=$(date -u +%s)" >> "$GITHUB_OUTPUT"
      - name: Security gate - prompt injection guard
        id: security_gate
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({ github, core });

            const { evaluatePromptInjectionGuard } = require(
              './.github/scripts/prompt_injection_guard.js'
            );

            // Resolve PR from event context
            const payload = context.payload || {};
            let prNumber = 0;
            let pr = null;

            if (context.eventName === 'pull_request' && payload.pull_request) {
              prNumber = payload.pull_request.number;
              pr = payload.pull_request;
            } else if (context.eventName === 'workflow_run' && payload.workflow_run) {
              const prs = payload.workflow_run.pull_requests || [];
              if (prs[0]?.number) {
                prNumber = prs[0].number;
                const { data } = await withRetry((client) => client.rest.pulls.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  pull_number: prNumber,
                }));
                pr = data;
              }
            }

            if (!pr) {
              core.setOutput('blocked', 'false');
              core.setOutput('reason', 'no-pr-context');
              return;
            }

            const result = await evaluatePromptInjectionGuard({
              github,
              context,
              pr,
              actor: context.actor,
              promptContent: pr.body || '',
              core,
            });

            core.setOutput('blocked', String(result.blocked));
            core.setOutput('reason', result.reason);

            if (result.blocked) {
              core.setFailed(`Security gate blocked: ${result.reason}`);
            }

      - name: Evaluate keepalive state
        id: evaluate
        uses: actions/github-script@v8
        env:
          INPUT_PR_NUMBER: ${{ github.event.inputs.pr_number || '' }}
          INPUT_FORCE_RETRY: ${{ github.event.inputs.force_retry || 'false' }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { evaluateKeepaliveLoop } = require('./.github/scripts/keepalive_loop.js');
            const options = { github, context, core };
            // Pass workflow_dispatch inputs if present
            const inputPrNumber = process.env.INPUT_PR_NUMBER;
            const forceRetry = process.env.INPUT_FORCE_RETRY === 'true';
            if (inputPrNumber) {
              options.overridePrNumber = parseInt(inputPrNumber, 10);
            }
            if (forceRetry) {
              options.forceRetry = true;
            }
            const result = await evaluateKeepaliveLoop(options);
            const output = {
              pr_number: String(result.prNumber || ''),
              pr_ref: String(result.prRef || ''),
              head_sha: String(result.headSha || ''),
              action: result.action || '',
              reason: result.reason || '',
              gate_conclusion: result.gateConclusion || '',
              iteration: String(result.iteration ?? ''),
              max_iterations: String(result.maxIterations ?? ''),
              failure_threshold: String(result.failureThreshold ?? ''),
              tasks_total: String(result.checkboxCounts?.total ?? ''),
              tasks_unchecked: String(result.checkboxCounts?.unchecked ?? ''),
              keepalive_enabled: String(result.keepaliveEnabled ?? ''),
              autofix_enabled: String(result.config?.autofix_enabled ?? ''),
              has_agent_label: String(result.hasAgentLabel ?? ''),
              agent_type: String(result.agentType || ''),
              trace: String(result.config?.trace || result.state?.trace || ''),
              prompt_mode: String(result.promptMode || 'normal'),
                prompt_file: String(
                  result.promptFile || '.github/codex/prompts/keepalive_next_task.md'
                ),
            };
            for (const [key, value] of Object.entries(output)) {
              core.setOutput(key, value);
            }
            // Task appendix needs special handling due to multiline content
            core.setOutput('task_appendix', result.taskAppendix || '');

  preflight:
    name: Verify secrets available
    needs: evaluate
    if: |
      needs.evaluate.outputs.action == 'run' ||
      needs.evaluate.outputs.action == 'fix' ||
      needs.evaluate.outputs.action == 'conflict'
    runs-on: ubuntu-latest
    environment: agent-standard
    outputs:
      secrets_ok: ${{ steps.check.outputs.secrets_ok }}
    steps:
      - name: Check secrets
        id: check
        env:
          HAS_CODEX_AUTH: ${{ secrets.CODEX_AUTH_JSON != '' }}
          HAS_CLAUDE_AUTH: ${{ secrets.CLAUDE_AUTH_JSON != '' }}
          HAS_APP_ID: >-
            ${{ secrets.KEEPALIVE_APP_ID != '' ||
                secrets.WORKFLOWS_APP_ID != '' }}
          HAS_APP_KEY: >-
            ${{ secrets.KEEPALIVE_APP_PRIVATE_KEY != '' ||
                secrets.WORKFLOWS_APP_PRIVATE_KEY != '' }}
        run: |
          echo "CODEX_AUTH_JSON present: $HAS_CODEX_AUTH"
          echo "CLAUDE_AUTH_JSON present: $HAS_CLAUDE_AUTH"
          echo "KEEPALIVE_APP or WORKFLOWS_APP present: $HAS_APP_ID"
          echo "WORKFLOWS_APP_PRIVATE_KEY present: $HAS_APP_KEY"
          if [ "$HAS_CODEX_AUTH" = "true" ] || [ "$HAS_CLAUDE_AUTH" = "true" ] || [ "$HAS_APP_ID" = "true" ]; then
            echo "secrets_ok=true" >> "$GITHUB_OUTPUT"
          else
            echo "::error::No agent auth found. Set CODEX_AUTH_JSON, CLAUDE_AUTH_JSON, or KEEPALIVE/WORKFLOWS_APP."
            echo "secrets_ok=false" >> "$GITHUB_OUTPUT"
            exit 1
          fi

  test-job:
    name: Test job creation
    needs: evaluate
    runs-on: ubuntu-latest
    steps:
      - run: |
          echo "Test job ran!"
            echo "Action was ${{ needs.evaluate.outputs.action }}"
            echo "Agent was ${{ needs.evaluate.outputs.agent_type }}"

  # Mark agent as running before starting the actual work
  # This provides real-time visibility that the agent is actively engaged
  mark-running:
    name: Mark agent running
    needs:
      - evaluate
      - preflight
    if: |
      needs.evaluate.outputs.action == 'run' ||
      needs.evaluate.outputs.action == 'fix' ||
      needs.evaluate.outputs.action == 'conflict'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}

      - name: Update summary with running status
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { markAgentRunning } = require('./.github/scripts/keepalive_loop.js');
              const runUrl =
                `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}` +
                `/actions/runs/${context.runId}`;
            const inputs = {
              pr_number: '${{ needs.evaluate.outputs.pr_number }}',
              agent_type: '${{ needs.evaluate.outputs.agent_type }}',
              iteration: '${{ needs.evaluate.outputs.iteration }}',
              max_iterations: '${{ needs.evaluate.outputs.max_iterations }}',
              tasks_total: '${{ needs.evaluate.outputs.tasks_total }}',
              tasks_unchecked: '${{ needs.evaluate.outputs.tasks_unchecked }}',
              trace: '${{ needs.evaluate.outputs.trace }}',
              run_url: runUrl,
            };
            await markAgentRunning({ github, context, core, inputs });

  # Route to appropriate agent based on agent:* label
  # Supports: agent:codex -> CLI Codex, agent:claude -> Claude API
  run-codex:
    name: Keepalive next task (Codex)
    needs:
      - evaluate
      - preflight
      - mark-running
    # Only run for agent:codex label
    if: needs.evaluate.outputs.agent_type == 'codex'
    uses: stranske/Workflows/.github/workflows/reusable-codex-run.yml@main
    secrets:
      CODEX_AUTH_JSON: ${{ secrets.CODEX_AUTH_JSON }}
      # Use dedicated KEEPALIVE_APP for isolated rate limit pool (5000/hr)
      # Falls back to WORKFLOWS_APP if KEEPALIVE_APP not configured
      WORKFLOWS_APP_ID: >-
        ${{ secrets.KEEPALIVE_APP_ID || secrets.WORKFLOWS_APP_ID }}
      WORKFLOWS_APP_PRIVATE_KEY: >-
        ${{ secrets.KEEPALIVE_APP_PRIVATE_KEY ||
            secrets.WORKFLOWS_APP_PRIVATE_KEY }}
    with:
      skip: >-
        ${{ needs.evaluate.outputs.action != 'run' &&
            needs.evaluate.outputs.action != 'fix' &&
            needs.evaluate.outputs.action != 'conflict' }}
      prompt_file: ${{ needs.evaluate.outputs.prompt_file }}
      mode: keepalive
      pr_number: ${{ needs.evaluate.outputs.pr_number }}
      pr_ref: ${{ needs.evaluate.outputs.pr_ref }}
      appendix: ${{ needs.evaluate.outputs.task_appendix }}
      iteration: ${{ needs.evaluate.outputs.iteration }}

  run-claude:
    name: Keepalive next task (Claude)
    needs:
      - evaluate
      - preflight
      - mark-running
    if: |
      needs.evaluate.outputs.agent_type == 'claude' &&
      (needs.evaluate.outputs.action == 'run' ||
       needs.evaluate.outputs.action == 'fix' ||
       needs.evaluate.outputs.action == 'conflict')
    uses: stranske/Workflows/.github/workflows/reusable-claude-run.yml@main
    secrets: inherit
    with:
      skip: >-
        ${{ needs.evaluate.outputs.action != 'run' &&
            needs.evaluate.outputs.action != 'fix' &&
            needs.evaluate.outputs.action != 'conflict' }}
      prompt_file: ${{ needs.evaluate.outputs.prompt_file }}
      mode: keepalive
      pr_number: ${{ needs.evaluate.outputs.pr_number }}
      pr_ref: ${{ needs.evaluate.outputs.pr_ref }}
      appendix: ${{ needs.evaluate.outputs.task_appendix }}
      iteration: ${{ needs.evaluate.outputs.iteration }}

  summary:
    name: Update keepalive summary
    needs:
      - evaluate
      - preflight
      - run-codex
      - run-claude
    # Run always if PR exists, handle skipped agent jobs gracefully
    if: |
      always() &&
      needs.evaluate.outputs.pr_number != '' &&
      needs.evaluate.outputs.pr_number != '0'
    runs-on: ubuntu-latest
    environment: agent-standard
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}

      - name: Emit keepalive metrics
        id: keepalive-metrics
        env:
          PR_NUMBER: ${{ needs.evaluate.outputs.pr_number }}
          ACTION: ${{ needs.evaluate.outputs.action }}
          REASON: ${{ needs.evaluate.outputs.reason }}
          GATE_CONCLUSION: ${{ needs.evaluate.outputs.gate_conclusion }}
          ITERATION: ${{ needs.evaluate.outputs.iteration }}
          MAX_ITERATIONS: ${{ needs.evaluate.outputs.max_iterations }}
          TASKS_TOTAL: ${{ needs.evaluate.outputs.tasks_total }}
          TASKS_UNCHECKED: ${{ needs.evaluate.outputs.tasks_unchecked }}
          START_TS: ${{ needs.evaluate.outputs.start_ts }}
        run: |
          set -euo pipefail

          now=$(date -u +%s)
          if [[ "${START_TS:-}" =~ ^[0-9]+$ ]]; then
            duration=$(( now - START_TS ))
            if [ "$duration" -lt 0 ]; then duration=0; fi
          else
            duration=0
          fi

          tasks_total=${TASKS_TOTAL:-0}
          tasks_unchecked=${TASKS_UNCHECKED:-0}
          if ! [[ "$tasks_total" =~ ^-?[0-9]+$ ]]; then tasks_total=0; fi
          if ! [[ "$tasks_unchecked" =~ ^-?[0-9]+$ ]]; then tasks_unchecked=0; fi
          tasks_completed=$(( tasks_total - tasks_unchecked ))
          if [ "$tasks_completed" -lt 0 ]; then tasks_completed=0; fi

          metrics_json=$(jq -n \
            --arg pr "${PR_NUMBER:-0}" \
            --arg iteration "${ITERATION:-0}" \
            --arg action "${ACTION:-}" \
            --arg stop_reason "${REASON:-}" \
            --arg gate_conclusion "${GATE_CONCLUSION:-}" \
            --arg tasks_total "$tasks_total" \
            --arg tasks_completed "$tasks_completed" \
            --arg duration "$duration" \
            '{
              pr_number: ($pr | tonumber? // 0),
              iteration_count: ($iteration | tonumber? // 0),
              action: $action,
              stop_reason: $stop_reason,
              gate_conclusion: $gate_conclusion,
              tasks_total: ($tasks_total | tonumber? // 0),
              tasks_completed: ($tasks_completed | tonumber? // 0),
              duration_seconds: ($duration | tonumber? // 0)
            }')

          {
            echo '### Keepalive metrics'
            echo ''
            echo '| Field | Value |'
            echo '| --- | --- |'
            echo "| pr_number | $(echo "$metrics_json" | jq -r '.pr_number') |"
            echo "| iteration_count | $(echo "$metrics_json" | jq -r '.iteration_count') |"
            echo "| action | $(echo "$metrics_json" | jq -r '.action') |"
            echo "| stop_reason | $(echo "$metrics_json" | jq -r '.stop_reason') |"
            echo "| gate_conclusion | $(echo "$metrics_json" | jq -r '.gate_conclusion') |"
            echo "| tasks_total | $(echo "$metrics_json" | jq -r '.tasks_total') |"
            echo "| tasks_completed | $(echo "$metrics_json" | jq -r '.tasks_completed') |"
            echo "| duration_seconds | $(echo "$metrics_json" | jq -r '.duration_seconds') |"
          } >> "$GITHUB_STEP_SUMMARY"

          echo "$metrics_json" >> keepalive-metrics.ndjson

      - name: Upload keepalive metrics artifact
        uses: actions/upload-artifact@v6
        with:
          name: keepalive-metrics
          path: keepalive-metrics.ndjson
          retention-days: 30
          if-no-files-found: error

      - name: Auto-reconcile task checkboxes
        if: |
          needs.run-codex.outputs.changes-made == 'true' ||
          needs.run-claude.outputs.changes-made == 'true'
        uses: actions/github-script@v8
        env:
          LLM_COMPLETED_TASKS: >-
            ${{
              needs.run-codex.outputs.llm-completed-tasks ||
              needs.run-claude.outputs.llm-completed-tasks ||
              '[]'
            }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { autoReconcileTasks } = require('./.github/scripts/keepalive_loop.js');

            const prNumber = Number('${{ needs.evaluate.outputs.pr_number }}') || 0;
            const beforeSha = '${{ needs.evaluate.outputs.head_sha }}';  // SHA before agent ran
            const headSha =
              '${{ needs.run-codex.outputs.commit-sha }}' ||
              '${{ needs.run-claude.outputs.commit-sha }}';

            // LLM analysis metadata
            const llmProvider =
              '${{ needs.run-codex.outputs.llm-provider }}' ||
              '${{ needs.run-claude.outputs.llm-provider }}' ||
              '';
            const llmConfidence =
              '${{ needs.run-codex.outputs.llm-confidence }}' ||
              '${{ needs.run-claude.outputs.llm-confidence }}' ||
              '';
            const llmAnalysisRun =
              '${{ needs.run-codex.outputs.llm-analysis-run }}' === 'true' ||
              '${{ needs.run-claude.outputs.llm-analysis-run }}' === 'true';

              // Parse LLM completed tasks if available
              // Use env var to avoid JS string escaping issues
            let llmCompletedTasks = [];
            const llmTasksJson = process.env.LLM_COMPLETED_TASKS || '[]';
            try {
              llmCompletedTasks = JSON.parse(llmTasksJson);
              if (llmCompletedTasks.length > 0) {
                core.info(`LLM analysis found ${llmCompletedTasks.length} completed task(s)`);
                if (llmProvider) {
                  core.info(`LLM provider: ${llmProvider} (confidence: ${llmConfidence})`);
                }
              }
            } catch (e) {
              core.debug(`Failed to parse LLM tasks: ${e.message}`);
            }

            if (!prNumber || !beforeSha || !headSha) {
              core.info('Missing required inputs for task reconciliation');
              return;
            }

            core.info(`Auto-reconciling tasks for PR #${prNumber}`);
            core.info(`Comparing ${beforeSha.slice(0, 7)} â†’ ${headSha.slice(0, 7)}`);

            const result = await autoReconcileTasks({
              github, context, prNumber, baseSha: beforeSha, headSha, llmCompletedTasks, core
            });

            if (result.updated) {
              core.info(`âœ… ${result.details}`);
              core.notice(`Auto-checked ${result.tasksChecked} task(s) based on analysis`);
            } else {
              core.info(`â„¹ï¸ ${result.details}`);
            }

            // Output for step summary and downstream reporting
            core.setOutput('tasks_checked', result.tasksChecked);
            core.setOutput('reconciliation_details', result.details);
            core.setOutput('llm_provider', llmProvider);
            core.setOutput('llm_confidence', llmConfidence);
            core.setOutput('llm_analysis_run', llmAnalysisRun);
            core.setOutput('llm_tasks_count', llmCompletedTasks.length);
            core.setOutput('commit_tasks_count', result.sources?.commit || 0);

      - name: Update summary comment
        uses: actions/github-script@v8
        env:
          AGENT_SUMMARY: >-
            ${{
              needs.run-codex.outputs.final-message-summary ||
              needs.run-claude.outputs.final-message-summary ||
              needs.run-codex.outputs.error-summary ||
              needs.run-claude.outputs.error-summary ||
              ''
            }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { updateKeepaliveLoopSummary } =
              require('./.github/scripts/keepalive_loop.js');

            const claudeResult = '${{ needs.run-claude.result }}';
            const codexResult = '${{ needs.run-codex.result }}';
            const runResult =
              claudeResult && claudeResult !== 'skipped' ? claudeResult : codexResult;

            const agentExitCode =
              '${{ needs.run-codex.outputs.exit-code }}' ||
              '${{ needs.run-claude.outputs.exit-code }}';
            const agentChangesMade =
              '${{ needs.run-codex.outputs.changes-made }}' ||
              '${{ needs.run-claude.outputs.changes-made }}';
            const agentCommitSha =
              '${{ needs.run-codex.outputs.commit-sha }}' ||
              '${{ needs.run-claude.outputs.commit-sha }}';
            const agentFilesChanged =
              '${{ needs.run-codex.outputs.files-changed }}' ||
              '${{ needs.run-claude.outputs.files-changed }}';

            const llmProvider =
              '${{ needs.run-codex.outputs.llm-provider }}' ||
              '${{ needs.run-claude.outputs.llm-provider }}' ||
              '';
            const llmConfidence =
              '${{ needs.run-codex.outputs.llm-confidence }}' ||
              '${{ needs.run-claude.outputs.llm-confidence }}' ||
              '';
            const llmAnalysisRun =
              '${{ needs.run-codex.outputs.llm-analysis-run }}' === 'true' ||
              '${{ needs.run-claude.outputs.llm-analysis-run }}' === 'true';

            const inputs = {
              pr_number: Number('${{ needs.evaluate.outputs.pr_number }}') || 0,
              action: '${{ needs.evaluate.outputs.action }}',
              reason: '${{ needs.evaluate.outputs.reason }}',
              gate_conclusion: '${{ needs.evaluate.outputs.gate_conclusion }}',
              iteration: Number('${{ needs.evaluate.outputs.iteration }}') || 0,
              max_iterations: Number('${{ needs.evaluate.outputs.max_iterations }}') || 0,
              failure_threshold: Number('${{ needs.evaluate.outputs.failure_threshold }}') || 3,
              tasks_total: Number('${{ needs.evaluate.outputs.tasks_total }}') || 0,
              tasks_unchecked: Number('${{ needs.evaluate.outputs.tasks_unchecked }}') || 0,
              keepalive_enabled: '${{ needs.evaluate.outputs.keepalive_enabled }}',
              autofix_enabled: '${{ needs.evaluate.outputs.autofix_enabled }}',
              agent_type: '${{ needs.evaluate.outputs.agent_type }}',
              trace: '${{ needs.evaluate.outputs.trace }}',
              // Agent run result - check which agent ran
              run_result: runResult,
              // Agent output details (merged from whichever agent ran)
              agent_exit_code: agentExitCode,
              agent_changes_made: agentChangesMade,
              agent_commit_sha: agentCommitSha,
              agent_files_changed: agentFilesChanged,
              agent_summary: process.env.AGENT_SUMMARY || '',
              // LLM analysis details for task completion reporting
              llm_provider: llmProvider,
              llm_confidence: llmConfidence,
              llm_analysis_run: llmAnalysisRun,
            };
            await updateKeepaliveLoopSummary({ github, context, core, inputs });

  prepare:
    name: Prepare autofix context
    if: vars.USE_CONSOLIDATED_WORKFLOWS == 'true'
    runs-on: ubuntu-latest
    environment: agent-standard
    outputs:
      should_run: ${{ steps.evaluate.outputs.should_run }}
      pr_number: ${{ steps.evaluate.outputs.pr_number }}
      head_ref: ${{ steps.evaluate.outputs.head_ref }}
      head_sha: ${{ steps.evaluate.outputs.head_sha }}
      appendix: ${{ steps.evaluate.outputs.appendix }}
      stop_reason: ${{ steps.evaluate.outputs.stop_reason }}
      attempts: ${{ steps.evaluate.outputs.attempts }}
      max_attempts: ${{ steps.evaluate.outputs.max_attempts }}
      trigger_reason: ${{ steps.evaluate.outputs.trigger_reason }}
      trigger_job: ${{ steps.evaluate.outputs.trigger_job }}
      trigger_step: ${{ steps.evaluate.outputs.trigger_step }}
      agent_type: ${{ steps.evaluate.outputs.agent_type }}
      gate_conclusion: ${{ steps.evaluate.outputs.gate_conclusion }}
      gate_run_id: ${{ steps.evaluate.outputs.gate_run_id }}
      security_blocked: ${{ steps.security_gate.outputs.blocked }}
      security_reason: ${{ steps.security_gate.outputs.reason }}
    steps:
      - name: Checkout (for security gate + agent registry)
        uses: actions/checkout@v6
        with:
          sparse-checkout: |
            .github/scripts/prompt_injection_guard.js
            .github/scripts/github-api-with-retry.js
            .github/scripts/token_load_balancer.js
            .github/scripts/agent_registry.js
            .github/agents/registry.yml
          sparse-checkout-cone-mode: false

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}

      - name: Security gate - prompt injection guard
        id: security_gate
        uses: actions/github-script@v8
        with:
          github-token: ${{ env.WRITE_TOKEN }}
          script: |
            const fs = require('fs');
            const retryPath = './.github/scripts/github-api-with-retry.js';
            const { createTokenAwareRetry } = fs.existsSync(retryPath)
              ? require(retryPath)
              : { createTokenAwareRetry: async () => ({ withRetry: (fn) => fn(github) }) };
            const { withRetry } = await createTokenAwareRetry({ github, core });

            const guardPath = './.github/scripts/prompt_injection_guard.js';

            // Check if guard exists (may not exist on older branches)
            if (!fs.existsSync(guardPath)) {
              core.info('Prompt injection guard not found, skipping security check.');
              core.setOutput('blocked', 'false');
              core.setOutput('reason', 'guard-not-found');
              return;
            }

            const { evaluatePromptInjectionGuard } = require(guardPath);

            const run = context.payload.workflow_run;
            if (!run) {
              core.setOutput('blocked', 'false');
              core.setOutput('reason', 'no-workflow-run');
              return;
            }

            const prInfo = Array.isArray(run.pull_requests) ? run.pull_requests[0] : undefined;
            if (!prInfo?.number) {
              core.setOutput('blocked', 'false');
              core.setOutput('reason', 'no-pr-context');
              return;
            }

            const { data: pr } = await withRetry((client) => client.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prInfo.number,
            }));

            const result = await evaluatePromptInjectionGuard({
              github,
              context,
              pr,
              actor: run.actor?.login || context.actor,
              promptContent: pr.body || '',
              core,
            });

            core.setOutput('blocked', String(result.blocked));
            core.setOutput('reason', result.reason);

            if (result.blocked) {
              core.setFailed(`Security gate blocked: ${result.reason}`);
            }

      - name: Evaluate workflow_run
        id: evaluate
        uses: actions/github-script@v8
        with:
          github-token: ${{ env.WRITE_TOKEN }}
          script: |
            const fs = require('fs');
            const retryPath = './.github/scripts/github-api-with-retry.js';
            const { createTokenAwareRetry } = fs.existsSync(retryPath)
              ? require(retryPath)
              : { createTokenAwareRetry: async () => ({ withRetry: (fn) => fn(github) }) };
            const { withRetry, paginateWithRetry } = await createTokenAwareRetry({ github, core });

            const run = context.payload.workflow_run;
            const outputs = {
              should_run: 'false',
              pr_number: '',
              head_ref: '',
              head_sha: '',
              appendix: '',
              agent_type: '',
              stop_reason: '',
              attempts: '0',
              max_attempts: '3',
              trigger_reason: 'unknown',
              trigger_job: '',
              trigger_step: '',
              gate_conclusion: String(run?.conclusion || run?.status || ''),
              gate_run_id: String(run?.id || ''),
            };

            const stop = (reason, stopReason = '') => {
              core.info(`Autofix loop skipped: ${reason}.`);
              outputs.stop_reason = stopReason || reason;
              for (const [key, value] of Object.entries(outputs)) {
                core.setOutput(key, value);
              }
            };

            if (!run) {
              return stop('missing workflow_run payload');
            }

            if ((run.conclusion || '').toLowerCase() === 'success') {
              return stop('upstream Gate succeeded');
            }

            if ((run.event || '').toLowerCase() !== 'pull_request') {
              return stop(`unsupported event type: ${run.event || 'unknown'}`);
            }

            const prInfo = Array.isArray(run.pull_requests) ? run.pull_requests[0] : undefined;
            if (!prInfo?.number) {
              return stop('no pull request context on workflow_run');
            }

            outputs.pr_number = String(prInfo.number);

            const { owner, repo } = context.repo;
            const prNumber = Number(prInfo.number);
            const pr = await withRetry((client) =>
              client.rest.pulls.get({ owner, repo, pull_number: prNumber })
            );
            const prData = pr.data;

            if (!prData || prData.state !== 'open') {
              return stop('pull request is not open');
            }

            if (prData.draft) {
              return stop('draft pull request');
            }

            const headSha = prData.head?.sha;
            if (!headSha || headSha !== run.head_sha) {
              return stop('head SHA drifted since Gate started');
            }

            const sameRepo = prData.head?.repo?.full_name === `${owner}/${repo}`;
            if (!sameRepo) {
              return stop('head repository mismatch (likely fork)');
            }

            const labels = Array.isArray(prData.labels)
              ? prData.labels
                  .map((label) => (label?.name || '').toLowerCase())
                  .filter(Boolean)
              : [];
            const hasAgentLabel = labels.some(l => l.startsWith('agent:'));
            const nonRoutingAgentLabels = new Set(['agent:rate-limited', 'agent:needs-attention']);
            const routingLabelObjects = Array.isArray(prData.labels)
              ? prData.labels.filter((label) => {
                  const normalized = (label?.name || '').toLowerCase();
                  if (!normalized.startsWith('agent:')) {
                    return true;
                  }
                  return !nonRoutingAgentLabels.has(normalized);
                })
              : [];

            // Resolve agent type from PR labels (for routing autofix to correct runner)
            try {
              const { resolveAgentFromLabels } = require('./.github/scripts/agent_registry.js');
              outputs.agent_type = resolveAgentFromLabels(routingLabelObjects, {
                registryPath: './.github/agents/registry.yml',
              });
            } catch (err) {
              core.warning(`Failed to resolve agent type: ${err.message}; defaulting to codex`);
              outputs.agent_type = 'codex';
            }

            const body = prData.body || '';
            const configMatch = body.match(/autofix\s*:\s*(true|false)/i);
            let autofixEnabled = configMatch
              ? configMatch[1].toLowerCase() === 'true'
              : hasAgentLabel;

            // Auto-escalation: Escalate to agent CLI when Gate fails
            // Triggers if: (1) basic autofix ran but insufficient, OR (2) no basic autofix applied
            // Note: We do NOT add agent:* label here because that triggers external agent UI
            // which would conflict with our internal agent CLI run. Only add autofix:escalated.
            if (!autofixEnabled && !configMatch) {
                const hasAutofixLabel =
                  labels.includes('autofix:applied') || labels.includes('autofix');
              const hasEscalatedLabel = labels.includes('autofix:escalated');
              const gateConclusion = (run.conclusion || '').toLowerCase();
              const gateFailed = gateConclusion === 'failure';

              // Escalate if Gate failed and we haven't already escalated
              if (gateFailed && !hasEscalatedLabel) {
                const reason = hasAutofixLabel
                  ? 'Basic autofix ran but Gate still failing'
                  : 'No basic autofix (non-Python PR?) and Gate failing';
                core.info(`ðŸ”„ Auto-escalation: ${reason}. Escalating to agent CLI...`);
                try {
                  await withRetry((client) => client.rest.issues.addLabels({
                    owner,
                    repo,
                    issue_number: prNumber,
                    labels: ['autofix:escalated'],
                  }));
                    core.info(
                      'âœ… Added autofix:escalated label - agent CLI will run in this workflow'
                    );
                  autofixEnabled = true;
                } catch (error) {
                  core.warning(`Failed to add escalation labels: ${error.message}`);
                }
              }
            }
            if (!autofixEnabled) {
              return stop('autofix disabled for this pull request');
            }

            const jobs = await paginateWithRetry(github.rest.actions.listJobsForWorkflowRun, {
              owner,
              repo,
              run_id: run.id,
              per_page: 100,
            });

            const workflowFile = 'agents-autofix-loop.yml';
            // Reduce attempts for auto-escalated PRs (they weren't agent-initiated)
            const isEscalated = labels.includes('autofix:escalated');
              const maxAttempts = isEscalated
                ? Math.min(2, Number(outputs.max_attempts))
                : Number(outputs.max_attempts);
            const previousRuns = await paginateWithRetry(github.rest.actions.listWorkflowRuns, {
              owner,
              repo,
              workflow_id: workflowFile,
              head_sha: run.head_sha,
              per_page: 100,
              status: 'completed',
            });

            const attemptCount = previousRuns.length + 1;
            outputs.attempts = String(attemptCount);
            outputs.max_attempts = String(maxAttempts);

            const failingJobs = [];
            let triggerJob = null;
            let triggerStep = null;
            for (const job of jobs) {
              const conclusion = (job.conclusion || job.status || '').toLowerCase();
              if (!conclusion || ['success', 'skipped'].includes(conclusion)) {
                continue;
              }

              const failingSteps =
                Array.isArray(job.steps)
                  ? job.steps
                      .filter((step) => {
                        const stepConclusion = (step.conclusion || step.status || '').toLowerCase();
                        return stepConclusion && !['success', 'skipped'].includes(stepConclusion);
                      })
                        .map((step) =>
                          `${step.name} (${step.conclusion || step.status || 'unknown'})`
                        )
                  : [];

              const detailLines = [`- ${job.name} (${job.conclusion || job.status || 'unknown'})`];
              if (failingSteps.length > 0) {
                detailLines.push(`  - steps: ${failingSteps.join('; ')}`);
              }
              failingJobs.push(detailLines.join('\n'));

              if (!triggerJob) {
                triggerJob = job;
                const failingStep = Array.isArray(job.steps)
                  ? job.steps.find((step) => {
                      const stepConclusion = (step.conclusion || step.status || '').toLowerCase();
                      return stepConclusion && !['success', 'skipped'].includes(stepConclusion);
                    })
                  : null;
                triggerStep = failingStep || null;
              }
            }

            const inferTriggerReason = (job, step) => {
              const text = [job?.name, step?.name]
                .filter(Boolean)
                .map((value) => String(value).toLowerCase())
                .join(' ');

              if (!text) return 'unknown';
              if (text.includes('mypy')) return 'mypy';
                if (
                  text.includes('lint') ||
                  text.includes('flake8') ||
                  text.includes('ruff')
                ) {
                  return 'lint';
                }
              if (text.includes('pytest') || text.includes('test')) return 'pytest';
              return 'unknown';
            };

            outputs.trigger_reason = inferTriggerReason(triggerJob, triggerStep);
            outputs.trigger_job = triggerJob?.name || triggerJob?.id || '';
            outputs.trigger_step = triggerStep?.name || '';

            const appendixLines = [
              `Gate run: ${run.html_url || run.id}`,
              `Conclusion: ${run.conclusion || run.status || 'unknown'}`,
              `PR: #${prNumber}`,
              `Head SHA: ${headSha}`,
              `Autofix attempts for this head: ${attemptCount} / ${maxAttempts}`,
              'Fix scope: src/, tests/, tools/, scripts/, agents/, templates/, .github/',
            ];

            if (failingJobs.length > 0) {
              appendixLines.push('Failing jobs:', ...failingJobs);
            } else {
              appendixLines.push('Failing jobs: none reported.');
            }

            outputs.appendix = appendixLines.join('\n');

            if (attemptCount > maxAttempts) {
                return stop(
                  `autofix attempt limit reached (${attemptCount} > ${maxAttempts})`,
                  'max_attempts'
                );
            }

            outputs.should_run = 'true';
            outputs.head_ref = prData.head.ref || '';
            outputs.head_sha = headSha;

            for (const [key, value] of Object.entries(outputs)) {
              core.setOutput(key, value);
            }

  autofix:
    needs: prepare
    if: >-
      needs.prepare.outputs.should_run == 'true' &&
      needs.prepare.outputs.agent_type == 'codex'
    name: Run Codex autofix
    uses: stranske/Workflows/.github/workflows/reusable-codex-run.yml@main
    with:
      prompt_file: .github/codex/prompts/autofix_from_ci_failure.md
      mode: autofix
      pr_number: ${{ needs.prepare.outputs.pr_number }}
      pr_ref: ${{ needs.prepare.outputs.head_ref }}
      appendix: ${{ needs.prepare.outputs.appendix }}
    secrets:
      CODEX_AUTH_JSON: ${{ secrets.CODEX_AUTH_JSON }}
      WORKFLOWS_APP_ID: ${{ secrets.WORKFLOWS_APP_ID }}
      WORKFLOWS_APP_PRIVATE_KEY: ${{ secrets.WORKFLOWS_APP_PRIVATE_KEY }}

  autofix-claude:
    needs: prepare
    if: >-
      needs.prepare.outputs.should_run == 'true' &&
      needs.prepare.outputs.agent_type == 'claude'
    name: Run Claude autofix
    uses: stranske/Workflows/.github/workflows/reusable-claude-run.yml@main
    with:
      prompt_file: .github/codex/prompts/autofix_from_ci_failure.md
      mode: autofix
      pr_number: ${{ needs.prepare.outputs.pr_number }}
      pr_ref: ${{ needs.prepare.outputs.head_ref }}
      appendix: ${{ needs.prepare.outputs.appendix }}
    secrets:
      CLAUDE_AUTH_JSON: ${{ secrets.CLAUDE_AUTH_JSON }}
      WORKFLOWS_APP_ID: ${{ secrets.WORKFLOWS_APP_ID }}
      WORKFLOWS_APP_PRIVATE_KEY: ${{ secrets.WORKFLOWS_APP_PRIVATE_KEY }}

  needs-human:
    needs: prepare
    if: needs.prepare.outputs.stop_reason == 'max_attempts'
    name: Flag for human follow-up
    runs-on: ubuntu-latest
    environment: agent-standard
    steps:
      - name: Checkout (for retry helpers)
        uses: actions/checkout@v6
        with:
          sparse-checkout: |
            .github/scripts/github-api-with-retry.js
            .github/scripts/token_load_balancer.js
          sparse-checkout-cone-mode: false

      - name: Add needs-human label and comment
        uses: actions/github-script@v8
        with:
          github-token: ${{ env.WRITE_TOKEN }}
          script: |
            const fs = require('fs');
            const retryPath = './.github/scripts/github-api-with-retry.js';
            const { createTokenAwareRetry } = fs.existsSync(retryPath)
              ? require(retryPath)
              : { createTokenAwareRetry: async () => ({ withRetry: (fn) => fn(github) }) };
            const { withRetry } = await createTokenAwareRetry({ github, core });

            const prNumber = Number('${{ needs.prepare.outputs.pr_number }}');
            if (!prNumber) {
              core.info('No PR number available; skipping comment/label.');
              return;
            }

            const appendix = `${{ toJSON(needs.prepare.outputs.appendix) }}`.replace(/^"|"$/g, '');
            const attempts = ${{ needs.prepare.outputs.attempts || 0 }};
            const maxAttempts = ${{ needs.prepare.outputs.max_attempts || 0 }};

            const { owner, repo } = context.repo;

            await withRetry((client) => client.rest.issues.addLabels({
              owner,
              repo,
              issue_number: prNumber,
              labels: ['needs-human'],
            })).catch((error) => {
              core.warning(`Failed to add label: ${error.message}`);
            });

            const body = [
              'Autofix attempts exhausted for this head.',
              `Attempts: ${attempts} / ${maxAttempts}`,
              '',
              'Latest Gate summary:',
              '```',
              appendix || 'No run context available.',
              '```',
              '',
              'Please investigate manually.',
            ].join('\n');

            await withRetry((client) => client.rest.issues.createComment({
              owner,
              repo,
              issue_number: prNumber,
              body,
            }));

  metrics:
    name: Record autofix metrics
    needs:
      - prepare
      - autofix
      - autofix-claude
    if: always()
    runs-on: ubuntu-latest
    environment: agent-standard
    steps:
      - name: Checkout (for retry helpers)
        uses: actions/checkout@v6
        with:
          sparse-checkout: |
            .github/scripts/github-api-with-retry.js
            .github/scripts/token_load_balancer.js
          sparse-checkout-cone-mode: false

      - name: Collect metrics
        id: collect
        uses: actions/github-script@v8
        with:
          github-token: ${{ env.WRITE_TOKEN }}
          script: |
            const fs = require('fs');
            const retryPath = './.github/scripts/github-api-with-retry.js';
            const { createTokenAwareRetry } = fs.existsSync(retryPath)
              ? require(retryPath)
              : { createTokenAwareRetry: async () => ({
                  withRetry: (fn) => fn(github),
                  paginateWithRetry: (method, params) => github.paginate(method, params)
                }) };
            const { withRetry, paginateWithRetry } = await createTokenAwareRetry({ github, core });

            const prNumber = Number('${{ needs.prepare.outputs.pr_number || 0 }}') || 0;
            const attemptNumber = Number('${{ needs.prepare.outputs.attempts || 0 }}') || 0;
            const attemptLimit = Number('${{ needs.prepare.outputs.max_attempts || 0 }}') || 0;
            const headShaBefore = '${{ needs.prepare.outputs.head_sha }}';
            const gateConclusionBefore =
              '${{ needs.prepare.outputs.gate_conclusion }}' ||
              (context.payload.workflow_run?.conclusion || '');
            const gateRunId =
              '${{ needs.prepare.outputs.gate_run_id }}' ||
              String(context.payload.workflow_run?.id || '');
            const triggerReason = '${{ needs.prepare.outputs.trigger_reason || 'unknown' }}';
            const triggerJob = '${{ needs.prepare.outputs.trigger_job }}';
            const triggerStep = '${{ needs.prepare.outputs.trigger_step }}';
            const stopReason = '${{ needs.prepare.outputs.stop_reason }}';
            const codexAutofixResult = '${{ needs.autofix.result }}';
            const claudeAutofixResult = '${{ needs.autofix-claude.result }}';
            const autofixResult =
              codexAutofixResult && codexAutofixResult !== 'skipped'
                ? codexAutofixResult
                : claudeAutofixResult;

            const { owner, repo } = context.repo;
            let fixApplied = false;
            let headShaAfter = headShaBefore;
            let gateResultAfter = gateConclusionBefore || 'unknown';

            if (prNumber) {
              try {
                const { data: pr } = await withRetry((client) => client.rest.pulls.get({
                  owner,
                  repo,
                  pull_number: prNumber,
                }));
                headShaAfter = pr.head?.sha || headShaAfter;
                  fixApplied = Boolean(
                    headShaBefore && headShaAfter && headShaBefore !== headShaAfter
                  );

                // Remove autofix:escalated label when fixes are applied
                // This allows re-escalation to the agent if Gate fails again
                if (fixApplied) {
                  const prLabels = pr.labels?.map(l => l.name) || [];
                  if (prLabels.includes('autofix:escalated')) {
                    try {
                      await withRetry((client) => client.rest.issues.removeLabel({
                        owner,
                        repo,
                        issue_number: prNumber,
                        name: 'autofix:escalated',
                      }));
                      core.info(
                        'âœ… Removed autofix:escalated label - allows re-escalation ' +
                          'if Gate fails again'
                      );
                    } catch (labelError) {
                      core.warning(
                        `Failed to remove autofix:escalated label: ${labelError.message}`
                      );
                    }
                  }
                }

                const gateWorkflow = 'pr-00-gate.yml';
                const runs = await paginateWithRetry(github.rest.actions.listWorkflowRuns, {
                  owner,
                  repo,
                  workflow_id: gateWorkflow,
                  head_sha: headShaAfter,
                  per_page: 20,
                });
                const latestGateRun = runs[0];
                if (latestGateRun) {
                  gateResultAfter = latestGateRun.conclusion || latestGateRun.status || 'unknown';
                } else {
                  gateResultAfter = 'not-found';
                }
              } catch (error) {
                core.warning(`Failed to resolve PR or gate status: ${error.message}`);
              }
            }

            const metrics = {
              workflow_run_id: gateRunId,
              pr_number: prNumber,
              attempt_number: attemptNumber,
              attempt_limit: attemptLimit,
              trigger_reason: triggerReason || 'unknown',
              trigger_job: triggerJob,
              trigger_step: triggerStep,
              fix_applied: fixApplied,
              gate_result_after: gateResultAfter || 'unknown',
              gate_conclusion_before: gateConclusionBefore || 'unknown',
              stop_reason: stopReason || '',
              autofix_result: autofixResult || 'unknown',
              head_sha_before: headShaBefore,
              head_sha_after: headShaAfter,
              recorded_at: new Date().toISOString(),
            };

            core.setOutput('metrics_json', JSON.stringify(metrics));

      - name: Write summary and artifact
        env:
          METRICS_JSON: ${{ steps.collect.outputs.metrics_json }}
        run: |
          set -euo pipefail
          if [ -z "${METRICS_JSON:-}" ]; then
            echo "No metrics JSON captured; skipping summary."
            exit 0
          fi

          python - <<'PY'
          import json
          import os

          metrics = json.loads(os.environ["METRICS_JSON"])
          order = [
              "pr_number",
              "attempt_number",
              "attempt_limit",
              "trigger_reason",
              "trigger_job",
              "trigger_step",
              "fix_applied",
              "gate_conclusion_before",
              "gate_result_after",
              "autofix_result",
              "stop_reason",
              "workflow_run_id",
              "head_sha_before",
              "head_sha_after",
              "recorded_at",
          ]

          lines = ["## Autofix loop metrics", ""] + ["| Field | Value |", "| --- | --- |"]
          for key in order:
              value = metrics.get(key, "")
              lines.append(f"| {key} | `{value}` |")

          summary_path = os.environ.get("GITHUB_STEP_SUMMARY")
          if summary_path:
              with open(summary_path, "a", encoding="utf-8") as fp:
                  fp.write("\n".join(lines) + "\n")

          out_path = "autofix-metrics.ndjson"
          with open(out_path, "a", encoding="utf-8") as fp:
              fp.write(json.dumps(metrics) + "\n")
          print(f"Wrote metrics to {out_path}")
          PY

      - name: Upload metrics artifact
        uses: actions/upload-artifact@v6
        with:
          name: agents-autofix-metrics
          path: autofix-metrics.ndjson
          retention-days: 30
