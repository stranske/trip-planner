# See docs/ci/AGENTS_POLICY.md for guardrails and override process.
name: Agents Auto-Pilot

# End-to-end automation: Issue ‚Üí Format ‚Üí Optimize ‚Üí Apply ‚Üí Agent ‚Üí Keepalive ‚Üí Merge
# Triggered by:
# 1. agents:auto-pilot label (initial trigger)
# 2. Issue/PR closed events (for verification)
# 3. Manual dispatch (for testing/recovery)

on:
  issues:
    types: [labeled, closed]
  pull_request:
    types: [labeled, closed]
  # Note: Optimizer now runs inline in auto-pilot, not as separate workflow
  # workflow_run trigger removed to eliminate race conditions
  # If needed for other child workflows, add them here specifically
  workflow_dispatch:
    inputs:
      issue_number:
        description: "Issue number to auto-pilot"
        required: true
        type: string
      force_step:
        description: "Force a specific step (optional, leave as 'auto' for normal flow)"
        required: false
        type: choice
        options:
          - auto
          - format
          - optimize
          - apply
          - capability-check
          - agent
          - verify

permissions:
  contents: read
  issues: write
  pull-requests: write  # Needed to create PRs automatically
  actions: write  # Needed for workflow re-dispatch
  models: read

env:
  # Safety limits
  MAX_CYCLES: 10
  MAX_WALL_TIME_HOURS: 4
  AUTOPILOT_METRICS_LOG_PATH: .agents/autopilot-metrics.ndjson
  AUTOPILOT_METRICS_SUMMARY_PATH: .agents/autopilot-metrics-summary.ndjson

# NOTE: Workflow-level concurrency is intentionally ABSENT.
# Concurrency lives on the auto-pilot job (behind the gate job) so that
# spurious label-event runs are filtered BEFORE entering the concurrency
# group. This prevents them from cancelling legitimate re-dispatched runs.
# See docs/analysis/verify-create-new-pr-failure-analysis.md

jobs:
  # ‚îÄ‚îÄ Gate job ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # Lightweight filter that runs BEFORE concurrency group entry.
  # Only passes for:
  #   1. workflow_dispatch (self-dispatched pipeline steps)
  #   2. agents:auto-pilot label specifically added (initial trigger)
  #   3. Issue/PR closed with agents:auto-pilot label (verification)
  # All other label events (status:in-progress, agents:formatted, etc.)
  # are rejected HERE, so they never enter the concurrency group and
  # cannot displace pending re-dispatched runs.
  gate:
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      proceed: ${{ steps.check.outputs.proceed }}
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.action == 'labeled' &&
       github.event.label.name == 'agents:auto-pilot') ||
      (github.event.action == 'closed' && (
        (github.event_name == 'issues' &&
         contains(github.event.issue.labels.*.name, 'agents:auto-pilot')) ||
        (github.event_name == 'pull_request' &&
         contains(github.event.pull_request.labels.*.name, 'agents:auto-pilot'))
      ))
    steps:
      - name: Approve pipeline entry
        id: check
        run: echo "proceed=true" >> "$GITHUB_OUTPUT"

  # ‚îÄ‚îÄ Main auto-pilot job ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  auto-pilot:
    needs: [gate]
    if: needs.gate.outputs.proceed == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 4 hours = MAX_WALL_TIME_HOURS
    concurrency:
      group: >-
        agents-auto-pilot-${{ github.repository }}-${{
          github.event.issue.number || github.event.pull_request.number ||
          github.event.inputs.issue_number || github.run_id
        }}
      cancel-in-progress: false

    steps:
      # Mint GitHub App token early to use for API calls (avoids rate limits)
      - name: Mint GitHub App Token
        id: app_token
        uses: actions/create-github-app-token@v2
        continue-on-error: true
        with:
          app-id: ${{ secrets.WORKFLOWS_APP_ID || '0' }}
          private-key: ${{ secrets.WORKFLOWS_APP_PRIVATE_KEY || 'dummy' }}
          owner: ${{ github.repository_owner }}

      - name: Check if auto-pilot is enabled
        id: check_enabled
        uses: actions/github-script@v8
        with:
          github-token: ${{ steps.app_token.outputs.token || github.token }}
          script: |
            // Handle different event types
            if (context.eventName === 'workflow_dispatch') {
              core.setOutput('enabled', 'true');
              return;
            }

            // For label events, verify auto-pilot is enabled
            const labelName = context.payload.label?.name || '';

            // Get issue/PR to check for agents:auto-pilot label
            let labels = [];
            if (context.payload.issue) {
              labels = context.payload.issue.labels.map(l => l.name);
            } else if (context.payload.pull_request) {
              labels = context.payload.pull_request.labels.map(l => l.name);
            }

            const hasAutoPilot = labels.includes('agents:auto-pilot');
            const isAutoPilotTrigger = labelName === 'agents:auto-pilot';
            if (!hasAutoPilot && !isAutoPilotTrigger) {
              core.info(`Skipping: auto-pilot not enabled (trigger: ${labelName})`);
              core.setOutput('enabled', 'false');
              return;
            }

            core.setOutput('enabled', 'true');

      - name: Checkout repository
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/checkout@v6
        with:
          token: ${{ steps.app_token.outputs.token || github.token }}

      - name: Set up Node
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Setup API client
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}

      - name: Resolve Workflows default branch
        if: steps.check_enabled.outputs.enabled == 'true'
        id: workflows_ref
        uses: actions/github-script@v8
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-resolve-workflows-ref',
            });

            const { data } = await withRetry((client) => client.rest.repos.get({
              owner: 'stranske',
              repo: 'Workflows'
            }));
            if (!data?.default_branch) {
              core.setFailed('Could not determine Workflows default branch');
              return;
            }
            core.setOutput('ref', data.default_branch);

      - name: Checkout Workflows scripts
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/checkout@v6
        with:
          token: ${{ steps.app_token.outputs.token || github.token }}
          repository: stranske/Workflows
          ref: ${{ steps.workflows_ref.outputs.ref }}
          sparse-checkout: |
            .github/actions/setup-api-client
            .github/scripts
          sparse-checkout-cone-mode: false
          path: workflows-lib
          fetch-depth: 1

      - name: Set scripts path
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          echo "WORKFLOWS_SCRIPTS_PATH=${GITHUB_WORKSPACE}/workflows-lib" >> "$GITHUB_ENV"

      - name: Link node_modules for Workflows scripts
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          # ESM import() resolves relative to file location, not NODE_PATH.
          # token_load_balancer.js uses 'await import("@octokit/rest")' which
          # fails when scripts run from workflows-lib/ because node_modules
          # was installed at $GITHUB_WORKSPACE/.github/scripts/ by setup-api-client.
          SRC="${GITHUB_WORKSPACE}/.github/scripts/node_modules"
          DST="${GITHUB_WORKSPACE}/workflows-lib/.github/scripts/node_modules"
          if [ -d "$SRC" ] && [ ! -d "$DST" ]; then
            ln -sfn "$SRC" "$DST"
            echo "‚úÖ Linked node_modules ‚Üí workflows-lib scripts path"
          elif [ ! -d "$SRC" ]; then
            echo "::warning::node_modules not found at $SRC ‚Äî token rotation may fail"
          fi

      - name: Set up Python
        id: setup-python
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Cache pip (LLM requirements)
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/cache@v5
        with:
          path: |
            ~/.cache/pip
          key: >-
            pip-${{ runner.os }}-${{
            steps.setup-python.outputs.python-version
            }}-${{ hashFiles('tools/requirements-llm.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-
            pip-${{ runner.os }}-

      - name: Install Python dependencies
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install -r tools/requirements-llm.txt

      - name: Initialize auto-pilot metrics logs
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          mkdir -p .agents

      - name: Determine context
        if: steps.check_enabled.outputs.enabled == 'true'
        id: context
        uses: actions/github-script@v8
        with:
          script: |
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { createTokenAwareRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );
            const { withRetry, paginateWithRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-determine-context',
            });

            let issueNumber, issue, pr;

            // Get issue number from various sources (in priority order)
            if (context.eventName === 'workflow_dispatch') {
              issueNumber = parseInt('${{ inputs.issue_number }}');
            } else if (context.payload.issue) {
              issueNumber = context.payload.issue.number;
              issue = context.payload.issue;
            } else if (context.payload.pull_request) {
              // For PR events, find linked issue
              pr = context.payload.pull_request;
              const prBody = pr.body || '';
              const prTitle = pr.title || '';
              const metaMatch = prBody.match(/<!--\s*meta:issue:(\d+)\s*-->/i);
              const sourceMatch = prBody.match(/Source:\s*Issue\s*#(\d+)/i);
              const closeMatch = prBody.match(
                /\b(close[sd]?|fixe?[sd]?|resolve[sd]?)[:\s]+#(\d+)\b/i
              );
              const titleCloseMatch = prTitle.match(
                /\b(close[sd]?|fixe?[sd]?|resolve[sd]?)[:\s]+#(\d+)\b/i
              );
              const fallbackMatch = prBody.match(/#(\d+)/);

              const resolved =
                metaMatch?.[1] ||
                sourceMatch?.[1] ||
                closeMatch?.[2] ||
                titleCloseMatch?.[2] ||
                fallbackMatch?.[1];
              issueNumber = resolved ? parseInt(resolved) : null;
            }

            if (!issueNumber) {
              core.setFailed('Could not determine issue number');
              return;
            }

            // Fetch issue if not in payload (with retry)
            if (!issue) {
              const { data } = await withRetry(() =>
                github.rest.issues.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber
                })
              );
              issue = data;
            }

            const labels = issue.labels.map(l => l.name);

            // Check for pause label
            if (labels.includes('agents:auto-pilot-pause')) {
              core.info('Auto-pilot paused by agents:auto-pilot-pause label');
              core.setOutput('should_continue', 'false');
              core.setOutput('reason', 'paused');
              return;
            }

            // Check for failure/needs-human
            if (labels.includes('needs-human') || labels.includes('agents:auto-pilot-failed')) {
              core.info('Auto-pilot stopped: requires human intervention');
              core.setOutput('should_continue', 'false');
              core.setOutput('reason', 'needs-human');
              return;
            }

            // Determine current state based on labels
            // NOTE: Use 'agents:formatted' (completion marker) not 'agents:format' (old trigger)
            const hasFormat = labels.includes('agents:formatted');
            const hasOptimize = labels.includes('agents:optimize');
            const hasApplySuggestions = labels.includes('agents:apply-suggestions');
            const hasAgentLabel = labels.some(l => l.startsWith('agent:'));
            const hasAutofix = labels.includes('autofix');
            const hasAutomerge = labels.includes('automerge');
            const hasVerify = labels.includes('verify:evaluate');

            // Check for actual optimizer output (not just label)
            // Since we run optimizer inline now, this should always exist after optimize step
            // the optimizer workflow actually completed its work
            const comments = await paginateWithRetry(
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            const hasOptimizerOutput = comments.some(c => {
              const body = c.body || '';
              return body.includes('Issue Optimization Suggestions') ||
                     body.includes('ISSUE_OPTIMIZER_SUGGESTIONS') ||
                     body.includes('## üìã Optimization Suggestions');
            });

            // Check for linked PR (with pagination and multiple event types)
            const timelineEvents = await paginateWithRetry(
              github.rest.issues.listEventsForTimeline,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            function matchesIssueReference(text, num) {
              if (!text) return false;
              const pattern = new RegExp(
                `\\b(close[sd]?|fixe?[sd]?|resolve[sd]?)\\s+#${num}\\b`,
                'i'
              );
              return pattern.test(text);
            }

            let linkedPR = null;
            for (const event of timelineEvents) {
              // Handle both cross-referenced and connected events
              const isCrossRef = event.event === 'cross-referenced';
              const isConnected = event.event === 'connected';
              const sourceIssue = event.source?.issue;
              const repoMatch = sourceIssue?.repository?.full_name ===
                `${context.repo.owner}/${context.repo.repo}`;
              if ((isCrossRef || isConnected) && repoMatch && sourceIssue?.pull_request) {
                const prBody = sourceIssue.body || '';
                const prTitle = sourceIssue.title || '';
                const hasMeta = prBody.includes(`meta:issue:${issueNumber}`);
                const hasReference = matchesIssueReference(prBody, issueNumber) ||
                  matchesIssueReference(prTitle, issueNumber);
                if (hasMeta || hasReference) {
                  linkedPR = sourceIssue.number;
                }
              }
            }

            core.setOutput('issue_number', issueNumber);
            core.setOutput('issue_title', issue.title);
            core.setOutput('issue_state', issue.state);
            core.setOutput('should_continue', 'true');
            core.setOutput('has_format', hasFormat.toString());
            core.setOutput('has_optimize', hasOptimize.toString());
            core.setOutput('has_optimizer_output', hasOptimizerOutput.toString());
            core.setOutput('has_apply', hasApplySuggestions.toString());
            core.setOutput('has_agent', hasAgentLabel.toString());
            core.setOutput('has_autofix', hasAutofix.toString());
            core.setOutput('has_automerge', hasAutomerge.toString());
            core.setOutput('has_verify', hasVerify.toString());
            core.setOutput('linked_pr', linkedPR || '');

            console.log(`Issue #${issueNumber} state:`);
            console.log(`  State: ${issue.state}`);
            console.log(`  Labels: ${labels.join(', ')}`);
            console.log(`  Optimizer output: ${hasOptimizerOutput}`);
            console.log(`  Linked PR: ${linkedPR || 'none'}`);

      - name: Check step count
        if: steps.context.outputs.should_continue == 'true'
        id: cycles
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { paginateWithRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Get all comments to count auto-pilot steps (with pagination and retry)
            const allComments = await paginateWithRetry(
              github,
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            const stepComments = allComments.filter(c =>
              typeof c.body === 'string' && c.body.includes('ü§ñ Auto-pilot step')
            );

            const stepCount = stepComments.length;
            const maxCycles = parseInt('${{ env.MAX_CYCLES }}');

            if (stepCount >= maxCycles) {
              core.warning(`Auto-pilot exceeded max steps (${stepCount}/${maxCycles})`);
              core.setOutput('exceeded', 'true');
              return;
            }

            core.setOutput('exceeded', 'false');
            core.setOutput('count', stepCount.toString());

      - name: Stop if exceeded
        if: steps.cycles.outputs.exceeded == 'true'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-stop',
              capabilities: ['issues:write']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Add failure label and comment
            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['needs-human', 'agents:auto-pilot-failed']
            }));

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `## ‚ö†Ô∏è Auto-Pilot Stopped

            **Reason:** Exceeded maximum cycle limit (${{ env.MAX_CYCLES }} cycles)

            This issue requires human review. Possible causes:
            - Repeated CI failures
            - Conflicting requirements
            - External dependencies

            **To resume:** Remove \`agents:auto-pilot-failed\` and
            \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
            }));

            core.setFailed('Auto-pilot exceeded max cycles');

      - name: Determine next step
        if: |
          steps.context.outputs.should_continue == 'true' &&
          steps.cycles.outputs.exceeded != 'true'
        id: next
        env:
          FORCE_STEP: ${{ inputs.force_step }}
        run: |
          # Priority order of steps
          # 1. If issue closed and has verify label ‚Üí done
          # 2. If issue closed without verify ‚Üí add verify
          # 3. If no PR ‚Üí need agent assignment
          # 4. If has PR ‚Üí check PR state
          # 5. If no format ‚Üí format first
          # 6. If no optimize label ‚Üí trigger optimize
          # 7. If optimize label but no output ‚Üí wait (optimizer still running)
          # 8. If has optimizer output but no apply ‚Üí apply suggestions

          ISSUE_STATE="${{ steps.context.outputs.issue_state }}"
          HAS_FORMAT="${{ steps.context.outputs.has_format }}"
          HAS_OPTIMIZER_OUTPUT="${{ steps.context.outputs.has_optimizer_output }}"
          HAS_APPLY="${{ steps.context.outputs.has_apply }}"
          HAS_AGENT="${{ steps.context.outputs.has_agent }}"
          LINKED_PR="${{ steps.context.outputs.linked_pr }}"
          HAS_VERIFY="${{ steps.context.outputs.has_verify }}"

          # Force step if specified (not 'auto')
          if [[ -n "$FORCE_STEP" && "$FORCE_STEP" != "auto" ]]; then
            echo "next_step=$FORCE_STEP" >> "$GITHUB_OUTPUT"
            echo "Forced step: $FORCE_STEP"
            exit 0
          fi

          # Issue closed = done or verify
          if [[ "$ISSUE_STATE" == "closed" ]]; then
            if [[ "$HAS_VERIFY" == "true" ]]; then
              echo "next_step=done" >> "$GITHUB_OUTPUT"
              echo "Issue closed with verification - auto-pilot complete"
            else
              echo "next_step=verify" >> "$GITHUB_OUTPUT"
              echo "Issue closed - triggering verification"
            fi
            exit 0
          fi

          # No PR yet - need to go through issue prep pipeline
          if [[ -z "$LINKED_PR" ]]; then
            if [[ "$HAS_FORMAT" != "true" ]]; then
              echo "next_step=format" >> "$GITHUB_OUTPUT"
              echo "Step 1: Format issue"
            elif [[ "$HAS_OPTIMIZER_OUTPUT" != "true" ]]; then
              # Run optimizer inline (not via label)
              echo "next_step=optimize" >> "$GITHUB_OUTPUT"
              echo "Step 2: Run optimizer (inline)"
            elif [[ "$HAS_APPLY" != "true" ]]; then
              echo "next_step=apply" >> "$GITHUB_OUTPUT"
              echo "Step 3: Apply suggestions"
            elif [[ "$HAS_AGENT" != "true" ]]; then
              echo "next_step=capability-check" >> "$GITHUB_OUTPUT"
              echo "Step 4: Run capability check and assign agent"
            else
              echo "next_step=create-pr" >> "$GITHUB_OUTPUT"
              echo "Step 5: All prep complete, checking for branch to create PR"
            fi
            exit 0
          fi

          # Has PR - check if it's complete and ready to merge
          # Get PR state to see if keepalive has finished
          if ! PR_STATE=$(LINKED_PR="$LINKED_PR" node - <<'NODE'
          (async () => {
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { paginateWithRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:read'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.LINKED_PR);
            const comments = await paginateWithRetry(
              github.rest.issues.listComments,
              { owner, repo, issue_number: issueNumber, per_page: 100 }
            );
            const last = [...comments].reverse().find((comment) =>
              (comment.body || '').includes('keepalive-state:')
            );
            if (last?.body) {
              process.stdout.write(last.body);
            }
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE
          ); then
            echo "‚ö†Ô∏è Failed to fetch PR state, defaulting to monitor-pr"
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Check if we got any state data
          if [ -z "$PR_STATE" ]; then
            echo "No keepalive state found, defaulting to monitor-pr"
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Check if keepalive marked tasks as complete
          if echo "$PR_STATE" | grep -q '"last_action":"stop"' && \
             echo "$PR_STATE" | grep -q '"last_reason":"tasks-complete"'; then
            echo "next_step=check-completion" >> "$GITHUB_OUTPUT"
            echo "Step 6.5: PR tasks complete - checking for merge"
          else
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            echo "PR #$LINKED_PR exists - monitoring via keepalive"
          fi
          exit 0

      - name: Metrics - Start format timer
        if: steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Format (inline)
        if: steps.next.outputs.next_step == 'format'
        id: format_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLAUDE_API_STRANSKE: ${{ secrets.CLAUDE_API_STRANSKE }}
          PYTHONPATH: ${{ github.workspace }}
        run: |

          # Post progress comment
          cat > /tmp/auto_pilot_format_start.md <<'EOF'
          ü§ñ **Auto-pilot step $((STEP_COUNT + 1))**: Starting issue formatting...

          Running formatter inline (not via label trigger).
          EOF
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/auto_pilot_format_start.md', 'utf8');
            await withRetry((client) => client.rest.issues.createComment({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Get issue body
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:read'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const { data } = await withRetry((client) => client.rest.issues.get({
              owner,
              repo,
              issue_number: issueNumber,
            }));
            fs.writeFileSync('/tmp/issue.json', JSON.stringify(data, null, 2));
            fs.writeFileSync('/tmp/issue_body.md', data.body || '');
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Format the issue
          echo "Formatting issue into AGENT_ISSUE_TEMPLATE structure..."
          python scripts/langchain/issue_formatter.py \
            --input-file /tmp/issue_body.md \
            --json > /tmp/format_result.json

          # Check for guard_blocked before proceeding
          python -c "
          import json, sys
          with open('/tmp/format_result.json') as f:
              result = json.load(f)
          if result.get('guard_blocked'):
              reason = result.get('guard_reason', 'unknown')
              print(f'GUARD_BLOCKED: {reason}')
              with open('/tmp/guard_blocked', 'w') as f:
                  f.write(reason)
              sys.exit(0)
          formatted = result.get('formatted_body', '')
          if not formatted:
              print('ERROR: No formatted body returned')
              sys.exit(1)
          with open('/tmp/formatted_body.md', 'w') as f:
              f.write(formatted)
          print('Issue formatted successfully')
          " || exit 1

          # If guard blocked, apply needs-human + pause labels and stop
          if [ -f /tmp/guard_blocked ]; then
            echo "‚ö†Ô∏è Prompt injection guard blocked this issue. Applying needs-human labels."
            node - <<'GUARD_NODE'
            (async () => {
              const fs = require('fs');
              const { Octokit } = require('@octokit/rest');
              const retryLib = require('./.github/scripts/github-api-with-retry.js');
              const { createTokenAwareRetry } = retryLib;
              const core = { info: () => {}, warning: console.warn, debug: () => {} };
              const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
              const { withRetry } = await createTokenAwareRetry({
                github,
                core,
                env: process.env,
                task: 'auto-pilot',
                capabilities: ['issues:write'],
              });
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const issueNumber = Number(process.env.ISSUE_NUMBER);
              const reason = fs.readFileSync('/tmp/guard_blocked', 'utf8').trim();
              await withRetry((client) => client.rest.issues.addLabels({
                owner, repo, issue_number: issueNumber,
                labels: ['needs-human', 'agents:auto-pilot-pause'],
              }));
              await withRetry((client) => client.rest.issues.createComment({
                owner, repo, issue_number: issueNumber,
                body: [
                  '‚ö†Ô∏è **Prompt injection guard triggered** during formatting.',
                  '',
                  `Reason: ${reason}`,
                  '',
                  (
                    'Automation has been paused. ' +
                    'A human must review this issue before automation can continue.'
                  ),
                ].join('\n'),
              }));
            })().catch((error) => {
              console.error(error);
              process.exit(1);
            });
          GUARD_NODE
            echo "üõë Automation stopped due to prompt injection guard."
            exit 0
          fi

          # Update issue body
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/formatted_body.md', 'utf8');
            await withRetry((client) => client.rest.issues.update({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Add marker labels (but don't trigger workflow)
          node - <<'NODE'
          (async () => {
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            try {
              await withRetry((client) => client.rest.issues.addLabels({
                owner,
                repo,
                issue_number: issueNumber,
                labels: ['agents:formatted'],
              }));
            } catch (error) {
              console.warn(`Label update failed: ${error.message}`);
            }
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          echo "‚úÖ Formatting complete - continuing to next step"

      - name: Metrics - End format timer
        if: always() && steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record format step
        if: always() && steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.format_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "format" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start optimize timer
        if: steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Optimize (inline)
        if: steps.next.outputs.next_step == 'optimize'
        id: optimize_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLAUDE_API_STRANSKE: ${{ secrets.CLAUDE_API_STRANSKE }}
          LANGCHAIN_PROVIDER: anthropic
          LANGCHAIN_MODEL: claude-sonnet-4-5-20250929
          PYTHONPATH: ${{ github.workspace }}
        run: |

          # Post progress comment
          cat > /tmp/auto_pilot_optimize_start.md <<'EOF'
          ü§ñ **Auto-pilot step $((STEP_COUNT + 1))**: Analyzing issue for improvements...

          Running optimizer inline (not via label trigger).
          EOF
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/auto_pilot_optimize_start.md', 'utf8');
            await withRetry((client) => client.rest.issues.createComment({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Get issue body
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:read'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const { data } = await withRetry((client) => client.rest.issues.get({
              owner,
              repo,
              issue_number: issueNumber,
            }));
            fs.writeFileSync('/tmp/issue.json', JSON.stringify(data, null, 2));
            fs.writeFileSync('/tmp/issue_body.md', data.body || '');
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Run optimizer analysis
          echo "Running optimization analysis..."
          python scripts/langchain/issue_optimizer.py \
            --input-file /tmp/issue_body.md \
            --json > /tmp/suggestions.json

          # Check for guard_blocked before proceeding with optimizer results
          python -c "
          import json, sys
          with open('/tmp/suggestions.json') as f:
              data = json.load(f)
          if data.get('guard_blocked'):
              reason = data.get('guard_reason', 'unknown')
              print(f'GUARD_BLOCKED: {reason}')
              with open('/tmp/guard_blocked', 'w') as f:
                  f.write(reason)
              sys.exit(0)
          "

          # If guard blocked, apply needs-human + pause labels and stop
          if [ -f /tmp/guard_blocked ]; then
            echo "‚ö†Ô∏è Prompt injection guard blocked this issue. Applying needs-human labels."
            node - <<'GUARD_NODE'
            (async () => {
              const fs = require('fs');
              const { Octokit } = require('@octokit/rest');
              const retryLib = require('./.github/scripts/github-api-with-retry.js');
              const { createTokenAwareRetry } = retryLib;
              const core = { info: () => {}, warning: console.warn, debug: () => {} };
              const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
              const { withRetry } = await createTokenAwareRetry({
                github,
                core,
                env: process.env,
                task: 'auto-pilot',
                capabilities: ['issues:write'],
              });
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const issueNumber = Number(process.env.ISSUE_NUMBER);
              const reason = fs.readFileSync('/tmp/guard_blocked', 'utf8').trim();
              await withRetry((client) => client.rest.issues.addLabels({
                owner, repo, issue_number: issueNumber,
                labels: ['needs-human', 'agents:auto-pilot-pause'],
              }));
              await withRetry((client) => client.rest.issues.createComment({
                owner, repo, issue_number: issueNumber,
                body: [
                  '‚ö†Ô∏è **Prompt injection guard triggered** during optimization.',
                  '',
                  `Reason: ${reason}`,
                  '',
                  (
                    'Automation has been paused. ' +
                    'A human must review this issue before automation can continue.'
                  ),
                ].join('\n'),
              }));
            })().catch((error) => {
              console.error(error);
              process.exit(1);
            });
          GUARD_NODE
            echo "üõë Automation stopped due to prompt injection guard."
            echo "stop_autopilot=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Format and post comment
          python -c "
          import json
          import sys
          sys.path.insert(0, 'scripts/langchain')
          from issue_optimizer import IssueOptimizationResult, format_suggestions_comment

          with open('/tmp/suggestions.json') as f:
              data = json.load(f)

          result = IssueOptimizationResult(
              task_splitting=data.get('task_splitting', []),
              blocked_tasks=data.get('blocked_tasks', []),
              objective_criteria=data.get('objective_criteria', []),
              missing_sections=data.get('missing_sections', []),
              formatting_issues=data.get('formatting_issues', []),
              overall_notes=data.get('overall_notes', ''),
              provider_used=data.get('provider_used')
          )

          comment = format_suggestions_comment(result)
          with open('/tmp/comment.md', 'w') as f:
              f.write(comment)
          " || {
            echo "Failed to format comment, using raw JSON"
            cat /tmp/suggestions.json > /tmp/comment.md
          }

          # Post suggestions comment
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/comment.md', 'utf8');
            await withRetry((client) => client.rest.issues.createComment({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Add marker labels (but don't trigger workflow)
          node - <<'NODE'
          (async () => {
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            try {
              await withRetry((client) => client.rest.issues.addLabels({
                owner,
                repo,
                issue_number: issueNumber,
                labels: ['agents:formatted', 'agents:apply-suggestions'],
              }));
            } catch (error) {
              console.warn(`Label update failed: ${error.message}`);
            }
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          echo "‚úÖ Optimization complete - continuing to next step"

      - name: Metrics - End optimize timer
        if: always() && steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record optimize step
        if: always() && steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.optimize_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "optimize" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Guard - Require optimizer output before apply
        if: steps.next.outputs.next_step == 'apply'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            // Guard: Verify optimizer produced suggestions before applying
            // This prevents silent failures when optimizer runs but produces no output
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-guard-optimizer',
              capabilities: ['issues:write']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Fetch all comments on the issue (with pagination and retry)
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { paginateWithRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );
            const comments = await paginateWithRetry(
              github,
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            // Look for optimizer suggestions marker
            // The optimizer workflow posts a comment containing "Issue Optimization Suggestions"
            // or the hidden marker "ISSUE_OPTIMIZER_SUGGESTIONS"
            const hasOptimizerOutput = comments.some(comment => {
              const body = comment.body || '';
              return body.includes('Issue Optimization Suggestions') ||
                     body.includes('ISSUE_OPTIMIZER_SUGGESTIONS') ||
                     body.includes('## üìã Optimization Suggestions');
            });

            if (!hasOptimizerOutput) {
              // No optimizer output found - this is a bug in the pipeline
              core.warning('‚ö†Ô∏è Optimizer was supposed to run but produced no suggestions comment');

              // Post warning comment
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `‚ö†Ô∏è **Auto-pilot warning**: Optimizer step completed but no suggestions found.

            This usually means the optimizer workflow was triggered but failed silently.

            **Next steps:**
            1. Check the \`agents-issue-optimizer.yml\` workflow runs
            2. Look for error messages in workflow logs
            3. Remove \`agents:auto-pilot-pause\` and \`needs-human\` labels to retry

            **For maintainers:** Issue paused pending investigation of optimizer failure.`
              }));

              // Add pause and needs-human labels
              await withRetry((client) => client.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['agents:auto-pilot-pause', 'needs-human']
              }));

              core.setFailed('Optimizer produced no output - pausing for investigation');
            } else {
              core.info('‚úÖ Optimizer output found - proceeding with apply step');
            }

      - name: Metrics - Start apply timer
        if: steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Apply suggestions (inline)
        if: steps.next.outputs.next_step == 'apply'
        id: apply_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLAUDE_API_STRANSKE: ${{ secrets.CLAUDE_API_STRANSKE }}
          LANGCHAIN_PROVIDER: anthropic
          LANGCHAIN_MODEL: claude-sonnet-4-5-20250929
          PYTHONPATH: ${{ github.workspace }}
        run: |

          # Post progress comment
          cat > /tmp/auto_pilot_apply_start.md <<'EOF'
          ü§ñ **Auto-pilot step $((STEP_COUNT + 1))**: Applying optimization suggestions...

          Running apply inline (not via label trigger).
          EOF
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/auto_pilot_apply_start.md', 'utf8');
            await withRetry((client) => client.rest.issues.createComment({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Get issue body and comments
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry, paginateWithRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:read'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const { data } = await withRetry((client) => client.rest.issues.get({
              owner,
              repo,
              issue_number: issueNumber,
            }));
            fs.writeFileSync('/tmp/issue.json', JSON.stringify(data, null, 2));
            fs.writeFileSync('/tmp/issue_body.md', data.body || '');
            const comments = await paginateWithRetry(
              github.rest.issues.listComments,
              { owner, repo, issue_number: issueNumber, per_page: 100 }
            );
            fs.writeFileSync('/tmp/comments.json', JSON.stringify(comments, null, 2));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Extract and apply suggestions
          python -c "
          import json
          import sys
          import re
          sys.path.insert(0, 'scripts/langchain')
          from issue_optimizer import _extract_suggestions_json, apply_suggestions

          with open('/tmp/comments.json') as f:
              comments = json.load(f)

          suggestions = None
          for comment in comments:
              body = comment.get('body', '')
              extracted = _extract_suggestions_json(body)
              if extracted:
                  suggestions = extracted
                  break

          if not suggestions:
              print('ERROR: No suggestions JSON found in comments')
              sys.exit(1)

          # Read current issue body
          with open('/tmp/issue_body.md') as f:
              issue_body = f.read()

          # Apply suggestions
          result = apply_suggestions(issue_body, suggestions, use_llm=True)

          # Check for guard_blocked
          if result.get('guard_blocked'):
              reason = result.get('guard_reason', 'unknown')
              print(f'GUARD_BLOCKED: {reason}')
              with open('/tmp/guard_blocked', 'w') as f:
                  f.write(reason)
              sys.exit(0)

          with open('/tmp/updated_body.md', 'w') as f:
              f.write(result['formatted_body'])

          print('Suggestions applied successfully')
          " || exit 1

          # If guard blocked during apply, apply needs-human + pause labels and stop
          if [ -f /tmp/guard_blocked ]; then
            echo "‚ö†Ô∏è Prompt injection guard blocked during apply step."
            node - <<'GUARD_NODE'
            (async () => {
              const fs = require('fs');
              const { Octokit } = require('@octokit/rest');
              const retryLib = require('./.github/scripts/github-api-with-retry.js');
              const { createTokenAwareRetry } = retryLib;
              const core = { info: () => {}, warning: console.warn, debug: () => {} };
              const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
              const { withRetry } = await createTokenAwareRetry({
                github,
                core,
                env: process.env,
                task: 'auto-pilot',
                capabilities: ['issues:write'],
              });
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const issueNumber = Number(process.env.ISSUE_NUMBER);
              const reason = fs.readFileSync('/tmp/guard_blocked', 'utf8').trim();
              await withRetry((client) => client.rest.issues.addLabels({
                owner, repo, issue_number: issueNumber,
                labels: ['needs-human', 'agents:auto-pilot-pause'],
              }));
              await withRetry((client) => client.rest.issues.createComment({
                owner, repo, issue_number: issueNumber,
                body: [
                  '‚ö†Ô∏è **Prompt injection guard triggered** during apply step.',
                  '',
                  `Reason: ${reason}`,
                  '',
                  (
                    'Automation has been paused. ' +
                    'A human must review this issue before automation can continue.'
                  ),
                ].join('\n'),
              }));
            })().catch((error) => {
              console.error(error);
              process.exit(1);
            });
          GUARD_NODE
            echo "üõë Automation stopped due to prompt injection guard."
            echo "stop_autopilot=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Update issue body
          node - <<'NODE'
          (async () => {
            const fs = require('fs');
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            const body = fs.readFileSync('/tmp/updated_body.md', 'utf8');
            await withRetry((client) => client.rest.issues.update({
              owner,
              repo,
              issue_number: issueNumber,
              body,
            }));
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          # Add marker label (but don't trigger workflow)
          node - <<'NODE'
          (async () => {
            const { Octokit } = require('@octokit/rest');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const core = { info: () => {}, warning: console.warn, debug: () => {} };
            const github = new Octokit({ auth: process.env.GITHUB_TOKEN });
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot',
              capabilities: ['issues:write'],
            });
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            const issueNumber = Number(process.env.ISSUE_NUMBER);
            try {
              await withRetry((client) => client.rest.issues.addLabels({
                owner,
                repo,
                issue_number: issueNumber,
                labels: ['agents:formatted', 'agents:apply-suggestions'],
              }));
            } catch (error) {
              console.warn(`Label update failed: ${error.message}`);
            }
          })().catch((error) => {
            console.error(error);
            process.exit(1);
          });
          NODE

          echo "‚úÖ Apply complete - continuing to next step"

      - name: Metrics - End apply timer
        if: always() && steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record apply step
        if: always() && steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.apply_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "apply" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start capability check timer
        if: steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      # ‚îÄ‚îÄ P2: Complexity pre-check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      # Analyse issue body for complexity signals before assigning to
      # the coding agent.  Issues flagged as high-complexity get
      # `needs-human` instead of an `agent:*` label.
      - name: Complexity pre-check
        if: steps.next.outputs.next_step == 'capability-check'
        id: complexity_check
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github, core, env: process.env,
              task: 'auto-pilot-complexity-check',
              capabilities: ['issues:read']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            const { data: issue } = await withRetry((client) =>
              client.rest.issues.get({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber
              })
            );

            const body = (issue.body || '').toLowerCase();
            const title = (issue.title || '').toLowerCase();

            // ‚îÄ‚îÄ Heuristic signals ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            let score = 0;
            const flags = [];

            // 1. Acceptance-criteria quality: vague or missing AC
            const acSection = body.match(
              /## acceptance criteria([\s\S]*?)(?=\n##|$)/i
            );
            if (!acSection) {
              score += 3;
              flags.push('missing-acceptance-criteria');
            } else {
              const acText = acSection[1];
              const checkboxes = (acText.match(/- \[[ x]\]/g) || []).length;
              if (checkboxes === 0) {
                score += 2;
                flags.push('no-checkboxes-in-AC');
              }
              // Vague AC: very short or contains weasel words
              const weaselWords = [
                'should work', 'as needed', 'if possible',
                'various', 'etc', 'and more', 'miscellaneous'
              ];
              for (const w of weaselWords) {
                if (acText.includes(w)) {
                  score += 1;
                  flags.push(`vague-AC:${w}`);
                  break;  // only count once
                }
              }
            }

            // 2. Scope breadth: mentions many files or directories
            const fileRefs = body.match(
              /[a-z0-9_\-]+\.(py|js|ts|yml|yaml|json|md|sh|toml)/g
            ) || [];
            const uniqueFiles = new Set(fileRefs);
            if (uniqueFiles.size > 8) {
              score += 2;
              flags.push(`wide-scope:${uniqueFiles.size}-files-referenced`);
            }

            // 3. Cross-concern indicators
            const crossConcerns = [
              'database', 'migration', 'security', 'auth',
              'breaking change', 'backwards compatible', 'api change',
              'multiple repos', 'cross-repo', 'consumer repo'
            ];
            for (const c of crossConcerns) {
              if (body.includes(c) || title.includes(c)) {
                score += 1;
                flags.push(`cross-concern:${c}`);
              }
            }

            // 4. Human-only markers
            const humanOnly = [
              'manual testing required', 'needs discussion',
              'design review', 'architecture decision',
              'RFC', 'ADR'
            ];
            for (const h of humanOnly) {
              if (body.includes(h.toLowerCase())) {
                score += 3;
                flags.push(`human-marker:${h}`);
              }
            }

            const THRESHOLD = 5;
            const tooComplex = score >= THRESHOLD;

            core.info(`Complexity score: ${score} (threshold: ${THRESHOLD})`);
            core.info(`Flags: ${flags.join(', ') || 'none'}`);
            core.setOutput('score', score.toString());
            core.setOutput('too_complex', tooComplex.toString());
            core.setOutput('flags', flags.join(', '));

      - name: Route complex issue to human
        if: |
          steps.next.outputs.next_step == 'capability-check' &&
          steps.complexity_check.outputs.too_complex == 'true'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          COMPLEXITY_SCORE: ${{ steps.complexity_check.outputs.score }}
          COMPLEXITY_FLAGS: ${{ steps.complexity_check.outputs.flags }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github, core, env: process.env,
              task: 'auto-pilot-complexity-route',
              capabilities: ['issues:write']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const score = process.env.COMPLEXITY_SCORE;
            const flags = process.env.COMPLEXITY_FLAGS;

            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['needs-human']
            }));

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `## üß† Complexity Pre-Check: Needs Human Review

            This issue scored **${score}/10+** on the complexity heuristic (threshold: 5).

            **Signals detected:**
            ${flags.split(', ').map(f => '- ' + f).join('\n')}

            The auto-pilot has paused before assigning to the coding agent.
            A human should review and either:
            1. Simplify the issue and remove \`needs-human\` to resume
            2. Split into smaller issues
            3. Assign manually

            _To override: remove \`needs-human\` label and re-add \`agents:auto-pilot\`._`
            }));

            core.info(`Issue #${issueNumber} routed to human (complexity: ${score})`);

      - name: Execute step - Capability check & Agent
        if: |
          steps.next.outputs.next_step == 'capability-check' &&
          steps.complexity_check.outputs.too_complex != 'true'
        id: capability_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-capability-check',
              capabilities: ['issues:write', 'actions:write', 'contents:read']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;

            let agentKey = 'codex';
            try {
              const { loadAgentRegistry } = require('./.github/scripts/agent_registry.js');
              const registry = loadAgentRegistry();
              const defaultAgent = registry.default_agent || agentKey;
              agentKey = String(defaultAgent).trim().toLowerCase() || agentKey;
              } catch (error) {
                const prefix = `Failed to load agent registry; defaulting to ${agentKey}:`;
                core.warning(`${prefix} ${error.message}`);
              }

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ü§ñ **Auto-pilot step ${stepCount}**: Issue prepared! Assigning to agent...

            Adding \`agent:${agentKey}\` label. The capability check will run automatically.

            ‚è≥ Agent will create a PR shortly.`
            }));

            // Add agent label - capability check triggers on this
            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: [`agent:${agentKey}`]
            }));

            let baseBranch = context.payload?.repository?.default_branch || '';
            if (!baseBranch) {
              try {
                const { data: repoInfo } = await withRetry((client) => client.rest.repos.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo
                }));
                baseBranch = repoInfo?.default_branch || '';
              } catch (error) {
                core.warning(`Failed to resolve default branch: ${error?.message || error}`);
              }
            }
            if (!baseBranch) {
              core.warning('Repository default branch not available; skipping belt dispatch.');
              return;
            }

            // Force-dispatch Codex belt dispatcher to create the branch
            try {
              await withRetry((client) => client.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'agents-71-codex-belt-dispatcher.yml',
                ref: baseBranch,
                inputs: {
                  agent_key: agentKey,
                  force_issue: issueNumber.toString(),
                  dry_run: 'false'
                }
              }));
              const prefix = `Dispatched belt dispatcher (agent: ${agentKey}) for issue`;
              core.info(`${prefix} #${issueNumber}`);
            } catch (dispatchError) {
              core.warning(`Could not dispatch belt dispatcher: ${dispatchError?.message}`);
            }

      - name: Metrics - End capability check timer
        if: always() && steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record capability check step
        if: always() && steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.capability_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "capability-check" \
            --success "$success" \
            --failure-reason "$failure_reason"
      - name: Metrics - Start verify timer
        if: steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Verify
        if: steps.next.outputs.next_step == 'verify'
        id: verify_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-verify',
              capabilities: ['issues:write', 'pulls:read']
              }));
              const prefix = `Dispatched belt dispatcher (agent: ${agentKey}) for issue`;
              core.info(`${prefix} #${issueNumber}`);

            // Find the merged PR for this issue
            // Look for PRs with the meta marker or explicit closing reference
            const { data: prs } = await withRetry((client) => client.rest.pulls.list({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'closed',
              sort: 'updated',
              direction: 'desc',
              per_page: 100
            }));

            // Helper to detect explicit closing/fixing references to this issue
            function matchesIssueReference(text, num) {
              if (!text) return false;
              // Match: closes #123, fixes #123, resolves #123 (and variations)
              const pattern = new RegExp(
                `\\b(close[sd]?|fixe?[sd]?|resolve[sd]?)\\s+#${num}\\b`, 'i'
              );
              return pattern.test(text);
            }

            // Find PR that references this issue
            const linkedPr = prs.find(pr =>
              pr.merged_at && (
                pr.body?.includes(`meta:issue:${issueNumber}`) ||
                matchesIssueReference(pr.body, issueNumber) ||
                matchesIssueReference(pr.title, issueNumber)
              )
            );

            if (!linkedPr) {
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot**: Issue closed but couldn't find linked merged PR.

            Adding \`verify:evaluate\` label to issue for tracking.`
              }));

              await withRetry((client) => client.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['verify:evaluate']
              }));
              return;
            }

            core.info(`Found merged PR #${linkedPr.number} for issue #${issueNumber}`);

            const verifyMsg = [
              `ü§ñ **Auto-pilot**: Issue closed.`,
              `Triggering verification on PR #${linkedPr.number}...`,
              '',
              'Adding `verify:evaluate` label to PR.'
            ].join('\n');

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: verifyMsg
            }));

            // Add verify label to the merged PR (this triggers agents-verifier.yml)
            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: linkedPr.number,
              labels: ['verify:evaluate']
            }));

            // Also add to issue for tracking
            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['verify:evaluate']
            }));

      - name: Metrics - End verify timer
        if: always() && steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record verify step
        if: always() && steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.verify_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "verify" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start create-pr timer
        if: steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Create PR
        if: steps.next.outputs.next_step == 'create-pr'
        id: create_pr_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          ISSUE_TITLE: ${{ steps.context.outputs.issue_title }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          MAX_STALL_RETRIES: '5'
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-create-pr',
              capabilities: ['issues:write', 'contents:read']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const issueTitle = process.env.ISSUE_TITLE || `Issue #${issueNumber}`;
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;
            let agentKey = 'codex';
            let branchPrefix = 'codex/issue-';
            try {
              const registryLib = require('./.github/scripts/agent_registry.js');
              const { loadAgentRegistry, getAgentConfig } = registryLib;
              const registry = loadAgentRegistry();
              const defaultAgent = registry.default_agent || agentKey;
              agentKey = String(defaultAgent).trim().toLowerCase() || agentKey;
              const cfg = getAgentConfig(agentKey);
              branchPrefix = String(cfg.branch_prefix || branchPrefix);
            } catch (error) {
              const prefix = 'Failed to load agent registry; defaulting branch prefix:';
              core.warning(`${prefix} ${error.message}`);
            }

            const branchName = `${branchPrefix}${issueNumber}`;
            const maxStallRetries = parseInt(process.env.MAX_STALL_RETRIES || '5');

            // Helper: count consecutive "waiting" comments (stall detection)
            async function countConsecutiveWaits(waitText) {
              const { data: comments } = await withRetry((client) =>
                client.rest.issues.listComments({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  per_page: 100
                })
              );

              // Look at comments in reverse order (newest first)
              const reversed = [...comments].reverse();
              let stallCount = 0;

              for (const comment of reversed) {
                const body = comment.body || '';
                const isStallComment = body.includes('Auto-pilot step') &&
                  body.includes(waitText);
                if (isStallComment) {
                  stallCount++;
                } else if (body.includes('Auto-pilot step')) {
                  // Different auto-pilot step - stop counting
                  break;
                }
              }
              return stallCount;
            }

            // Check if branch exists
            let branchExists = false;
            try {
              await withRetry((client) => client.rest.repos.getBranch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                branch: branchName
              }));
              branchExists = true;
              core.info(`Branch ${branchName} exists`);
            } catch (e) {
              if (e.status === 404) {
                core.info(`Branch ${branchName} does not exist yet`);
              } else {
                throw e;
              }
            }

            if (!branchExists) {
              // Branch not created yet - agent still working
              const stallCount = await countConsecutiveWaits('Waiting for agent to create branch');
              core.info(`Consecutive branch-wait count: ${stallCount}/${maxStallRetries}`);

              if (stallCount >= maxStallRetries) {
                const warnMsg = `Stall: ${stallCount} attempts without branch creation`;
                core.warning(warnMsg);

                await withRetry((client) => client.rest.issues.addLabels({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  labels: ['agents:auto-pilot-pause', 'needs-human']
                }));

                await withRetry((client) => client.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `## ‚ö†Ô∏è Auto-Pilot Stalled

                    **Reason:** Branch was not created after ${stallCount} attempts.

                    Expected branch: \`${branchName}\`

                    **Possible causes:**
                    - Agent failed before branch creation
                    - Workflow dispatch failed silently
                    - Permissions or token issues

                    **To resume:** Remove \`agents:auto-pilot-pause\` and
                    \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
                }));

                const failMsg = `Auto-pilot stalled: ${stallCount} branch creation attempts`;
                core.setFailed(failMsg);
                return;
              }

              // EXPONENTIAL BACKOFF: Wait longer between each retry
              // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
              if (stallCount > 0) {
                const backoffMinutes = Math.pow(2, stallCount);
                const backoffMs = backoffMinutes * 60 * 1000;
                const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
                const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
                const actualMinutes = Math.round(actualBackoffMs / 60000);

                core.info(`Applying branch-creation backoff: waiting ${actualMinutes} minutes`);
                await withRetry((client) => client.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                    body: `ü§ñ **Auto-pilot**: Backoff delay (${actualMinutes}m)

                    Branch not created yet. Attempt ${stallCount + 1}/${maxStallRetries}.
                    Waiting before retry...`
                }));

                // Sleep with exponential backoff
                await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
              }

              const backoffNote = stallCount === 0
                ? ' (no backoff on the first check).'
                : '.';

              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot step ${stepCount}**: Waiting for agent to create branch...

            The agent has been assigned but hasn't created the branch yet.
            Branch expected: \`${branchName}\`

            üìä Branch check attempt: ${stallCount + 1}/${maxStallRetries}

            ‚è≥ Auto-pilot will check again on next trigger${backoffNote}`
              }));
              return;
            }

            const { data: repoInfo } = await withRetry((client) => client.rest.repos.get({
              owner: context.repo.owner,
              repo: context.repo.repo
            }));
            const baseBranch = repoInfo.default_branch;
            if (!baseBranch) {
              core.setFailed('Repository default branch not available');
              return;
            }

            // If a PR already exists for this branch, stop create-pr loop
            try {
              const headRef = `${context.repo.owner}:${branchName}`;
              const { data: existingPrs } = await withRetry((client) => client.rest.pulls.list({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                head: headRef,
                per_page: 1
              }));

              if (existingPrs.length > 0) {
                const pr = existingPrs[0];
                const serverUrl = process.env.GITHUB_SERVER_URL
                  || 'https://github.com';
                const { owner, repo } = context.repo;
                const prUrl = `${serverUrl}/${owner}/${repo}/pull/${pr.number}`;

                await withRetry((client) => client.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ü§ñ **Auto-pilot step ${stepCount}**: PR already exists

            ‚úÖ Found **[PR #${pr.number}](${prUrl})** for branch \`${branchName}\`.

            Auto-pilot will stop creating/dispatching work for this issue. If you want to restart,
            remove and re-add the \`agents:auto-pilot\` label.`
                }));

                try {
                  await withRetry((client) => client.rest.issues.removeLabel({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    name: 'agents:auto-pilot'
                  }));
                } catch (labelError) {
                  core.warning(`Could not remove agents:auto-pilot label: ${labelError?.message}`);
                }

                core.setOutput('stop_autopilot', 'true');
                return;
              }
            } catch (prLookupError) {
              core.warning(`Could not check for existing PRs: ${prLookupError?.message}`);
            }

            // If branch has no commits ahead of base, dispatch the belt worker
            try {
              const { data: comparison } = await withRetry((client) =>
                client.rest.repos.compareCommits({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  base: baseBranch,
                  head: branchName
                })
              );

              if ((comparison.ahead_by || 0) === 0) {
                core.info(`Branch ${branchName} has no commits ahead of ${baseBranch}`);

                // STALL DETECTION: Check how many consecutive "waiting for commits" we've had
                const stallCount = await countConsecutiveWaits('Branch ready, waiting for commits');
                core.info(`Consecutive stall count: ${stallCount}/${maxStallRetries}`);

                if (stallCount >= maxStallRetries) {
                  // Worker failed to produce commits - pause for human review
                  const warnMsg = `Stall: ${stallCount} attempts without commits`;
                  core.warning(warnMsg);

                  await withRetry((client) => client.rest.issues.addLabels({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    labels: ['agents:auto-pilot-pause', 'needs-human']
                  }));

                  await withRetry((client) => client.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    body: `## ‚ö†Ô∏è Auto-Pilot Stalled

            **Reason:** Belt worker failed to generate commits after ${stallCount} attempts.

            Branch \`${branchName}\` exists but the agent has not produced any changes.

            **Possible causes:**
            - Issue requirements are unclear or too complex
            - Agent encountered an error during execution
            - Belt worker workflow failed silently

            **To investigate:**
            1. Check recent workflow runs for belt worker failures
            2. Review the issue requirements for clarity
            3. Check the agent session logs if available

            **To resume:** Remove \`agents:auto-pilot-pause\` and \`needs-human\` labels,
            then re-add \`agents:auto-pilot\`.`
              }));

                  const failMsg = `Auto-pilot stalled: ${stallCount} failed dispatches`;
                  core.setFailed(failMsg);
                  return;
                }

                // EXPONENTIAL BACKOFF: Wait longer between each retry
                // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
                if (stallCount > 0) {
                  const backoffMinutes = Math.pow(2, stallCount);
                  const backoffMs = backoffMinutes * 60 * 1000;
                  const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
                  const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
                  const actualMinutes = Math.round(actualBackoffMs / 60000);

                  core.info(`Applying backoff: waiting ${actualMinutes} minutes`);
                  await withRetry((client) => client.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    body: `ü§ñ **Auto-pilot**: Backoff delay (${actualMinutes}m)

            Attempt ${stallCount + 1}/${maxStallRetries}. Waiting before retry...`
              }));

                  // Sleep with exponential backoff
                  await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
                }

                let workerDispatched = false;
                let dispatchError = null;
                try {
                  await withRetry((client) => client.rest.actions.createWorkflowDispatch({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: 'agents-72-codex-belt-worker-dispatch.yml',
                    ref: baseBranch,
                    inputs: {
                      agent_key: agentKey,
                      issue: issueNumber.toString(),
                      branch: branchName,
                      base: baseBranch,
                      source: 'auto-pilot'
                    }
                  }));
                  workerDispatched = true;
                  core.info(`Dispatched belt worker for issue #${issueNumber}`);
                } catch (err) {
                  dispatchError = err;
                  core.warning(`Could not dispatch belt worker: ${err?.message}`);
                }

                // Build detailed status message
                let dispatchLine;
                if (workerDispatched) {
                  const stallMsg = `${stallCount + 1}/${maxStallRetries}`;
                  dispatchLine = [
                    '‚úÖ Dispatched the belt worker to generate changes.',
                    '',
                    `üìä Stall count: ${stallMsg} (pauses after ${maxStallRetries})`
                  ].join('\n');
                } else {
                  const errorDetail = dispatchError?.message || 'Unknown error';
                  const errorStatus = dispatchError?.status
                    ? ` (HTTP ${dispatchError.status})` : '';
                  dispatchLine = [
                    `‚ùå **Failed to dispatch belt worker**${errorStatus}`,
                    '',
                    `Error: \`${errorDetail}\``,
                    '',
                    '**Troubleshooting:**',
                    '- Check if `agents-72-codex-belt-worker-dispatch.yml` exists',
                    '- Verify workflow permissions allow `actions: write`',
                    '- Check workflow runs in the Actions tab for errors'
                  ].join('\n');
                }

                await withRetry((client) => client.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ü§ñ **Auto-pilot step ${stepCount}**: Branch ready, waiting for commits

            Branch \`${branchName}\` exists but has no commits yet.
            ${dispatchLine}

            ‚è≥ Auto-pilot will check again on next trigger.`
                }));
                return;
              }
            } catch (compareError) {
              const message = compareError?.message || String(compareError);
              core.warning(`Could not compare ${branchName} to ${baseBranch}: ${message}`);
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot step ${stepCount}**: Compare failed

            Could not compare \`${branchName}\` to \`${baseBranch}\`.
            Skipping PR creation for now. Auto-pilot will retry on the next trigger.`
              }));
              return;
            }

            // Branch has commits - create PR
            core.info(`Creating PR from ${branchName}`);

            // Fetch issue body to include in PR
            const { data: issue } = await withRetry((client) => client.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber
            }));

            const prTitle = `[Auto-pilot] ${issueTitle}`;
            const prBody = [
              `<!-- meta:issue:${issueNumber} -->`,
              '',
              `Closes #${issueNumber}`,
              '',
              issue.body || ''
            ].join('\n');

            try {
              const { data: pr } = await withRetry((client) => client.rest.pulls.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: prTitle,
                head: branchName,
                base: baseBranch,
                body: prBody
              }));

              core.info(`Created PR #${pr.number}`);

              // Add standard agent labels to the PR (separate try-catch to not fail PR creation)
              let labelsAdded = false;
              try {
                await withRetry((client) => client.rest.issues.addLabels({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: pr.number,
                  labels: [`agent:${agentKey}`, 'agents:keepalive', 'autofix']
                }));
                labelsAdded = true;
                core.info(`Added agent labels to PR #${pr.number}`);
              } catch (labelError) {
                const errMsg = labelError?.message || String(labelError);
                core.warning(`Failed to add labels to PR #${pr.number}: ${errMsg}`);
              }

              const labelStatus = labelsAdded
                ? `‚úÖ Added labels: \`agent:${agentKey}\`, \`agents:keepalive\`, \`autofix\``
                : '‚ö†Ô∏è Could not add labels (add manually)';

              // Dispatch PR meta workflow to build Automated Status Summary
              // (GITHUB_TOKEN actions do not trigger workflow runs automatically)
              try {
                await withRetry((client) => client.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'agents-pr-meta.yml',
                  ref: baseBranch,
                  inputs: {
                    pr_number: pr.number.toString(),
                    debug: 'false'
                  }
                }));
                core.info(`Dispatched PR meta update for PR #${pr.number}`);
              } catch (dispatchError) {
                core.warning(`Could not dispatch PR meta update: ${dispatchError?.message}`);
              }

              // Dispatch keepalive workflow since GITHUB_TOKEN labels don't trigger it
              try {
                await withRetry((client) => client.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'agents-keepalive-loop.yml',
                  ref: baseBranch,
                  inputs: {
                    pr_number: pr.number.toString(),
                    force_retry: 'true'
                  }
                }));
                core.info(`Dispatched keepalive for PR #${pr.number}`);
              } catch (dispatchError) {
                core.warning(`Could not dispatch keepalive: ${dispatchError?.message}`);
              }

              // Add PR link comment to the issue with full URL for visibility
              // Use GITHUB_SERVER_URL for GHES/AE compatibility instead of hardcoding github.com
              const serverUrl = process.env.GITHUB_SERVER_URL || 'https://github.com';
              const { owner, repo } = context.repo;
              const prUrl = `${serverUrl}/${owner}/${repo}/pull/${pr.number}`;
              const branchUrl = `${serverUrl}/${owner}/${repo}/tree/${branchName}`;

              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot step ${stepCount}**: PR created!

            ‚úÖ Created **[PR #${pr.number}](${prUrl})** from branch [\`${branchName}\`](${branchUrl})
            ${labelStatus}

            üîó **Links:**
            - Pull Request: ${prUrl}
            - Branch: ${branchUrl}

            The PR will now go through CI checks. Auto-pilot will continue monitoring.`
              }));

            } catch (e) {
              if (e.status === 422 && e.message?.includes('already exists')) {
                core.info('PR already exists - this is fine');
              } else {
                // PR creation failed - report but don't fail workflow
                core.warning(`Failed to create PR: ${e.message}`);
                await withRetry((client) => client.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ü§ñ **Auto-pilot step ${stepCount}**: Could not create PR

            ‚ö†Ô∏è Branch \`${branchName}\` exists but PR creation failed.

            Error: ${e.message}

            Please create the PR manually or check permissions.`
                }));
              }
            }

      - name: Metrics - End create-pr timer
        if: always() && steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record create-pr step
        if: always() && steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.create_pr_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "create-pr" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start monitor-pr timer
        if: steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Report - Monitoring PR
        if: steps.next.outputs.next_step == 'monitor-pr'
        id: monitor_pr_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          MAX_STALL_RETRIES: '5'
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-monitor-pr',
              capabilities: ['issues:write', 'contents:read']
            });
            const prNumber = '${{ steps.context.outputs.linked_pr }}';
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;
            const maxStallRetries = parseInt(process.env.MAX_STALL_RETRIES || '5');

            // Helper: count consecutive "monitor-pr" comments (stall detection)
            async function countConsecutiveWaits(waitText) {
              const { data: comments } = await withRetry((client) =>
                client.rest.issues.listComments({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  per_page: 100
                })
              );

              // Look at comments in reverse order (newest first)
              const reversed = [...comments].reverse();
              let stallCount = 0;

              for (const comment of reversed) {
                const body = comment.body || '';
                const isStallComment = body.includes('Auto-pilot step') &&
                  body.includes(waitText);
                if (isStallComment) {
                  stallCount++;
                } else if (body.includes('Auto-pilot step')) {
                  // Different auto-pilot step - stop counting
                  break;
                }
              }
              return stallCount;
            }

            const stallCount = await countConsecutiveWaits('Monitoring PR status');
            core.info(`Consecutive monitor-pr count: ${stallCount}/${maxStallRetries}`);

            if (stallCount >= maxStallRetries) {
              const warnMsg = `Stall: ${stallCount} monitor-pr attempts without completion`;
              core.warning(warnMsg);

              await withRetry((client) => client.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['agents:auto-pilot-pause', 'needs-human']
              }));

              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `## ‚ö†Ô∏è Auto-Pilot Stalled

            **Reason:** PR monitoring exceeded ${stallCount} attempts without completion.

            PR #${prNumber} exists but auto-pilot did not reach a completion state.

            **To resume:** Remove \`agents:auto-pilot-pause\` and
            \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
              }));

              core.setOutput('stop_autopilot', 'true');
              core.setFailed(warnMsg);
              return;
            }

            // EXPONENTIAL BACKOFF: Wait longer between each retry
            // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
            if (stallCount > 0) {
              const backoffMinutes = Math.pow(2, stallCount);
              const backoffMs = backoffMinutes * 60 * 1000;
              const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
              const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
              const actualMinutes = Math.round(actualBackoffMs / 60000);

              core.info(`Applying monitor-pr backoff: waiting ${actualMinutes} minutes`);
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot**: Backoff delay (${actualMinutes}m)

            Monitoring PR status. Attempt ${stallCount + 1}/${maxStallRetries}.
            Waiting before retry...`
              }));

              // Sleep with exponential backoff
              await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
            }

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ü§ñ **Auto-pilot step ${stepCount}**: Monitoring PR status

            PR #${prNumber} exists. Keepalive and autofix will handle CI.

            üìä Stall count: ${stallCount + 1}/${maxStallRetries}

            ‚è≥ Auto-pilot will check again on next trigger.`
            }));

      - name: Metrics - End monitor-pr timer
        if: always() && steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record monitor-pr step
        if: always() && steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.monitor_pr_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "monitor-pr" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start check-completion timer
        if: steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python scripts/autopilot_step_timer.py --event start --format epoch-ms --github-env

      - name: Execute step - Check Completion & Trigger Merge
        if: steps.next.outputs.next_step == 'check-completion'
        id: completion_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          PR_NUMBER: ${{ steps.context.outputs.linked_pr }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-check-completion',
              capabilities: ['issues:write', 'contents:read']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const prNumber = parseInt(process.env.PR_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;

            // Get PR details to check CI status
            const { data: pr } = await withRetry((client) => client.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber
            }));

            // Check if PR is mergeable
            if (pr.mergeable !== true) {
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot step ${stepCount}**: PR completion check

            ‚ö†Ô∏è PR #${prNumber} is not mergeable or its mergeability is still being computed.

            Auto-pilot cannot proceed with merge. Manual intervention may be required.`
              }));
              return;
            }

            // Check CI status
            let checksPass = true;
            try {
              const { data: checks } = await withRetry((client) => client.rest.checks.listForRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: pr.head.sha
              }));

              const pendingChecks = checks.check_runs.filter(check =>
                check.status !== 'completed'
              );
              const failedChecks = checks.check_runs.filter(check =>
                check.status === 'completed' && check.conclusion !== 'success' &&
                check.conclusion !== 'neutral' && check.conclusion !== 'skipped'
              );

              if (failedChecks.length > 0 || pendingChecks.length > 0) {
                checksPass = false;
              }
            } catch (e) {
              core.warning(`Could not check CI status: ${e.message}`);
            }

            if (!checksPass) {
              await withRetry((client) => client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ü§ñ **Auto-pilot step ${stepCount}**: PR completion check

            ‚ö†Ô∏è PR #${prNumber} has failing CI checks.

            Auto-pilot will wait for checks to pass before merging.`
              }));
              return;
            }

            // All checks pass - add automerge label
            await withRetry((client) => client.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              labels: ['automerge']
            }));

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ü§ñ **Auto-pilot step ${stepCount}**: PR ready for merge!

            ‚úÖ All tasks completed
            ‚úÖ CI checks passing
            ‚úÖ No merge conflicts

            Added \`automerge\` label to PR #${prNumber}. The orchestrator will merge it shortly.`
            }));

            core.info(`PR #${prNumber} ready for automerge - added label`);

      - name: Metrics - End check-completion timer
        if: always() && steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python scripts/autopilot_step_timer.py --event end --format epoch-ms --github-env

      - name: Metrics - Record check-completion step
        if: always() && steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.completion_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python scripts/autopilot_metrics_collector.py \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "check-completion" \
            --success "$success" \
            --failure-reason "$failure_reason"

      # ‚îÄ‚îÄ Upload auto-pilot metrics for weekly aggregation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Upload auto-pilot metrics
        if: always()
        uses: actions/upload-artifact@v6
        continue-on-error: true
        with:
          name: autopilot-metrics-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
          retention-days: 14
          if-no-files-found: ignore

      # Re-dispatch workflow to continue pipeline after prep steps
      # GitHub prevents recursive triggers on labels added by GITHUB_TOKEN
      - name: Re-dispatch for next step
        if: |
          steps.context.outputs.should_continue == 'true' &&
          steps.cycles.outputs.exceeded != 'true' &&
          steps.format_step.outputs.stop_autopilot != 'true' &&
          steps.optimize_step.outputs.stop_autopilot != 'true' &&
          steps.apply_step.outputs.stop_autopilot != 'true' &&
          steps.create_pr_step.outputs.stop_autopilot != 'true' &&
          steps.monitor_pr_step.outputs.stop_autopilot != 'true' &&
          contains(
            fromJSON('["format","optimize","apply","capability-check","create-pr","monitor-pr"]'),
            steps.next.outputs.next_step
          )
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          CURRENT_STEP: ${{ steps.next.outputs.next_step }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-redispatch',
              capabilities: ['contents:read', 'actions:write']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const currentStep = process.env.CURRENT_STEP;
            const { data: repoInfo } = await withRetry((client) => client.rest.repos.get({
              owner: context.repo.owner,
              repo: context.repo.repo
            }));
            const baseBranch = repoInfo.default_branch;
            if (!baseBranch) {
              core.setFailed('Repository default branch not available');
              return;
            }

            // Determine next step explicitly to avoid label race conditions
            // Don't rely on 'auto' detection which has API cache timing issues
            const nextStepMap = {
              'format': 'optimize',
              'optimize': 'apply',
              'apply': 'capability-check',
              'capability-check': 'auto',  // Let it detect agent/PR state
              'create-pr': 'auto',  // Re-evaluate after branch/PR creation
              'monitor-pr': 'auto'  // Let it check PR completion
            };
            const nextStep = nextStepMap[currentStep] || 'auto';

            // For monitor-pr or create-pr, add delay to avoid tight polling loops
            // Keepalive updates and branch creation can take time; without delay
            // we'd spam Actions with rapid re-dispatches
            if (currentStep === 'monitor-pr' || currentStep === 'create-pr') {
              const waitTime = currentStep === 'monitor-pr' ? 120000 : 60000;
              core.info(`Waiting ${waitTime/1000}s before re-dispatch...`);
              await new Promise(resolve => setTimeout(resolve, waitTime));
            }
            // Other steps dispatch immediately - explicit force_step
            // eliminates label dependency, no wait needed

            core.info(
              `Re-dispatching auto-pilot: issue #${issueNumber}, ` +
              `next_step=${nextStep}`
            );
            await withRetry((client) => client.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'agents-auto-pilot.yml',
              ref: baseBranch,
              inputs: {
                issue_number: issueNumber.toString(),
                force_step: nextStep
              }
            }));

            // Verify the dispatch was accepted by checking for a new run
            // createWorkflowDispatch returns 204 (no content) so we poll briefly
            let dispatchVerified = false;
            const runIdBefore = context.runId;
            for (let attempt = 0; attempt < 3; attempt++) {
              await new Promise(resolve => setTimeout(resolve, 5000));
              try {
                const { data: runs } = await withRetry(
                  (client) => client.rest.actions.listWorkflowRuns({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: 'agents-auto-pilot.yml',
                    per_page: 5,
                    status: 'queued'
                  })
                );
                const newRun = (runs.workflow_runs || []).find(
                  r => r.id !== runIdBefore
                );
                if (newRun) {
                  dispatchVerified = true;
                  core.info(`Dispatch verified: new run #${newRun.id} (${newRun.status})`);
                  break;
                }
              } catch (e) {
                core.warning(`Dispatch verification check failed: ${e.message}`);
              }
            }
            if (!dispatchVerified) {
              core.warning(
                `Could not verify dispatch for issue #${issueNumber} ` +
                `(step: ${nextStep}). The run may still start ‚Äî ` +
                `check Actions tab manually if pipeline stalls.`
              );
            }

            core.info(
              `Re-dispatched for issue #${issueNumber} after ` +
              `${currentStep} step (next: ${nextStep})`
            );

      - name: Report - Done
        if: steps.next.outputs.next_step == 'done'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'auto-pilot-report-done',
              capabilities: ['issues:write', 'contents:read']
            });
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Remove auto-pilot label since we're done
            try {
              await withRetry((client) => client.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                name: 'agents:auto-pilot'
              }));
            } catch (e) {
              // Label might already be removed (404) - that's OK
              if (e && e.status === 404) {
                core.info('Auto-pilot label already removed or not found');
              } else {
                core.warning(`Unexpected error removing auto-pilot label: ${e?.message || e}`);
              }
            }

            await withRetry((client) => client.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `## ‚úÖ Auto-Pilot Complete

            This issue has been fully processed:
            - ‚úÖ Issue formatted and optimized
            - ‚úÖ Agent assigned and PR created
            - ‚úÖ PR merged
            - ‚úÖ Verification triggered

            Thank you for using auto-pilot! üöÄ`
            }));

            core.info('Auto-pilot complete!');
