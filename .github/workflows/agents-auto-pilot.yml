# See docs/ci/AGENTS_POLICY.md for guardrails and override process.
name: Agents Auto-Pilot

# End-to-end automation: Issue â†’ Format â†’ Optimize â†’ Apply â†’ Agent â†’ Keepalive â†’ Merge
# Triggered by:
# 1. agents:auto-pilot label (initial trigger)
# 2. Issue/PR closed events (for verification)
# 3. Manual dispatch (for testing/recovery)

on:
  issues:
    types: [labeled, closed]
  pull_request:
    types: [labeled, closed]
  # Note: Optimizer now runs inline in auto-pilot, not as separate workflow
  # workflow_run trigger removed to eliminate race conditions
  # If needed for other child workflows, add them here specifically
  workflow_dispatch:
    inputs:
      issue_number:
        description: "Issue number to auto-pilot"
        required: true
        type: string
      force_step:
        description: "Force a specific step (optional, leave as 'auto' for normal flow)"
        required: false
        type: choice
        options:
          - auto
          - format
          - optimize
          - apply
          - capability-check
          - agent
          - verify

permissions:
  contents: read
  issues: write
  pull-requests: write  # Needed to create PRs automatically
  actions: write  # Needed for workflow re-dispatch
  models: read

env:
  # Safety limits
  MAX_CYCLES: 10
  MAX_WALL_TIME_HOURS: 4
  AUTOPILOT_METRICS_LOG_PATH: .agents/autopilot-metrics.ndjson
  AUTOPILOT_METRICS_SUMMARY_PATH: .agents/autopilot-metrics-summary.ndjson
  LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
  LANGCHAIN_TRACING_V2: "true"
  LANGCHAIN_PROJECT: workflows-agents

concurrency:
  group: >-
    agents-auto-pilot-${{ github.repository }}-${{
      github.event.issue.number || github.event.inputs.issue_number || github.run_id
    }}
  cancel-in-progress: false

jobs:
  auto-pilot:
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 4 hours = MAX_WALL_TIME_HOURS
    # Trigger on:
    # 1. agents:auto-pilot label added (starts the automation)
    # 2. Issue/PR closed (verification trigger)
    # 3. workflow_dispatch (manual trigger)
    # NOTE: Optimizer and formatter now run INLINE, not as separate workflows
    # This eliminates race conditions and workflow_run complexity
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.action == 'labeled' && (
        github.event.label.name == 'agents:auto-pilot' ||
        github.event.label.name == 'agent:codex' ||
        contains(github.event.issue.labels.*.name, 'agents:auto-pilot') ||
        contains(github.event.issue.labels.*.name, 'agent:codex') ||
        contains(github.event.pull_request.labels.*.name, 'agents:auto-pilot') ||
        contains(github.event.pull_request.labels.*.name, 'agent:codex')
      )) ||
      (github.event.action == 'closed' &&
       contains(github.event.issue.labels.*.name, 'agents:auto-pilot'))

    steps:
      - name: Check if auto-pilot is enabled
        id: check_enabled
        uses: actions/github-script@v8
        with:
          script: |
            // Handle different event types
            if (context.eventName === 'workflow_dispatch') {
              core.setOutput('enabled', 'true');
              return;
            }

            // For label events, verify auto-pilot is enabled
            const labelName = context.payload.label?.name || '';

            // Get issue/PR to check for agents:auto-pilot label
            let labels = [];
            if (context.payload.issue) {
              labels = context.payload.issue.labels.map(l => l.name);
            } else if (context.payload.pull_request) {
              labels = context.payload.pull_request.labels.map(l => l.name);
            }

            const hasAutoPilot = labels.includes('agents:auto-pilot') || labels.includes('agent:codex');
            const isAutoPilotTrigger = labelName === 'agents:auto-pilot' || labelName === 'agent:codex';
            if (!hasAutoPilot && !isAutoPilotTrigger) {
              core.info(`Skipping: auto-pilot not enabled (trigger: ${labelName})`);
              core.setOutput('enabled', 'false');
              return;
            }

            core.setOutput('enabled', 'true');

      - name: Checkout repository
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/checkout@v6

      - name: Export load balancer tokens
        uses: ./.github/actions/export-load-balancer-tokens
        with:
          github_token: ${{ github.token }}
          token_rotation_json: ${{ secrets.TOKEN_ROTATION_JSON }}
          token_rotation_env_keys: ${{ vars.TOKEN_ROTATION_ENV_KEYS }}
      - name: Resolve Workflows default branch
        if: steps.check_enabled.outputs.enabled == 'true'
        id: workflows_ref
        uses: actions/github-script@v8
        with:
          script: |
            const { data } = await github.rest.repos.get({
              owner: 'stranske',
              repo: 'Workflows'
            });
            if (!data?.default_branch) {
              core.setFailed('Could not determine Workflows default branch');
              return;
            }
            core.setOutput('ref', data.default_branch);

      - name: Checkout Workflows scripts
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/checkout@v6
        with:
          repository: stranske/Workflows
          ref: ${{ steps.workflows_ref.outputs.ref }}
          sparse-checkout: |
            .github/actions/export-load-balancer-tokens
            .github/scripts
            scripts
          sparse-checkout-cone-mode: false
          path: workflows-lib
          fetch-depth: 1

      - name: Set scripts path
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          echo "WORKFLOWS_SCRIPTS_PATH=${GITHUB_WORKSPACE}/workflows-lib" >> "$GITHUB_ENV"

      - name: Set up Python
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          # Install langchain dependencies for inline optimizer
          pip install langchain langchain-core langchain-openai langchain-community

      - name: Initialize auto-pilot metrics logs
        if: steps.check_enabled.outputs.enabled == 'true'
        run: |
          mkdir -p .agents

      - name: Determine context
        if: steps.check_enabled.outputs.enabled == 'true'
        id: context
        uses: actions/github-script@v8
        with:
          script: |
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { withRetry, paginateWithRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );

            let issueNumber, issue, pr;

            // Get issue number from various sources (in priority order)
            if (context.eventName === 'workflow_dispatch') {
              issueNumber = parseInt('${{ inputs.issue_number }}');
            } else if (context.payload.issue) {
              issueNumber = context.payload.issue.number;
              issue = context.payload.issue;
            } else if (context.payload.pull_request) {
              // For PR events, find linked issue
              pr = context.payload.pull_request;
              const bodyMatch = pr.body?.match(/#(\d+)/);
              issueNumber = bodyMatch ? parseInt(bodyMatch[1]) : null;
            }

            if (!issueNumber) {
              core.setFailed('Could not determine issue number');
              return;
            }

            // Fetch issue if not in payload (with retry)
            if (!issue) {
              const { data } = await withRetry(() =>
                github.rest.issues.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber
                })
              );
              issue = data;
            }

            const labels = issue.labels.map(l => l.name);

            // Check for pause label
            if (labels.includes('agents:auto-pilot-pause')) {
              core.info('Auto-pilot paused by agents:auto-pilot-pause label');
              core.setOutput('should_continue', 'false');
              core.setOutput('reason', 'paused');
              return;
            }

            // Check for failure/needs-human
            if (labels.includes('needs-human') || labels.includes('agents:auto-pilot-failed')) {
              core.info('Auto-pilot stopped: requires human intervention');
              core.setOutput('should_continue', 'false');
              core.setOutput('reason', 'needs-human');
              return;
            }

            // Determine current state based on labels
            // NOTE: Use 'agents:formatted' (completion marker) not 'agents:format' (old trigger)
            const hasFormat = labels.includes('agents:formatted');
            const hasOptimize = labels.includes('agents:optimize');
            const hasApplySuggestions = labels.includes('agents:apply-suggestions');
            const hasAgentCodex = labels.includes('agent:codex');
            const hasAutofix = labels.includes('autofix');
            const hasAutomerge = labels.includes('automerge');
            const hasVerify = labels.includes('verify:evaluate');

            // Check for actual optimizer output (not just label)
            // Since we run optimizer inline now, this should always exist after optimize step
            // the optimizer workflow actually completed its work
            const comments = await paginateWithRetry(
              github,
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            const hasOptimizerOutput = comments.some(c => {
              const body = c.body || '';
              return body.includes('Issue Optimization Suggestions') ||
                     body.includes('ISSUE_OPTIMIZER_SUGGESTIONS') ||
                     body.includes('## ðŸ“‹ Optimization Suggestions');
            });

            // Check for linked PR (with pagination and multiple event types)
            const timelineEvents = await paginateWithRetry(
              github,
              github.rest.issues.listEventsForTimeline,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            function matchesIssueReference(text, num) {
              if (!text) return false;
              const pattern = new RegExp(
                `\\b(close[sd]?|fixe?[sd]?|resolve[sd]?)\\s+#${num}\\b`,
                'i'
              );
              return pattern.test(text);
            }

            let linkedPR = null;
            for (const event of timelineEvents) {
              // Handle both cross-referenced and connected events
              const isCrossRef = event.event === 'cross-referenced';
              const isConnected = event.event === 'connected';
              const sourceIssue = event.source?.issue;
              const repoMatch = sourceIssue?.repository?.full_name ===
                `${context.repo.owner}/${context.repo.repo}`;
              if ((isCrossRef || isConnected) && repoMatch && sourceIssue?.pull_request) {
                const prBody = sourceIssue.body || '';
                const prTitle = sourceIssue.title || '';
                const hasMeta = prBody.includes(`meta:issue:${issueNumber}`);
                const hasReference = matchesIssueReference(prBody, issueNumber) ||
                  matchesIssueReference(prTitle, issueNumber);
                if (hasMeta || hasReference) {
                  linkedPR = sourceIssue.number;
                }
              }
            }

            core.setOutput('issue_number', issueNumber);
            core.setOutput('issue_title', issue.title);
            core.setOutput('issue_state', issue.state);
            core.setOutput('should_continue', 'true');
            core.setOutput('has_format', hasFormat.toString());
            core.setOutput('has_optimize', hasOptimize.toString());
            core.setOutput('has_optimizer_output', hasOptimizerOutput.toString());
            core.setOutput('has_apply', hasApplySuggestions.toString());
            core.setOutput('has_agent', hasAgentCodex.toString());
            core.setOutput('has_autofix', hasAutofix.toString());
            core.setOutput('has_automerge', hasAutomerge.toString());
            core.setOutput('has_verify', hasVerify.toString());
            core.setOutput('linked_pr', linkedPR || '');

            console.log(`Issue #${issueNumber} state:`);
            console.log(`  State: ${issue.state}`);
            console.log(`  Labels: ${labels.join(', ')}`);
            console.log(`  Optimizer output: ${hasOptimizerOutput}`);
            console.log(`  Linked PR: ${linkedPR || 'none'}`);

      - name: Check step count
        if: steps.context.outputs.should_continue == 'true'
        id: cycles
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { paginateWithRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Get all comments to count auto-pilot steps (with pagination and retry)
            const allComments = await paginateWithRetry(
              github,
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            const stepComments = allComments.filter(c =>
              typeof c.body === 'string' && c.body.includes('ðŸ¤– Auto-pilot step')
            );

            const stepCount = stepComments.length;
            const maxCycles = parseInt('${{ env.MAX_CYCLES }}');

            if (stepCount >= maxCycles) {
              core.warning(`Auto-pilot exceeded max steps (${stepCount}/${maxCycles})`);
              core.setOutput('exceeded', 'true');
              return;
            }

            core.setOutput('exceeded', 'false');
            core.setOutput('count', stepCount.toString());

      - name: Stop if exceeded
        if: steps.cycles.outputs.exceeded == 'true'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Add failure label and comment
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['needs-human', 'agents:auto-pilot-failed']
            });

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `## âš ï¸ Auto-Pilot Stopped

            **Reason:** Exceeded maximum cycle limit (${{ env.MAX_CYCLES }} cycles)

            This issue requires human review. Possible causes:
            - Repeated CI failures
            - Conflicting requirements
            - External dependencies

            **To resume:** Remove \`agents:auto-pilot-failed\` and
            \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
            });

            core.setFailed('Auto-pilot exceeded max cycles');

      - name: Determine next step
        if: |
          steps.context.outputs.should_continue == 'true' &&
          steps.cycles.outputs.exceeded != 'true'
        id: next
        env:
          FORCE_STEP: ${{ inputs.force_step }}
        run: |
          # Priority order of steps
          # 1. If issue closed and has verify label â†’ done
          # 2. If issue closed without verify â†’ add verify
          # 3. If no PR â†’ need agent assignment
          # 4. If has PR â†’ check PR state
          # 5. If no format â†’ format first
          # 6. If no optimize label â†’ trigger optimize
          # 7. If optimize label but no output â†’ wait (optimizer still running)
          # 8. If has optimizer output but no apply â†’ apply suggestions

          ISSUE_STATE="${{ steps.context.outputs.issue_state }}"
          HAS_FORMAT="${{ steps.context.outputs.has_format }}"
          HAS_OPTIMIZE="${{ steps.context.outputs.has_optimize }}"
          HAS_OPTIMIZER_OUTPUT="${{ steps.context.outputs.has_optimizer_output }}"
          HAS_APPLY="${{ steps.context.outputs.has_apply }}"
          HAS_AGENT="${{ steps.context.outputs.has_agent }}"
          LINKED_PR="${{ steps.context.outputs.linked_pr }}"
          HAS_VERIFY="${{ steps.context.outputs.has_verify }}"

          # Force step if specified (not 'auto')
          if [[ -n "$FORCE_STEP" && "$FORCE_STEP" != "auto" ]]; then
            echo "next_step=$FORCE_STEP" >> "$GITHUB_OUTPUT"
            echo "Forced step: $FORCE_STEP"
            exit 0
          fi

          # Issue closed = done or verify
          if [[ "$ISSUE_STATE" == "closed" ]]; then
            if [[ "$HAS_VERIFY" == "true" ]]; then
              echo "next_step=done" >> "$GITHUB_OUTPUT"
              echo "Issue closed with verification - auto-pilot complete"
            else
              echo "next_step=verify" >> "$GITHUB_OUTPUT"
              echo "Issue closed - triggering verification"
            fi
            exit 0
          fi

          # No PR yet - need to go through issue prep pipeline
          if [[ -z "$LINKED_PR" ]]; then
            if [[ "$HAS_FORMAT" != "true" ]]; then
              echo "next_step=format" >> "$GITHUB_OUTPUT"
              echo "Step 1: Format issue"
            elif [[ "$HAS_OPTIMIZER_OUTPUT" != "true" ]]; then
              # Run optimizer inline (not via label)
              echo "next_step=optimize" >> "$GITHUB_OUTPUT"
              echo "Step 2: Run optimizer (inline)"
            elif [[ "$HAS_APPLY" != "true" ]]; then
              echo "next_step=apply" >> "$GITHUB_OUTPUT"
              echo "Step 3: Apply suggestions"
            elif [[ "$HAS_AGENT" != "true" ]]; then
              echo "next_step=capability-check" >> "$GITHUB_OUTPUT"
              echo "Step 4: Run capability check and assign agent"
            else
              echo "next_step=create-pr" >> "$GITHUB_OUTPUT"
              echo "Step 5: All prep complete, checking for branch to create PR"
            fi
            exit 0
          fi

          # Has PR - check if it's complete and ready to merge
          # Get PR state to see if keepalive has finished
          if ! PR_STATE=$(gh api "/repos/${{ github.repository }}/issues/$LINKED_PR/comments" \
            --jq '.[] | select(.body | contains("keepalive-state:")) | .body' 2>&1 | tail -1); then
            echo "âš ï¸ Failed to fetch PR state, defaulting to monitor-pr"
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Check if we got any state data
          if [ -z "$PR_STATE" ]; then
            echo "No keepalive state found, defaulting to monitor-pr"
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Check if keepalive marked tasks as complete
          if echo "$PR_STATE" | grep -q '"last_action":"stop"' && \
             echo "$PR_STATE" | grep -q '"last_reason":"tasks-complete"'; then
            echo "next_step=check-completion" >> "$GITHUB_OUTPUT"
            echo "Step 6.5: PR tasks complete - checking for merge"
          else
            echo "next_step=monitor-pr" >> "$GITHUB_OUTPUT"
            echo "PR #$LINKED_PR exists - monitoring via keepalive"
          fi
          exit 0

      - name: Metrics - Start format timer
        if: steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Format (inline)
        if: steps.next.outputs.next_step == 'format'
        id: format_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          ISSUE_NUMBER="$ISSUE_NUMBER"
          STEP_COUNT="$STEP_COUNT"

          # Post progress comment
          gh issue comment "${ISSUE_NUMBER}" --body \
            "ðŸ¤– **Auto-pilot step $((STEP_COUNT + 1))**: Starting issue formatting...

          Running formatter inline (not via label trigger)."

          # Get issue body
          gh api "repos/${{ github.repository }}/issues/${ISSUE_NUMBER}" > /tmp/issue.json
          jq -r '.body' /tmp/issue.json > /tmp/issue_body.md

          # Format the issue
          echo "Formatting issue into AGENT_ISSUE_TEMPLATE structure..."
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/langchain/issue_formatter.py" \
            --input-file /tmp/issue_body.md \
            --json > /tmp/format_result.json

          # Extract and apply formatted body
          python -c "
          import json
          with open('/tmp/format_result.json') as f:
              result = json.load(f)
          formatted = result.get('formatted_body', '')
          if not formatted:
              print('ERROR: No formatted body returned')
              import sys
              sys.exit(1)
          with open('/tmp/formatted_body.md', 'w') as f:
              f.write(formatted)
          print('Issue formatted successfully')
          " || exit 1

          # Update issue body
          gh issue edit "${ISSUE_NUMBER}" --body-file /tmp/formatted_body.md

          # Add marker labels (but don't trigger workflow)
          gh issue edit "${ISSUE_NUMBER}" --add-label "agents:formatted" || true
          gh issue edit "${ISSUE_NUMBER}" --add-label "agents:apply-suggestions" || true

          echo "âœ… Formatting complete - continuing to next step"

      - name: Metrics - End format timer
        if: always() && steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record format step
        if: always() && steps.next.outputs.next_step == 'format'
        env:
          AUTOPILOT_STEP_NAME: format
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.format_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "format" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start optimize timer
        if: steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Optimize (inline)
        if: steps.next.outputs.next_step == 'optimize'
        id: optimize_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          ISSUE_NUMBER="$ISSUE_NUMBER"
          STEP_COUNT="$STEP_COUNT"

          # Post progress comment
          gh issue comment "${ISSUE_NUMBER}" --body \
            "ðŸ¤– **Auto-pilot step $((STEP_COUNT + 1))**: Analyzing issue for improvements...

          Running optimizer inline (not via label trigger)."

          # Get issue body
          gh api "repos/${{ github.repository }}/issues/${ISSUE_NUMBER}" > /tmp/issue.json
          jq -r '.body' /tmp/issue.json > /tmp/issue_body.md

          # Run optimizer analysis
          echo "Running optimization analysis..."
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/langchain/issue_optimizer.py" \
            --input-file /tmp/issue_body.md \
            --json > /tmp/suggestions.json

          # Format and post comment
          python -c "
          import json
          import sys
          sys.path.insert(0, 'scripts/langchain')
          from issue_optimizer import IssueOptimizationResult, format_suggestions_comment

          with open('/tmp/suggestions.json') as f:
              data = json.load(f)

          result = IssueOptimizationResult(
              task_splitting=data.get('task_splitting', []),
              blocked_tasks=data.get('blocked_tasks', []),
              objective_criteria=data.get('objective_criteria', []),
              missing_sections=data.get('missing_sections', []),
              formatting_issues=data.get('formatting_issues', []),
              overall_notes=data.get('overall_notes', ''),
              provider_used=data.get('provider_used')
          )

          comment = format_suggestions_comment(result)
          with open('/tmp/comment.md', 'w') as f:
              f.write(comment)
          " || {
            echo "Failed to format comment, using raw JSON"
            cat /tmp/suggestions.json > /tmp/comment.md
          }

          # Post suggestions comment
          gh issue comment "${ISSUE_NUMBER}" --body-file /tmp/comment.md

          # Add marker labels (but don't trigger workflow)
          gh issue edit "${ISSUE_NUMBER}" --add-label "agents:formatted" || true
          gh issue edit "${ISSUE_NUMBER}" --add-label "agents:apply-suggestions" || true

          echo "âœ… Optimization complete - continuing to next step"

      - name: Metrics - End optimize timer
        if: always() && steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record optimize step
        if: always() && steps.next.outputs.next_step == 'optimize'
        env:
          AUTOPILOT_STEP_NAME: optimize
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.optimize_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "optimize" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Guard - Require optimizer output before apply
        if: steps.next.outputs.next_step == 'apply'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            // Guard: Verify optimizer produced suggestions before applying
            // This prevents silent failures when optimizer runs but produces no output
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Fetch all comments on the issue (with pagination and retry)
            const scriptsPath = process.env.WORKFLOWS_SCRIPTS_PATH || process.env.GITHUB_WORKSPACE;
            const { paginateWithRetry } = require(
              `${scriptsPath}/.github/scripts/github-api-with-retry.js`
            );
            const comments = await paginateWithRetry(
              github,
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              }
            );

            // Look for optimizer suggestions marker
            // The optimizer workflow posts a comment containing "Issue Optimization Suggestions"
            // or the hidden marker "ISSUE_OPTIMIZER_SUGGESTIONS"
            const hasOptimizerOutput = comments.some(comment => {
              const body = comment.body || '';
              return body.includes('Issue Optimization Suggestions') ||
                     body.includes('ISSUE_OPTIMIZER_SUGGESTIONS') ||
                     body.includes('## ðŸ“‹ Optimization Suggestions');
            });

            if (!hasOptimizerOutput) {
              // No optimizer output found - this is a bug in the pipeline
              core.warning('âš ï¸ Optimizer was supposed to run but produced no suggestions comment');

              // Post warning comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `âš ï¸ **Auto-pilot warning**: Optimizer step completed but no suggestions found.

            This usually means the optimizer workflow was triggered but failed silently.

            **Next steps:**
            1. Check the \`agents-issue-optimizer.yml\` workflow runs
            2. Look for error messages in workflow logs
            3. Remove \`agents:auto-pilot-pause\` and \`needs-human\` labels to retry

            **For maintainers:** Issue paused pending investigation of optimizer failure.`
              });

              // Add pause and needs-human labels
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['agents:auto-pilot-pause', 'needs-human']
              });

              core.setFailed('Optimizer produced no output - pausing for investigation');
            } else {
              core.info('âœ… Optimizer output found - proceeding with apply step');
            }

      - name: Metrics - Start apply timer
        if: steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Apply suggestions (inline)
        if: steps.next.outputs.next_step == 'apply'
        id: apply_step
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          ISSUE_NUMBER="$ISSUE_NUMBER"
          STEP_COUNT="$STEP_COUNT"

          # Post progress comment
          gh issue comment "${ISSUE_NUMBER}" --body \
            "ðŸ¤– **Auto-pilot step $((STEP_COUNT + 1))**: Applying optimization suggestions...

          Running apply inline (not via label trigger)."

          # Get issue body and comments
          gh api "repos/${{ github.repository }}/issues/${ISSUE_NUMBER}" > /tmp/issue.json
          jq -r '.body' /tmp/issue.json > /tmp/issue_body.md
          gh api "repos/${{ github.repository }}/issues/${ISSUE_NUMBER}/comments" \
            --paginate > /tmp/comments.json

          # Extract and apply suggestions
          python -c "
          import json
          import sys
          import re
          sys.path.insert(0, 'scripts/langchain')
          from issue_optimizer import _extract_suggestions_json, apply_suggestions

          with open('/tmp/comments.json') as f:
              comments = json.load(f)

          suggestions = None
          for comment in comments:
              body = comment.get('body', '')
              extracted = _extract_suggestions_json(body)
              if extracted:
                  suggestions = extracted
                  break

          if not suggestions:
              print('ERROR: No suggestions JSON found in comments')
              sys.exit(1)

          # Read current issue body
          with open('/tmp/issue_body.md') as f:
              issue_body = f.read()

          # Apply suggestions
          result = apply_suggestions(issue_body, suggestions, use_llm=False)

          with open('/tmp/updated_body.md', 'w') as f:
              f.write(result['formatted_body'])

          print('Suggestions applied successfully')
          " || exit 1

          # Update issue body
          gh issue edit "${ISSUE_NUMBER}" --body-file /tmp/updated_body.md

          # Add marker label (but don't trigger workflow)
          gh issue edit "${ISSUE_NUMBER}" --add-label "agents:formatted" || true

          echo "âœ… Apply complete - continuing to next step"

      - name: Metrics - End apply timer
        if: always() && steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record apply step
        if: always() && steps.next.outputs.next_step == 'apply'
        env:
          AUTOPILOT_STEP_NAME: apply
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.apply_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "apply" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start capability check timer
        if: steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Capability check & Agent
        if: steps.next.outputs.next_step == 'capability-check'
        id: capability_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Issue prepared! Assigning to agent...

            Adding \`agent:codex\` label. The capability check will run automatically.

            â³ Agent will create a PR shortly.`
            });

            // Add agent label - capability check triggers on this
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['agent:codex']
            });

            let baseBranch = context.payload?.repository?.default_branch || '';
            if (!baseBranch) {
              try {
                const { data: repoInfo } = await github.rest.repos.get({
                  owner: context.repo.owner,
                  repo: context.repo.repo
                });
                baseBranch = repoInfo?.default_branch || '';
              } catch (error) {
                core.warning(`Failed to resolve default branch: ${error?.message || error}`);
              }
            }
            if (!baseBranch) {
              core.warning('Repository default branch not available; skipping belt dispatch.');
              return;
            }

            // Force-dispatch Codex belt dispatcher to create the branch
            try {
              await github.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'agents-71-codex-belt-dispatcher.yml',
                ref: baseBranch,
                inputs: {
                  force_issue: issueNumber.toString(),
                  dry_run: 'false'
                }
              });
              core.info(`Dispatched codex belt dispatcher for issue #${issueNumber}`);
            } catch (dispatchError) {
              core.warning(`Could not dispatch codex belt dispatcher: ${dispatchError?.message}`);
            }

      - name: Metrics - End capability check timer
        if: always() && steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record capability check step
        if: always() && steps.next.outputs.next_step == 'capability-check'
        env:
          AUTOPILOT_STEP_NAME: capability-check
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.capability_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "capability-check" \
            --success "$success" \
            --failure-reason "$failure_reason"
      - name: Metrics - Start verify timer
        if: steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Verify
        if: steps.next.outputs.next_step == 'verify'
        id: verify_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Find the merged PR for this issue
            // Look for PRs with the meta marker or explicit closing reference
            const { data: prs } = await github.rest.pulls.list({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'closed',
              sort: 'updated',
              direction: 'desc',
              per_page: 100
            });

            // Helper to detect explicit closing/fixing references to this issue
            function matchesIssueReference(text, num) {
              if (!text) return false;
              // Match: closes #123, fixes #123, resolves #123 (and variations)
              const pattern = new RegExp(
                `\\b(close[sd]?|fixe?[sd]?|resolve[sd]?)\\s+#${num}\\b`, 'i'
              );
              return pattern.test(text);
            }

            // Find PR that references this issue
            const linkedPr = prs.find(pr =>
              pr.merged_at && (
                pr.body?.includes(`meta:issue:${issueNumber}`) ||
                matchesIssueReference(pr.body, issueNumber) ||
                matchesIssueReference(pr.title, issueNumber)
              )
            );

            if (!linkedPr) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot**: Issue closed but couldn't find linked merged PR.

            Adding \`verify:evaluate\` label to issue for tracking.`
              });

              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['verify:evaluate']
              });
              return;
            }

            core.info(`Found merged PR #${linkedPr.number} for issue #${issueNumber}`);

            const verifyMsg = [
              `ðŸ¤– **Auto-pilot**: Issue closed.`,
              `Triggering verification on PR #${linkedPr.number}...`,
              '',
              'Adding `verify:evaluate` label to PR.'
            ].join('\n');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: verifyMsg
            });

            // Add verify label to the merged PR (this triggers agents-verifier.yml)
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: linkedPr.number,
              labels: ['verify:evaluate']
            });

            // Also add to issue for tracking
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: ['verify:evaluate']
            });

      - name: Metrics - End verify timer
        if: always() && steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record verify step
        if: always() && steps.next.outputs.next_step == 'verify'
        env:
          AUTOPILOT_STEP_NAME: verify
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.verify_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "verify" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start create-pr timer
        if: steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Create PR
        if: steps.next.outputs.next_step == 'create-pr'
        id: create_pr_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          ISSUE_TITLE: ${{ steps.context.outputs.issue_title }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          MAX_STALL_RETRIES: '5'
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const issueTitle = process.env.ISSUE_TITLE || `Issue #${issueNumber}`;
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;
            const branchName = `codex/issue-${issueNumber}`;
            const maxStallRetries = parseInt(process.env.MAX_STALL_RETRIES || '5');

            // Helper: count consecutive "waiting" comments (stall detection)
            async function countConsecutiveWaits(waitText) {
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              });

              // Look at comments in reverse order (newest first)
              const reversed = [...comments].reverse();
              let stallCount = 0;

              for (const comment of reversed) {
                const body = comment.body || '';
                const isStallComment = body.includes('Auto-pilot step') &&
                  body.includes(waitText);
                if (isStallComment) {
                  stallCount++;
                } else if (body.includes('Auto-pilot step')) {
                  // Different auto-pilot step - stop counting
                  break;
                }
              }
              return stallCount;
            }

            // Check if branch exists
            let branchExists = false;
            try {
              await github.rest.repos.getBranch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                branch: branchName
              });
              branchExists = true;
              core.info(`Branch ${branchName} exists`);
            } catch (e) {
              if (e.status === 404) {
                core.info(`Branch ${branchName} does not exist yet`);
              } else {
                throw e;
              }
            }

            if (!branchExists) {
              // Branch not created yet - agent still working
              const stallCount = await countConsecutiveWaits('Waiting for agent to create branch');
              core.info(`Consecutive branch-wait count: ${stallCount}/${maxStallRetries}`);

              if (stallCount >= maxStallRetries) {
                const warnMsg = `Stall: ${stallCount} attempts without branch creation`;
                core.warning(warnMsg);

                await github.rest.issues.addLabels({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  labels: ['agents:auto-pilot-pause', 'needs-human']
                });

                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                    body: `## âš ï¸ Auto-Pilot Stalled

                    **Reason:** Branch was not created after ${stallCount} attempts.

                    Expected branch: \`${branchName}\`

                    **Possible causes:**
                    - Agent failed before branch creation
                    - Workflow dispatch failed silently
                    - Permissions or token issues

                    **To resume:** Remove \`agents:auto-pilot-pause\` and
                    \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
                });

                const failMsg = `Auto-pilot stalled: ${stallCount} branch creation attempts`;
                core.setFailed(failMsg);
                return;
              }

              // EXPONENTIAL BACKOFF: Wait longer between each retry
              // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
              if (stallCount > 0) {
                const backoffMinutes = Math.pow(2, stallCount);
                const backoffMs = backoffMinutes * 60 * 1000;
                const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
                const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
                const actualMinutes = Math.round(actualBackoffMs / 60000);

                core.info(`Applying branch-creation backoff: waiting ${actualMinutes} minutes`);
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                    body: `ðŸ¤– **Auto-pilot**: Backoff delay (${actualMinutes}m)

                    Branch not created yet. Attempt ${stallCount + 1}/${maxStallRetries}.
                    Waiting before retry...`
                });

                // Sleep with exponential backoff
                await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
              }

              const backoffNote = stallCount === 0
                ? ' (no backoff on the first check).'
                : '.';

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Waiting for agent to create branch...

            The agent has been assigned but hasn't created the branch yet.
            Branch expected: \`${branchName}\`

            ðŸ“Š Branch check attempt: ${stallCount + 1}/${maxStallRetries}

            â³ Auto-pilot will check again on next trigger${backoffNote}`
              });
              return;
            }

            const { data: repoInfo } = await github.rest.repos.get({
              owner: context.repo.owner,
              repo: context.repo.repo
            });
            const baseBranch = repoInfo.default_branch;
            if (!baseBranch) {
              core.setFailed('Repository default branch not available');
              return;
            }

            // If a PR already exists for this branch, stop create-pr loop
            try {
              const headRef = `${context.repo.owner}:${branchName}`;
              const { data: existingPrs } = await github.rest.pulls.list({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                head: headRef,
                per_page: 1
              });

              if (existingPrs.length > 0) {
                const pr = existingPrs[0];
                const serverUrl = process.env.GITHUB_SERVER_URL
                  || 'https://github.com';
                const { owner, repo } = context.repo;
                const prUrl = `${serverUrl}/${owner}/${repo}/pull/${pr.number}`;

                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ðŸ¤– **Auto-pilot step ${stepCount}**: PR already exists

            âœ… Found **[PR #${pr.number}](${prUrl})** for branch \`${branchName}\`.

            Auto-pilot will stop creating/dispatching work for this issue. If you want to restart,
            remove and re-add the \`agents:auto-pilot\` label.`
                });

                try {
                  await github.rest.issues.removeLabel({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    name: 'agents:auto-pilot'
                  });
                } catch (labelError) {
                  core.warning(`Could not remove agents:auto-pilot label: ${labelError?.message}`);
                }

                core.setOutput('stop_autopilot', 'true');
                return;
              }
            } catch (prLookupError) {
              core.warning(`Could not check for existing PRs: ${prLookupError?.message}`);
            }

            // If branch has no commits ahead of base, dispatch the belt worker
            try {
              const { data: comparison } = await github.rest.repos.compareCommits({
                owner: context.repo.owner,
                repo: context.repo.repo,
                base: baseBranch,
                head: branchName
              });

              if ((comparison.ahead_by || 0) === 0) {
                core.info(`Branch ${branchName} has no commits ahead of ${baseBranch}`);

                // STALL DETECTION: Check how many consecutive "waiting for commits" we've had
                const stallCount = await countConsecutiveWaits('Branch ready, waiting for commits');
                core.info(`Consecutive stall count: ${stallCount}/${maxStallRetries}`);

                if (stallCount >= maxStallRetries) {
                  // Worker failed to produce commits - pause for human review
                  const warnMsg = `Stall: ${stallCount} attempts without commits`;
                  core.warning(warnMsg);

                  await github.rest.issues.addLabels({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    labels: ['agents:auto-pilot-pause', 'needs-human']
                  });

                  await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    body: `## âš ï¸ Auto-Pilot Stalled

            **Reason:** Codex belt worker failed to generate commits after ${stallCount} attempts.

            Branch \`${branchName}\` exists but the agent has not produced any changes.

            **Possible causes:**
            - Issue requirements are unclear or too complex
            - Agent encountered an error during execution
            - Belt worker workflow failed silently

            **To investigate:**
            1. Check recent workflow runs for \`agents-72-codex-belt-worker\` failures
            2. Review the issue requirements for clarity
            3. Check the Codex session logs if available

            **To resume:** Remove \`agents:auto-pilot-pause\` and \`needs-human\` labels,
            then re-add \`agents:auto-pilot\`.`
                  });

                  const failMsg = `Auto-pilot stalled: ${stallCount} failed dispatches`;
                  core.setFailed(failMsg);
                  return;
                }

                // EXPONENTIAL BACKOFF: Wait longer between each retry
                // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
                if (stallCount > 0) {
                  const backoffMinutes = Math.pow(2, stallCount);
                  const backoffMs = backoffMinutes * 60 * 1000;
                  const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
                  const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
                  const actualMinutes = Math.round(actualBackoffMs / 60000);

                  core.info(`Applying backoff: waiting ${actualMinutes} minutes`);
                  await github.rest.issues.createComment({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber,
                    body: `ðŸ¤– **Auto-pilot**: Backoff delay (${actualMinutes}m)

            Attempt ${stallCount + 1}/${maxStallRetries}. Waiting before retry...`
                  });

                  // Sleep with exponential backoff
                  await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
                }

                let workerDispatched = false;
                let dispatchError = null;
                try {
                  await github.rest.actions.createWorkflowDispatch({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: 'agents-72-codex-belt-worker-dispatch.yml',
                    ref: baseBranch,
                    inputs: {
                      issue: issueNumber.toString(),
                      branch: branchName,
                      base: baseBranch,
                      source: 'auto-pilot'
                    }
                  });
                  workerDispatched = true;
                  core.info(`Dispatched codex belt worker for issue #${issueNumber}`);
                } catch (err) {
                  dispatchError = err;
                  core.warning(`Could not dispatch codex belt worker: ${err?.message}`);
                }

                // Build detailed status message
                let dispatchLine;
                if (workerDispatched) {
                  const stallMsg = `${stallCount + 1}/${maxStallRetries}`;
                  dispatchLine = [
                    'âœ… Dispatched the Codex belt worker to generate changes.',
                    '',
                    `ðŸ“Š Stall count: ${stallMsg} (pauses after ${maxStallRetries})`
                  ].join('\n');
                } else {
                  const errorDetail = dispatchError?.message || 'Unknown error';
                  const errorStatus = dispatchError?.status
                    ? ` (HTTP ${dispatchError.status})` : '';
                  dispatchLine = [
                    `âŒ **Failed to dispatch Codex belt worker**${errorStatus}`,
                    '',
                    `Error: \`${errorDetail}\``,
                    '',
                    '**Troubleshooting:**',
                    '- Check if `agents-72-codex-belt-worker-dispatch.yml` exists',
                    '- Verify workflow permissions allow `actions: write`',
                    '- Check workflow runs in the Actions tab for errors'
                  ].join('\n');
                }

                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Branch ready, waiting for commits

            Branch \`${branchName}\` exists but has no commits yet.
            ${dispatchLine}

            â³ Auto-pilot will check again on next trigger.`
                });
                return;
              }
            } catch (compareError) {
              const message = compareError?.message || String(compareError);
              core.warning(`Could not compare ${branchName} to ${baseBranch}: ${message}`);
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Compare failed

            Could not compare \`${branchName}\` to \`${baseBranch}\`.
            Skipping PR creation for now. Auto-pilot will retry on the next trigger.`
              });
              return;
            }

            // Branch has commits - create PR
            core.info(`Creating PR from ${branchName}`);

            // Fetch issue body to include in PR
            const { data: issue } = await github.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber
            });

            const prTitle = `[Auto-pilot] ${issueTitle}`;
            const prBody = [
              `<!-- meta:issue:${issueNumber} -->`,
              '',
              `Closes #${issueNumber}`,
              '',
              issue.body || ''
            ].join('\n');

            try {
              const { data: pr } = await github.rest.pulls.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: prTitle,
                head: branchName,
                base: baseBranch,
                body: prBody
              });

              core.info(`Created PR #${pr.number}`);

              // Add standard agent labels to the PR (separate try-catch to not fail PR creation)
              let labelsAdded = false;
              try {
                await github.rest.issues.addLabels({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: pr.number,
                  labels: ['agent:codex', 'agents:keepalive', 'autofix']
                });
                labelsAdded = true;
                core.info(`Added agent labels to PR #${pr.number}`);
              } catch (labelError) {
                const errMsg = labelError?.message || String(labelError);
                core.warning(`Failed to add labels to PR #${pr.number}: ${errMsg}`);
              }

              const labelStatus = labelsAdded
                ? 'âœ… Added labels: `agent:codex`, `agents:keepalive`, `autofix`'
                : 'âš ï¸ Could not add labels (add manually)';

              // Dispatch PR meta workflow to build Automated Status Summary
              // (GITHUB_TOKEN actions do not trigger workflow runs automatically)
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'agents-pr-meta-v4.yml',
                  ref: baseBranch,
                  inputs: {
                    pr_number: pr.number.toString(),
                    debug: 'false'
                  }
                });
                core.info(`Dispatched PR meta update for PR #${pr.number}`);
              } catch (dispatchError) {
                core.warning(`Could not dispatch PR meta update: ${dispatchError?.message}`);
              }

              // Dispatch keepalive workflow since GITHUB_TOKEN labels don't trigger it
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'agents-keepalive-loop.yml',
                  ref: baseBranch,
                  inputs: {
                    pr_number: pr.number.toString(),
                    force_retry: 'true'
                  }
                });
                core.info(`Dispatched keepalive for PR #${pr.number}`);
              } catch (dispatchError) {
                core.warning(`Could not dispatch keepalive: ${dispatchError?.message}`);
              }

              // Add PR link comment to the issue with full URL for visibility
              // Use GITHUB_SERVER_URL for GHES/AE compatibility instead of hardcoding github.com
              const serverUrl = process.env.GITHUB_SERVER_URL || 'https://github.com';
              const { owner, repo } = context.repo;
              const prUrl = `${serverUrl}/${owner}/${repo}/pull/${pr.number}`;
              const branchUrl = `${serverUrl}/${owner}/${repo}/tree/${branchName}`;

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot step ${stepCount}**: PR created!

            âœ… Created **[PR #${pr.number}](${prUrl})** from branch [\`${branchName}\`](${branchUrl})
            ${labelStatus}

            ðŸ”— **Links:**
            - Pull Request: ${prUrl}
            - Branch: ${branchUrl}

            The PR will now go through CI checks. Auto-pilot will continue monitoring.`
              });

            } catch (e) {
              if (e.status === 422 && e.message?.includes('already exists')) {
                core.info('PR already exists - this is fine');
              } else {
                // PR creation failed - report but don't fail workflow
                core.warning(`Failed to create PR: ${e.message}`);
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issueNumber,
                  body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Could not create PR

            âš ï¸ Branch \`${branchName}\` exists but PR creation failed.

            Error: ${e.message}

            Please create the PR manually or check permissions.`
                });
              }
            }

      - name: Metrics - End create-pr timer
        if: always() && steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record create-pr step
        if: always() && steps.next.outputs.next_step == 'create-pr'
        env:
          AUTOPILOT_STEP_NAME: create-pr
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.create_pr_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "create-pr" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start monitor-pr timer
        if: steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Report - Monitoring PR
        if: steps.next.outputs.next_step == 'monitor-pr'
        id: monitor_pr_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
          MAX_STALL_RETRIES: '5'
        with:
          script: |
            const prNumber = '${{ steps.context.outputs.linked_pr }}';
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;
            const maxStallRetries = parseInt(process.env.MAX_STALL_RETRIES || '5');

            // Helper: count consecutive "monitor-pr" comments (stall detection)
            async function countConsecutiveWaits(waitText) {
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                per_page: 100
              });

              // Look at comments in reverse order (newest first)
              const reversed = [...comments].reverse();
              let stallCount = 0;

              for (const comment of reversed) {
                const body = comment.body || '';
                const isStallComment = body.includes('Auto-pilot step') &&
                  body.includes(waitText);
                if (isStallComment) {
                  stallCount++;
                } else if (body.includes('Auto-pilot step')) {
                  // Different auto-pilot step - stop counting
                  break;
                }
              }
              return stallCount;
            }

            const stallCount = await countConsecutiveWaits('Monitoring PR status');
            core.info(`Consecutive monitor-pr count: ${stallCount}/${maxStallRetries}`);

            if (stallCount >= maxStallRetries) {
              const warnMsg = `Stall: ${stallCount} monitor-pr attempts without completion`;
              core.warning(warnMsg);

              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                labels: ['agents:auto-pilot-pause', 'needs-human']
              });

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `## âš ï¸ Auto-Pilot Stalled

            **Reason:** PR monitoring exceeded ${stallCount} attempts without completion.

            PR #${prNumber} exists but auto-pilot did not reach a completion state.

            **To resume:** Remove \`agents:auto-pilot-pause\` and
            \`needs-human\` labels, then re-add \`agents:auto-pilot\`.`
              });

              core.setOutput('stop_autopilot', 'true');
              core.setFailed(warnMsg);
              return;
            }

            // EXPONENTIAL BACKOFF: Wait longer between each retry
            // Delays: 1min, 2min, 4min, 8min, 16min (2^stallCount minutes)
            if (stallCount > 0) {
              const backoffMinutes = Math.pow(2, stallCount);
              const backoffMs = backoffMinutes * 60 * 1000;
              const maxBackoffMs = 16 * 60 * 1000; // Cap at 16 minutes
              const actualBackoffMs = Math.min(backoffMs, maxBackoffMs);
              const actualMinutes = Math.round(actualBackoffMs / 60000);

              core.info(`Applying monitor-pr backoff: waiting ${actualMinutes} minutes`);
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot**: Backoff delay (${actualMinutes}m)

            Monitoring PR status. Attempt ${stallCount + 1}/${maxStallRetries}.
            Waiting before retry...`
              });

              // Sleep with exponential backoff
              await new Promise(resolve => setTimeout(resolve, actualBackoffMs));
            }

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ðŸ¤– **Auto-pilot step ${stepCount}**: Monitoring PR status

            PR #${prNumber} exists. Keepalive and autofix will handle CI.

            ðŸ“Š Stall count: ${stallCount + 1}/${maxStallRetries}

            â³ Auto-pilot will check again on next trigger.`
            });

      - name: Metrics - End monitor-pr timer
        if: always() && steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record monitor-pr step
        if: always() && steps.next.outputs.next_step == 'monitor-pr'
        env:
          AUTOPILOT_STEP_NAME: monitor-pr
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.monitor_pr_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "monitor-pr" \
            --success "$success" \
            --failure-reason "$failure_reason"

      - name: Metrics - Start check-completion timer
        if: steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: timer-start
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event start --format epoch-ms --github-env

      - name: Execute step - Check Completion & Trigger Merge
        if: steps.next.outputs.next_step == 'check-completion'
        id: completion_step
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          PR_NUMBER: ${{ steps.context.outputs.linked_pr }}
          STEP_COUNT: ${{ steps.cycles.outputs.count }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const prNumber = parseInt(process.env.PR_NUMBER);
            const stepCount = parseInt(process.env.STEP_COUNT || '0') + 1;

            // Get PR details to check CI status
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: prNumber
            });

            // Check if PR is mergeable
            if (pr.mergeable !== true) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot step ${stepCount}**: PR completion check

            âš ï¸ PR #${prNumber} is not mergeable or its mergeability is still being computed.

            Auto-pilot cannot proceed with merge. Manual intervention may be required.`
              });
              return;
            }

            // Check CI status
            let checksPass = true;
            try {
              const { data: checks } = await github.rest.checks.listForRef({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: pr.head.sha
              });

              const pendingChecks = checks.check_runs.filter(check =>
                check.status !== 'completed'
              );
              const failedChecks = checks.check_runs.filter(check =>
                check.status === 'completed' && check.conclusion !== 'success' &&
                check.conclusion !== 'neutral' && check.conclusion !== 'skipped'
              );

              if (failedChecks.length > 0 || pendingChecks.length > 0) {
                checksPass = false;
              }
            } catch (e) {
              core.warning(`Could not check CI status: ${e.message}`);
            }

            if (!checksPass) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `ðŸ¤– **Auto-pilot step ${stepCount}**: PR completion check

            âš ï¸ PR #${prNumber} has failing CI checks.

            Auto-pilot will wait for checks to pass before merging.`
              });
              return;
            }

            // All checks pass - add automerge label
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              labels: ['automerge']
            });

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `ðŸ¤– **Auto-pilot step ${stepCount}**: PR ready for merge!

            âœ… All tasks completed
            âœ… CI checks passing
            âœ… No merge conflicts

            Added \`automerge\` label to PR #${prNumber}. The orchestrator will merge it shortly.`
            });

            core.info(`PR #${prNumber} ready for automerge - added label`);

      - name: Metrics - End check-completion timer
        if: always() && steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: timer-end
        run: |
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_step_timer.py" \
           --event end --format epoch-ms --github-env

      - name: Metrics - Record check-completion step
        if: always() && steps.next.outputs.next_step == 'check-completion'
        env:
          AUTOPILOT_STEP_NAME: check-completion
          AUTOPILOT_ERROR_CATEGORY: metrics-collector
          AUTOPILOT_METRICS_LOG_PATH: ${{ env.AUTOPILOT_METRICS_LOG_PATH }}
        run: |
          success="${{ steps.completion_step.outcome == 'success' }}"
          failure_reason="none"
          if [ "$success" != "true" ]; then
            failure_reason="step-failed"
          fi
          python "$WORKFLOWS_SCRIPTS_PATH/scripts/autopilot_metrics_collector.py" \
            --path "$AUTOPILOT_METRICS_LOG_PATH" \
            --metric-type step \
            --issue-number "${{ steps.context.outputs.issue_number }}" \
            --cycle-count "${{ steps.cycles.outputs.count }}" \
            --step-name "check-completion" \
            --success "$success" \
            --failure-reason "$failure_reason"

      # Re-dispatch workflow to continue pipeline after prep steps
      # GitHub prevents recursive triggers on labels added by GITHUB_TOKEN
      - name: Re-dispatch for next step
        if: |
          steps.context.outputs.should_continue == 'true' &&
          steps.cycles.outputs.exceeded != 'true' &&
          steps.create_pr_step.outputs.stop_autopilot != 'true' &&
          steps.monitor_pr_step.outputs.stop_autopilot != 'true' &&
          contains(
            fromJSON('["format","optimize","apply","capability-check","create-pr","monitor-pr"]'),
            steps.next.outputs.next_step
          )
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
          CURRENT_STEP: ${{ steps.next.outputs.next_step }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);
            const currentStep = process.env.CURRENT_STEP;
            const { data: repoInfo } = await github.rest.repos.get({
              owner: context.repo.owner,
              repo: context.repo.repo
            });
            const baseBranch = repoInfo.default_branch;
            if (!baseBranch) {
              core.setFailed('Repository default branch not available');
              return;
            }

            // Determine next step explicitly to avoid label race conditions
            // Don't rely on 'auto' detection which has API cache timing issues
            const nextStepMap = {
              'format': 'optimize',
              'optimize': 'apply',
              'apply': 'capability-check',
              'capability-check': 'auto',  // Let it detect agent/PR state
              'create-pr': 'auto',  // Re-evaluate after branch/PR creation
              'monitor-pr': 'auto'  // Let it check PR completion
            };
            const nextStep = nextStepMap[currentStep] || 'auto';

            // For monitor-pr or create-pr, add delay to avoid tight polling loops
            // Keepalive updates and branch creation can take time; without delay
            // we'd spam Actions with rapid re-dispatches
            if (currentStep === 'monitor-pr' || currentStep === 'create-pr') {
              const waitTime = currentStep === 'monitor-pr' ? 120000 : 60000;
              core.info(`Waiting ${waitTime/1000}s before re-dispatch...`);
              await new Promise(resolve => setTimeout(resolve, waitTime));
            }
            // Other steps dispatch immediately - explicit force_step
            // eliminates label dependency, no wait needed

            core.info(
              `Re-dispatching auto-pilot: issue #${issueNumber}, ` +
              `next_step=${nextStep}`
            );
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'agents-auto-pilot.yml',
              ref: baseBranch,
              inputs: {
                issue_number: issueNumber.toString(),
                force_step: nextStep
              }
            });

            core.info(
              `Re-dispatched for issue #${issueNumber} after ` +
              `${currentStep} step (next: ${nextStep})`
            );

      - name: Report - Done
        if: steps.next.outputs.next_step == 'done'
        uses: actions/github-script@v8
        env:
          ISSUE_NUMBER: ${{ steps.context.outputs.issue_number }}
        with:
          script: |
            const issueNumber = parseInt(process.env.ISSUE_NUMBER);

            // Remove auto-pilot label since we're done
            try {
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                name: 'agents:auto-pilot'
              });
            } catch (e) {
              // Label might already be removed (404) - that's OK
              if (e && e.status === 404) {
                core.info('Auto-pilot label already removed or not found');
              } else {
                core.warning(`Unexpected error removing auto-pilot label: ${e?.message || e}`);
              }
            }

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: `## âœ… Auto-Pilot Complete

            This issue has been fully processed:
            - âœ… Issue formatted and optimized
            - âœ… Agent assigned and PR created
            - âœ… PR merged
            - âœ… Verification triggered

            Thank you for using auto-pilot! ðŸš€`
            });

            core.info('Auto-pilot complete!');
