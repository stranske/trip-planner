name: Agents Keepalive Loop

on:
  workflow_run:
    workflows: ["Gate"]
    types: [completed]
  pull_request:
    types:
      - labeled
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to force retry'
        required: true
        type: string
      force_retry:
        description: 'Force retry even if gate is cancelled/deferred'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  pull-requests: write
  actions: write
  models: read

concurrency:
  group: >-
    keepalive-${{ github.event.workflow_run.pull_requests[0].number ||
      github.event.pull_request.number ||
      github.event.inputs.pr_number ||
      github.run_id }}
  cancel-in-progress: false

jobs:
  evaluate:
    name: Evaluate keepalive loop
    if: vars.USE_CONSOLIDATED_WORKFLOWS != 'true'
    runs-on: ubuntu-latest
    environment: agent-standard
    outputs:
      pr_number: ${{ steps.evaluate.outputs.pr_number }}
      pr_ref: ${{ steps.evaluate.outputs.pr_ref }}
      base_ref: ${{ steps.evaluate.outputs.base_ref }}
      head_sha: ${{ steps.evaluate.outputs.head_sha }}
      action: ${{ steps.evaluate.outputs.action }}
      reason: ${{ steps.evaluate.outputs.reason }}
      gate_conclusion: ${{ steps.evaluate.outputs.gate_conclusion }}
      iteration: ${{ steps.evaluate.outputs.iteration }}
      max_iterations: ${{ steps.evaluate.outputs.max_iterations }}
      failure_threshold: ${{ steps.evaluate.outputs.failure_threshold }}
      tasks_total: ${{ steps.evaluate.outputs.tasks_total }}
      tasks_unchecked: ${{ steps.evaluate.outputs.tasks_unchecked }}
      keepalive_enabled: ${{ steps.evaluate.outputs.keepalive_enabled }}
      autofix_enabled: ${{ steps.evaluate.outputs.autofix_enabled }}
      has_agent_label: ${{ steps.evaluate.outputs.has_agent_label }}
      has_high_privilege: ${{ steps.evaluate.outputs.has_high_privilege }}
      agent_type: ${{ steps.evaluate.outputs.agent_type }}
      # task_appendix is delivered via artifact upload (keepalive-task-appendix-<pr>)
      # to avoid GitHub's secret scanner censoring the job output.
      trace: ${{ steps.evaluate.outputs.trace }}
      prompt_mode: ${{ steps.evaluate.outputs.prompt_mode }}
      prompt_file: ${{ steps.evaluate.outputs.prompt_file }}
      start_ts: ${{ steps.timestamps.outputs.start_ts }}
      security_blocked: ${{ steps.security_gate.outputs.blocked }}
      security_reason: ${{ steps.security_gate.outputs.reason }}
      rate_limit_remaining: ${{ steps.evaluate.outputs.rate_limit_remaining }}
      rate_limit_recommendation: ${{ steps.evaluate.outputs.rate_limit_recommendation }}
      rounds_without_task_completion: ${{ steps.evaluate.outputs.rounds_without_task_completion }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: 20

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}




      - name: Handle agent:retry label
        id: retry_label
        if: >-
          github.event_name == 'pull_request' &&
          github.event.action == 'labeled' &&
          github.event.label.name == 'agent:retry'
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { github: retryGithub, withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'keepalive-loop',
              capabilities: ['issues:write'],
            });
            const prNumber = context.payload.pull_request.number;
            core.info(`agent:retry label detected on PR #${prNumber} - cleaning up labels`);

            // Remove agent:retry label (so it can be used again later)
            try {
              await withRetry((client) =>
                client.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: prNumber,
                  name: 'agent:retry',
                })
              );
              core.info('Removed agent:retry label');
            } catch (error) {
              if (error.message.includes('rate limit') || error.status === 403) {
                core.warning(
                  `âš ï¸ Rate limited - could not remove agent:retry label: ` +
                    `${error.message}`
                );
              } else if (!error.message.includes('Label does not exist')) {
                core.warning(`Could not remove agent:retry: ${error.message}`);
              }
            }

            // Remove agent:rate-limited label if present
            try {
              await withRetry((client) =>
                client.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: prNumber,
                  name: 'agent:rate-limited',
                })
              );
              core.info('Removed agent:rate-limited label');
            } catch (error) {
              if (error.message.includes('rate limit') || error.status === 403) {
                core.warning(
                  `âš ï¸ Rate limited - could not remove agent:rate-limited label: ` +
                    `${error.message}`
                );
              } else if (!error.message.includes('Label does not exist')) {
                // Only warn if it's not just "label doesn't exist"
                core.warning(`Could not remove agent:rate-limited: ${error.message}`);
              }
            }

            core.info('Label cleanup complete - proceeding with keepalive evaluation');
            core.setOutput('force_retry', 'true');

      - name: Capture timestamps
        id: timestamps
        run: echo "start_ts=$(date -u +%s)" >> "$GITHUB_OUTPUT"
      - name: Security gate - prompt injection guard
        id: security_gate
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { github: retryGithub, withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'keepalive-loop',
              capabilities: ['pull-requests:read'],
            });
            const { evaluatePromptInjectionGuard } = require(
              './.github/scripts/prompt_injection_guard.js'
            );

            // Resolve PR from event context
            const payload = context.payload || {};
            let prNumber = 0;
            let pr = null;

            if (context.eventName === 'pull_request' && payload.pull_request) {
              prNumber = payload.pull_request.number;
              pr = payload.pull_request;
            } else if (context.eventName === 'workflow_run' && payload.workflow_run) {
              const prs = payload.workflow_run.pull_requests || [];
              if (prs[0]?.number) {
                prNumber = prs[0].number;
                const { data } = await withRetry((client) =>
                  client.rest.pulls.get({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    pull_number: prNumber,
                  })
                );
                pr = data;
              }
            }

            if (!pr) {
              core.setOutput('blocked', 'false');
              core.setOutput('reason', 'no-pr-context');
              return;
            }

            const result = await evaluatePromptInjectionGuard({
              github,
              context,
              pr,
              actor: context.actor,
              promptContent: pr.body || '',
              core,
            });

            core.setOutput('blocked', String(result.blocked));
            core.setOutput('reason', result.reason);

            if (result.blocked) {
              core.setFailed(`Security gate blocked: ${result.reason}`);
            }

      - name: Evaluate keepalive state
        id: evaluate
        uses: actions/github-script@v8
        env:
          INPUT_PR_NUMBER: ${{ github.event.inputs.pr_number || '' }}
          INPUT_FORCE_RETRY: >-
            ${{ steps.retry_label.outputs.force_retry ||
                (github.event_name == 'pull_request' &&
                 github.event.action == 'labeled' &&
                 github.event.label.name == 'agent:retry') ||
                github.event.inputs.force_retry ||
                'false' }}
          HAS_CODEX_AUTH: ${{ secrets.CODEX_AUTH_JSON != '' }}
          HAS_CLAUDE_AUTH: ${{ secrets.CLAUDE_AUTH_JSON != '' }}
          HAS_CLAUDE_OAUTH: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN != '' }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { evaluateKeepaliveLoop } = require('./.github/scripts/keepalive_loop.js');
            const options = { github, context, core };
            // Pass workflow_dispatch inputs if present
            const inputPrNumber = process.env.INPUT_PR_NUMBER;
            let forceRetry = process.env.INPUT_FORCE_RETRY === 'true';
            if (inputPrNumber) {
              options.overridePrNumber = parseInt(inputPrNumber, 10);
            }
            // Check if agent:retry label exists on PR (works for all event types)
            // Use token-aware retry to avoid rate limit failures on GITHUB_TOKEN
            if (!forceRetry) {
              const { owner, repo } = context.repo;
              // Resolve PR number from override, workflow_run, or pull_request event
              const prNumberForLabelCheck =
                options.overridePrNumber ||
                (context.payload?.workflow_run?.pull_requests?.[0]?.number) ||
                (context.payload?.pull_request?.number);
              if (prNumberForLabelCheck) {
                try {
                  const retryMod = require(
                    './.github/scripts/github-api-with-retry.js'
                  );
                  const { withRetry } = await retryMod.createTokenAwareRetry({
                    github,
                    core,
                    env: process.env,
                    task: 'keepalive-label-check',
                    capabilities: ['issues:read'],
                  });
                  const labelsResponse = await withRetry((client) =>
                    client.rest.issues.listLabelsOnIssue({
                      owner,
                      repo,
                      issue_number: prNumberForLabelCheck,
                    })
                  );
                  const hasRetryLabel = Array.isArray(labelsResponse.data) &&
                    labelsResponse.data.some(label => label.name === 'agent:retry');
                  if (hasRetryLabel) {
                    forceRetry = true;
                    core.info(
                      `agent:retry label found on PR #${prNumberForLabelCheck} - ` +
                      `enabling force retry`
                    );
                  }
                } catch (error) {
                  core.warning(
                    `Could not check labels for PR #${prNumberForLabelCheck}: ` +
                    `${error.message}`
                  );
                }
              }
            }
            if (forceRetry) {
              options.forceRetry = true;
            }
            const result = await evaluateKeepaliveLoop(options);
            const output = {
              pr_number: String(result.prNumber || ''),
              pr_ref: String(result.prRef || ''),
              base_ref: String(result.baseRef || ''),
              head_sha: String(result.headSha || ''),
              action: result.action || '',
              reason: result.reason || '',
              gate_conclusion: result.gateConclusion || '',
              iteration: String(result.iteration ?? ''),
              max_iterations: String(result.maxIterations ?? ''),
              failure_threshold: String(result.failureThreshold ?? ''),
              tasks_total: String(result.checkboxCounts?.total ?? ''),
              tasks_unchecked: String(result.checkboxCounts?.unchecked ?? ''),
              keepalive_enabled: String(result.keepaliveEnabled ?? ''),
              autofix_enabled: String(result.config?.autofix_enabled ?? ''),
              has_agent_label: String(result.hasAgentLabel ?? ''),
              has_high_privilege: String(result.hasHighPrivilege ?? 'false'),
              agent_type: String(result.agentType || ''),
              trace: String(result.config?.trace || result.state?.trace || ''),
              prompt_mode: String(result.promptMode || 'normal'),
                prompt_file: String(
                  result.promptFile || '.github/codex/prompts/keepalive_next_task.md'
                ),
              // Rate limit status
              rate_limit_remaining: String(result.rateLimitStatus?.totalRemaining ?? ''),
              rate_limit_recommendation: String(result.rateLimitStatus?.recommendation ?? ''),
              // Progress review tracking
              rounds_without_task_completion: String(result.roundsWithoutTaskCompletion ?? '0'),
            };
            for (const [key, value] of Object.entries(output)) {
              core.setOutput(key, value);
            }

            // Task appendix: Write directly to file to avoid GitHub's secret scanner
            // blocking job outputs (which happens with long/repetitive content).
            // Writing to the artifact file here (before setting the task_appendix output
            // via core.setOutput below) ensures the content reaches the artifact even if
            // that output value gets censored.
            const fs = require('fs');
            const path = require('path');
            const artifactsDir = '/tmp/keepalive-artifacts';
            const appendixPath = path.join(artifactsDir, 'task-appendix.txt');

            // Ensure artifacts directory exists
            fs.mkdirSync(artifactsDir, { recursive: true });

            // Write the task appendix directly to the artifact file
            if (result.taskAppendix && result.taskAppendix.length > 0) {
              const opts = { encoding: 'utf8' };
              fs.writeFileSync(appendixPath, result.taskAppendix + '\n', opts);
              const len = result.taskAppendix.length;
              core.info(`Task appendix written to file (${len} chars)`);
            } else {
              // Create an empty file if there is no appendix content
              fs.closeSync(fs.openSync(appendixPath, 'w'));
              core.info('Empty task appendix file created');
            }

            // task_appendix is delivered exclusively via the artifact upload.
            // Do NOT call core.setOutput('task_appendix', ...) here â€” the
            // secret scanner warning fires at the step-output level, not just
            // the job-output level, so even a step output would re-introduce
            // the "Skip output since it may contain secret" noise.

      - name: Verify task appendix artifact
        if: >
          steps.evaluate.outputs.action == 'run' ||
          steps.evaluate.outputs.action == 'fix' ||
          steps.evaluate.outputs.action == 'conflict'
        run: |
          if [ ! -f /tmp/keepalive-artifacts/task-appendix.txt ]; then
            echo "ERROR: Task appendix file not created by evaluate step"
            exit 1
          fi
          echo "Task appendix ready ($(wc -c < /tmp/keepalive-artifacts/task-appendix.txt) bytes)"

      - name: Upload task appendix artifact
        if: >
          steps.evaluate.outputs.action == 'run' ||
          steps.evaluate.outputs.action == 'fix' ||
          steps.evaluate.outputs.action == 'conflict'
        uses: actions/upload-artifact@v6
        with:
          name: keepalive-task-appendix-${{ steps.evaluate.outputs.pr_number }}
          path: /tmp/keepalive-artifacts/task-appendix.txt
          retention-days: 1

  preflight:
    name: Verify secrets available
    needs: evaluate
    if: |
      needs.evaluate.outputs.action == 'run' ||
      needs.evaluate.outputs.action == 'fix' ||
      needs.evaluate.outputs.action == 'conflict'
    runs-on: ubuntu-latest
    environment: >-
      ${{
        needs.evaluate.outputs.has_high_privilege == 'true' &&
        'agent-high-privilege' ||
        'agent-standard'
      }}
    outputs:
      secrets_ok: ${{ steps.check.outputs.secrets_ok }}
    steps:
      - name: Check secrets
        id: check
        env:
          HAS_CODEX_AUTH: ${{ secrets.CODEX_AUTH_JSON != '' }}
          HAS_CLAUDE_AUTH: ${{ secrets.CLAUDE_AUTH_JSON != '' }}
          HAS_CLAUDE_OAUTH: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN != '' }}
          AGENT_TYPE: ${{ needs.evaluate.outputs.agent_type || 'codex' }}
          HAS_APP_ID: >-
            ${{ secrets.KEEPALIVE_APP_ID != '' ||
                secrets.WORKFLOWS_APP_ID != '' }}
          HAS_APP_KEY: >-
            ${{ secrets.KEEPALIVE_APP_PRIVATE_KEY != '' ||
                secrets.WORKFLOWS_APP_PRIVATE_KEY != '' }}
        run: |
          echo "Requested agent: $AGENT_TYPE"
          echo "CODEX_AUTH_JSON present: $HAS_CODEX_AUTH"
          echo "CLAUDE_AUTH_JSON present: $HAS_CLAUDE_AUTH"
          echo "CLAUDE_CODE_OAUTH_TOKEN present: $HAS_CLAUDE_OAUTH"
          echo "KEEPALIVE_APP or WORKFLOWS_APP present: $HAS_APP_ID"
          echo "WORKFLOWS_APP_PRIVATE_KEY present: $HAS_APP_KEY"
          agent_auth_ok=false
          case "$AGENT_TYPE" in
            claude)
              if [ "$HAS_CLAUDE_AUTH" = "true" ] || [ "$HAS_CLAUDE_OAUTH" = "true" ]; then
                agent_auth_ok=true
              fi
              ;;
            codex)
              if [ "$HAS_CODEX_AUTH" = "true" ]; then
                agent_auth_ok=true
              fi
              ;;
            *)
              if [ "$HAS_CODEX_AUTH" = "true" ] || [ "$HAS_CLAUDE_AUTH" = "true" ] || [ "$HAS_CLAUDE_OAUTH" = "true" ]; then
                agent_auth_ok=true
              fi
              ;;
          esac
          if [ "$agent_auth_ok" != "true" ] && [ "$HAS_APP_ID" = "true" ]; then
            agent_auth_ok=true
          fi
          if [ "$agent_auth_ok" != "true" ]; then
            case "$AGENT_TYPE" in
              claude)
                missing_msg="Missing credentials for agent 'claude'. Set CLAUDE_CODE_OAUTH_TOKEN (preferred), CLAUDE_AUTH_JSON, or configure KEEPALIVE/WORKFLOWS_APP credentials."
                ;;
              codex)
                missing_msg="Missing credentials for agent 'codex'. Set CODEX_AUTH_JSON, or configure KEEPALIVE/WORKFLOWS_APP credentials."
                ;;
              *)
                missing_msg="Missing credentials for agent '${AGENT_TYPE}'. Configure that agent's credentials or KEEPALIVE/WORKFLOWS_APP credentials."
                ;;
            esac
            echo "::error::$missing_msg"
            echo "secrets_ok=false" >> "$GITHUB_OUTPUT"
            exit 1
          fi
          echo "secrets_ok=true" >> "$GITHUB_OUTPUT"

  test-job:
    name: Test job creation
    needs: evaluate
    runs-on: ubuntu-latest
    steps:
      - run: |
          echo "Test job ran!"
          echo "Action was ${{ needs.evaluate.outputs.action }}"
          echo "Agent was ${{ needs.evaluate.outputs.agent_type }}"

  # Mark agent as running before starting the actual work
  # This provides real-time visibility that the agent is actively engaged
  mark-running:
    name: Mark agent running
    needs:
      - evaluate
      - preflight
    if: |
      needs.evaluate.outputs.action == 'run' ||
      needs.evaluate.outputs.action == 'fix' ||
      needs.evaluate.outputs.action == 'conflict'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: 20

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}



      - name: Update summary with running status
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { markAgentRunning } = require('./.github/scripts/keepalive_loop.js');
            const runUrl =
              `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}` +
              `/actions/runs/${context.runId}`;
            const inputs = {
              pr_number: '${{ needs.evaluate.outputs.pr_number }}',
              agent_type: '${{ needs.evaluate.outputs.agent_type }}',
              iteration: '${{ needs.evaluate.outputs.iteration }}',
              max_iterations: '${{ needs.evaluate.outputs.max_iterations }}',
              tasks_total: '${{ needs.evaluate.outputs.tasks_total }}',
              tasks_unchecked: '${{ needs.evaluate.outputs.tasks_unchecked }}',
              trace: '${{ needs.evaluate.outputs.trace }}',
              run_url: runUrl,
            };
            await markAgentRunning({ github, context, core, inputs });

  # Route to appropriate agent based on agent:* label
  # Currently supports: agent:codex -> CLI Codex
  # Future: agent:claude, agent:gemini, etc. will have their own jobs
  run-codex:
    name: Keepalive next task (Codex)
    needs:
      - evaluate
      - mark-running
    # Only run for agent:codex label when action is run/fix/conflict
    if: |
      needs.evaluate.outputs.agent_type == 'codex' &&
      (needs.evaluate.outputs.action == 'run' ||
       needs.evaluate.outputs.action == 'fix' ||
       needs.evaluate.outputs.action == 'conflict')
    uses: stranske/Workflows/.github/workflows/reusable-codex-run.yml@main
    secrets: inherit
    with:
      skip: >-
        ${{ needs.evaluate.outputs.action != 'run' &&
            needs.evaluate.outputs.action != 'fix' &&
            needs.evaluate.outputs.action != 'conflict' }}
      prompt_file: ${{ needs.evaluate.outputs.prompt_file }}
      mode: keepalive
      pr_number: ${{ needs.evaluate.outputs.pr_number }}
      pr_ref: ${{ needs.evaluate.outputs.pr_ref }}
      base_ref: ${{ needs.evaluate.outputs.base_ref }}
      # task_appendix delivered via artifact; input left empty to avoid secret scanner
      appendix: ''
      iteration: ${{ needs.evaluate.outputs.iteration }}
      environment: >-
        ${{
          needs.evaluate.outputs.has_high_privilege == 'true' &&
          'agent-high-privilege' ||
          'agent-standard'
        }}

  run-claude:
    name: Keepalive next task (Claude)
    needs:
      - evaluate
      - mark-running
    if: |
      needs.evaluate.outputs.agent_type == 'claude' &&
      (needs.evaluate.outputs.action == 'run' ||
       needs.evaluate.outputs.action == 'fix' ||
       needs.evaluate.outputs.action == 'conflict')
    uses: stranske/Workflows/.github/workflows/reusable-claude-run.yml@main
    secrets: inherit
    with:
      skip: >-
        ${{ needs.evaluate.outputs.action != 'run' &&
            needs.evaluate.outputs.action != 'fix' &&
            needs.evaluate.outputs.action != 'conflict' }}
      prompt_file: ${{ needs.evaluate.outputs.prompt_file }}
      mode: keepalive
      pr_number: ${{ needs.evaluate.outputs.pr_number }}
      pr_ref: ${{ needs.evaluate.outputs.pr_ref }}
      base_ref: ${{ needs.evaluate.outputs.base_ref }}
      appendix: ''
      iteration: ${{ needs.evaluate.outputs.iteration }}
      environment: >-
        ${{
          needs.evaluate.outputs.has_high_privilege == 'true' &&
          'agent-high-privilege' ||
          'agent-standard'
        }}

  # Progress review: LLM-based check when agent is active but not completing tasks
  # This catches "productive but unfocused" patterns where agent works on tangential items
  progress-review:
    name: Review agent progress alignment
    needs: evaluate
    if: needs.evaluate.outputs.action == 'review'
    runs-on: ubuntu-latest
    environment: >-
      ${{
        needs.evaluate.outputs.has_high_privilege == 'true' &&
        'agent-high-privilege' ||
        'agent-standard'
      }}
    outputs:
      recommendation: ${{ steps.review.outputs.recommendation }}
      alignment_score: ${{ steps.review.outputs.alignment_score }}
      feedback: ${{ steps.review.outputs.feedback }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: 20

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}



      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install pydantic langchain-openai langchain-anthropic

      - name: Get recent commits
        id: commits
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = Number('${{ needs.evaluate.outputs.pr_number }}');
            const { createTokenAwareRetry } =
              require('./.github/scripts/github-api-with-retry.js');
            const {
              github: retryGithub,
              withRetry,
              paginateWithRetry,
            } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'keepalive-loop',
              capabilities: ['pull-requests:read'],
            });
            const { data: commits } = await withRetry((client) =>
              client.rest.pulls.listCommits({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                per_page: 30,
              })
            );
            const messages = commits.map(c => c.commit.message.split('\n')[0]);
            const prFiles = await paginateWithRetry(
              retryGithub.rest.pulls.listFiles,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                per_page: 100,
              }
            );
            const files = [...new Set(prFiles.map(file => file.filename))];
            core.setOutput('messages', JSON.stringify(messages));
            core.setOutput('files', JSON.stringify(files.slice(0, 50)));


      - name: Extract acceptance criteria
        id: criteria
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = Number('${{ needs.evaluate.outputs.pr_number }}');
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { github: retryGithub, withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'keepalive-loop',
              capabilities: ['pull-requests:read'],
            });
            const { data: pr } = await withRetry((client) =>
              client.rest.pulls.get({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
              })
            );
            // Extract acceptance criteria from PR body
            const body = pr.body || '';
            const criteria = [];
            const lines = body.split('\n');
            const startIndex = lines.findIndex((line) =>
              /^#{2,6}\s*Acceptance\s+criteria\b/i.test(line.trim())
            );
            if (startIndex !== -1) {
              for (let i = startIndex + 1; i < lines.length; i += 1) {
                const trimmed = lines[i].trim();
                if (/^#{1,6}\s*(\S|$)/.test(trimmed)) {
                  break;
                }
                const match = lines[i].match(/^\s*[-*+]\s*(?:\[[ xX]\]\s*)?(.+)/);
                if (match) {
                  criteria.push(match[1].trim());
                }
              }
            }
            core.setOutput('criteria', JSON.stringify(criteria));

      - name: Run progress review
        id: review
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLAUDE_API_STRANSKE: ${{ secrets.CLAUDE_API_STRANSKE }}
          CRITERIA: ${{ steps.criteria.outputs.criteria }}
          COMMITS: ${{ steps.commits.outputs.messages }}
          FILES: ${{ steps.commits.outputs.files }}
          ROUNDS: ${{ needs.evaluate.outputs.rounds_without_task_completion }}
        run: |
          mapfile -t criteria_array < <(printf '%s\n' "$CRITERIA" | jq -r '.[]')
          mapfile -t commits_array < <(printf '%s\n' "$COMMITS" | jq -r '.[]')
          mapfile -t files_array < <(printf '%s\n' "$FILES" | jq -r '.[]')

          args=("scripts/langchain/progress_reviewer.py")

          for c in "${criteria_array[@]}"; do
            args+=("--acceptance-criteria" "$c")
          done

          for c in "${commits_array[@]}"; do
            args+=("--recent-commits" "$c")
          done

          for f in "${files_array[@]}"; do
            args+=("--files-changed" "$f")
          done

          args+=("--rounds-without-completion" "$ROUNDS" "--json")

          python "${args[@]}" > review_result.json || true

          # Parse results
          if [ -f review_result.json ]; then
            echo "recommendation=$(jq -r '.recommendation // "REDIRECT"' review_result.json)" \
              >> "$GITHUB_OUTPUT"
            echo "alignment_score=$(jq -r '.alignment_score // 5' review_result.json)" \
              >> "$GITHUB_OUTPUT"
            echo "feedback=$(jq -r '.feedback_for_agent // ""' review_result.json)" \
              >> "$GITHUB_OUTPUT"
            echo "summary=$(jq -r '.summary // ""' review_result.json)" >> "$GITHUB_OUTPUT"

            cat review_result.json >> "$GITHUB_STEP_SUMMARY"
          else
            echo "recommendation=REDIRECT" >> "$GITHUB_OUTPUT"
            echo "alignment_score=5" >> "$GITHUB_OUTPUT"
            printf '%s\n' \
              "feedback=Unable to analyze progress. Please review acceptance criteria." \
              >> "$GITHUB_OUTPUT"
          fi


      - name: Evaluate whether to post review
        id: review_guard
        run: |
          node .github/scripts/should-post-review.js review_result.json

      - name: Post review feedback to PR
        if: steps.review_guard.outputs.should_post_review == 'true'
        uses: actions/github-script@v8
        env:
          REVIEW_FEEDBACK: ${{ steps.review.outputs.feedback }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = Number('${{ needs.evaluate.outputs.pr_number }}');
            const recommendation = '${{ steps.review.outputs.recommendation }}';
            const alignmentScore = '${{ steps.review.outputs.alignment_score }}';
            const rounds = '${{ needs.evaluate.outputs.rounds_without_task_completion }}';
            const feedback = process.env.REVIEW_FEEDBACK || '';
            const { createTokenAwareRetry } = require('./.github/scripts/github-api-with-retry.js');
            const { github: retryGithub, withRetry } = await createTokenAwareRetry({
              github,
              core,
              env: process.env,
              task: 'keepalive-loop',
              capabilities: ['issues:write'],
            });

            const emojiMap = {
              'CONTINUE': 'âœ…',
              'REDIRECT': 'âš ï¸',
              'STOP': 'ðŸ›‘'
            };
            const emoji = emojiMap[recommendation] || 'â“';

            const body = [
              `## ${emoji} Progress Review (Round ${rounds})`,
              '',
              `**Recommendation:** ${recommendation}`,
              `**Alignment Score:** ${alignmentScore}/10`,
              '',
              '### Feedback',
              feedback || 'No specific feedback.',
              '',
              '---',
              `_This review was triggered because the agent has been working for ${rounds} ` +
                `rounds without completing any task checkboxes._`,
              '_The review evaluates whether recent work is advancing toward ' +
                'the acceptance criteria._',
            ].join('\n');

            await withRetry((client) =>
              client.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body,
              })
            );

            // If STOP recommended, remove agent label to prevent further runs
            if (recommendation === 'STOP') {
              core.warning('Progress review recommends STOP - agent work appears unaligned');
              const agentType = '${{ needs.evaluate.outputs.agent_type }}';
              if (agentType) {
                const agentLabel = `agent:${agentType}`;
                try {
                  await withRetry((client) =>
                    client.rest.issues.removeLabel({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      issue_number: prNumber,
                      name: agentLabel,
                    })
                  );
                  core.info(`Removed ${agentLabel} label after STOP recommendation`);
                } catch (e) {
                  core.info(`Could not remove ${agentLabel} label: ${e.message}`);
                }
              }
            }

  summary:
    name: Update keepalive summary
    needs:
      - evaluate
      - run-codex
      - run-claude
    # Run if PR exists, handle skipped/failed agent jobs gracefully
    # run-codex will be skipped when action != run/fix/conflict, which is expected
    if: |
      always() &&
      needs.evaluate.outputs.pr_number != '' &&
      needs.evaluate.outputs.pr_number != '0'
    runs-on: ubuntu-latest
    environment: >-
      ${{
        needs.evaluate.outputs.has_high_privilege == 'true' &&
        'agent-high-privilege' ||
        'agent-standard'
      }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup API client
        uses: ./.github/actions/setup-api-client
        with:
          secrets: ${{ toJSON(secrets) }}
          github_token: ${{ github.token }}



      - name: Emit keepalive metrics
        id: keepalive-metrics
        env:
          PR_NUMBER: ${{ needs.evaluate.outputs.pr_number }}
          ACTION: ${{ needs.evaluate.outputs.action }}
          REASON: ${{ needs.evaluate.outputs.reason }}
          GATE_CONCLUSION: ${{ needs.evaluate.outputs.gate_conclusion }}
          ITERATION: ${{ needs.evaluate.outputs.iteration }}
          MAX_ITERATIONS: ${{ needs.evaluate.outputs.max_iterations }}
          TASKS_TOTAL: ${{ needs.evaluate.outputs.tasks_total }}
          TASKS_UNCHECKED: ${{ needs.evaluate.outputs.tasks_unchecked }}
          START_TS: ${{ needs.evaluate.outputs.start_ts }}
        run: |
          set -euo pipefail

          now=$(date -u +%s)
          if [[ "${START_TS:-}" =~ ^[0-9]+$ ]]; then
            duration=$(( now - START_TS ))
            if [ "$duration" -lt 0 ]; then duration=0; fi
          else
            duration=0
          fi

          tasks_total=${TASKS_TOTAL:-0}
          tasks_unchecked=${TASKS_UNCHECKED:-0}
          if ! [[ "$tasks_total" =~ ^-?[0-9]+$ ]]; then tasks_total=0; fi
          if ! [[ "$tasks_unchecked" =~ ^-?[0-9]+$ ]]; then tasks_unchecked=0; fi
          tasks_completed=$(( tasks_total - tasks_unchecked ))
          if [ "$tasks_completed" -lt 0 ]; then tasks_completed=0; fi

          metrics_json=$(jq -n \
            --arg pr "${PR_NUMBER:-0}" \
            --arg iteration "${ITERATION:-0}" \
            --arg action "${ACTION:-}" \
            --arg stop_reason "${REASON:-}" \
            --arg gate_conclusion "${GATE_CONCLUSION:-}" \
            --arg tasks_total "$tasks_total" \
            --arg tasks_completed "$tasks_completed" \
            --arg duration "$duration" \
            '{
              pr_number: ($pr | tonumber? // 0),
              iteration_count: ($iteration | tonumber? // 0),
              action: $action,
              stop_reason: $stop_reason,
              gate_conclusion: $gate_conclusion,
              tasks_total: ($tasks_total | tonumber? // 0),
              tasks_completed: ($tasks_completed | tonumber? // 0),
              duration_seconds: ($duration | tonumber? // 0)
            }')

          {
            echo '### Keepalive metrics'
            echo ''
            echo '| Field | Value |'
            echo '| --- | --- |'
            echo "| pr_number | $(echo "$metrics_json" | jq -r '.pr_number') |"
            echo "| iteration_count | $(echo "$metrics_json" | jq -r '.iteration_count') |"
            echo "| action | $(echo "$metrics_json" | jq -r '.action') |"
            echo "| stop_reason | $(echo "$metrics_json" | jq -r '.stop_reason') |"
            echo "| gate_conclusion | $(echo "$metrics_json" | jq -r '.gate_conclusion') |"
            echo "| tasks_total | $(echo "$metrics_json" | jq -r '.tasks_total') |"
            echo "| tasks_completed | $(echo "$metrics_json" | jq -r '.tasks_completed') |"
            echo "| duration_seconds | $(echo "$metrics_json" | jq -r '.duration_seconds') |"
          } >> "$GITHUB_STEP_SUMMARY"

          echo "$metrics_json" >> keepalive-metrics.ndjson

      - name: Upload keepalive metrics artifact
        uses: actions/upload-artifact@v6
        with:
          name: keepalive-metrics
          path: keepalive-metrics.ndjson
          retention-days: 30
          if-no-files-found: error

      - name: Auto-reconcile task checkboxes
        if: |
          needs.run-codex.outputs.changes-made == 'true' ||
          needs.run-claude.outputs.changes-made == 'true'
        uses: actions/github-script@v8
        env:
          LLM_COMPLETED_TASKS: >-
            ${{
              needs.run-codex.outputs.llm-completed-tasks ||
              needs.run-claude.outputs.llm-completed-tasks ||
              '[]'
            }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { autoReconcileTasks } = require('./.github/scripts/keepalive_loop.js');

            const prNumber = Number('${{ needs.evaluate.outputs.pr_number }}') || 0;
            const beforeSha = '${{ needs.evaluate.outputs.head_sha }}';  // SHA before agent ran
            const headSha =
              '${{ needs.run-codex.outputs.commit-sha }}' ||
              '${{ needs.run-claude.outputs.commit-sha }}';

            // LLM analysis metadata
            const llmProvider =
              '${{ needs.run-codex.outputs.llm-provider }}' ||
              '${{ needs.run-claude.outputs.llm-provider }}' ||
              '';
            const llmConfidence =
              '${{ needs.run-codex.outputs.llm-confidence }}' ||
              '${{ needs.run-claude.outputs.llm-confidence }}' ||
              '';
            const llmAnalysisRun =
              '${{ needs.run-codex.outputs.llm-analysis-run }}' === 'true' ||
              '${{ needs.run-claude.outputs.llm-analysis-run }}' === 'true';

              // Parse LLM completed tasks if available
              // Use env var to avoid JS string escaping issues
            let llmCompletedTasks = [];
            const llmTasksJson = process.env.LLM_COMPLETED_TASKS || '[]';
            try {
              llmCompletedTasks = JSON.parse(llmTasksJson);
              if (llmCompletedTasks.length > 0) {
                core.info(`LLM analysis found ${llmCompletedTasks.length} completed task(s)`);
                if (llmProvider) {
                  core.info(`LLM provider: ${llmProvider} (confidence: ${llmConfidence})`);
                }
              }
            } catch (e) {
              core.debug(`Failed to parse LLM tasks: ${e.message}`);
            }

            if (!prNumber || !beforeSha || !headSha) {
              core.info('Missing required inputs for task reconciliation');
              return;
            }

            core.info(`Auto-reconciling tasks for PR #${prNumber}`);
            core.info(`Comparing ${beforeSha.slice(0, 7)} â†’ ${headSha.slice(0, 7)}`);

            const result = await autoReconcileTasks({
              github, context, prNumber, baseSha: beforeSha, headSha, llmCompletedTasks, core
            });

            if (result.updated) {
              core.info(`âœ… ${result.details}`);
              core.notice(`Auto-checked ${result.tasksChecked} task(s) based on analysis`);
            } else {
              core.info(`â„¹ï¸ ${result.details}`);
            }

            // Output for step summary and downstream reporting
            core.setOutput('tasks_checked', result.tasksChecked);
            core.setOutput('reconciliation_details', result.details);
            core.setOutput('llm_provider', llmProvider);
            core.setOutput('llm_confidence', llmConfidence);
            core.setOutput('llm_analysis_run', llmAnalysisRun);
            core.setOutput('llm_tasks_count', llmCompletedTasks.length);
            core.setOutput('commit_tasks_count', result.sources?.commit || 0);

      - name: Update summary comment
        id: update-summary
        uses: actions/github-script@v8
        env:
          AGENT_SUMMARY: >-
            ${{
              needs.run-codex.outputs.final-message-summary ||
              needs.run-claude.outputs.final-message-summary ||
              needs.run-codex.outputs.error-summary ||
              needs.run-claude.outputs.error-summary ||
              ''
            }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { updateKeepaliveLoopSummary } =
              require('./.github/scripts/keepalive_loop.js');

            const claudeResult = '${{ needs.run-claude.result }}';
            const codexResult = '${{ needs.run-codex.result }}';
            const runResult =
              claudeResult && claudeResult !== 'skipped' ? claudeResult : codexResult;

            const agentExitCode =
              '${{ needs.run-codex.outputs.exit-code }}' ||
              '${{ needs.run-claude.outputs.exit-code }}';
            const agentChangesMade =
              '${{ needs.run-codex.outputs.changes-made }}' ||
              '${{ needs.run-claude.outputs.changes-made }}';
            const agentCommitSha =
              '${{ needs.run-codex.outputs.commit-sha }}' ||
              '${{ needs.run-claude.outputs.commit-sha }}';
            const agentFilesChanged =
              '${{ needs.run-codex.outputs.files-changed }}' ||
              '${{ needs.run-claude.outputs.files-changed }}';

            const llmProvider =
              '${{ needs.run-codex.outputs.llm-provider }}' ||
              '${{ needs.run-claude.outputs.llm-provider }}' ||
              '';
            const llmModel =
              '${{ needs.run-codex.outputs.llm-model }}' ||
              '${{ needs.run-claude.outputs.llm-model }}' ||
              '';
            const llmConfidence =
              '${{ needs.run-codex.outputs.llm-confidence }}' ||
              '${{ needs.run-claude.outputs.llm-confidence }}' ||
              '';
            const llmAnalysisRun =
              '${{ needs.run-codex.outputs.llm-analysis-run }}' === 'true' ||
              '${{ needs.run-claude.outputs.llm-analysis-run }}' === 'true';
            const inputs = {
              pr_number: Number('${{ needs.evaluate.outputs.pr_number }}') || 0,
              action: '${{ needs.evaluate.outputs.action }}',
              reason: '${{ needs.evaluate.outputs.reason }}',
              gate_conclusion: '${{ needs.evaluate.outputs.gate_conclusion }}',
              iteration: Number('${{ needs.evaluate.outputs.iteration }}') || 0,
              max_iterations: Number('${{ needs.evaluate.outputs.max_iterations }}') || 0,
              failure_threshold: Number('${{ needs.evaluate.outputs.failure_threshold }}') || 3,
              rounds_without_task_completion:
                Number('${{ needs.evaluate.outputs.rounds_without_task_completion }}') || 0,
              tasks_total: Number('${{ needs.evaluate.outputs.tasks_total }}') || 0,
              tasks_unchecked: Number('${{ needs.evaluate.outputs.tasks_unchecked }}') || 0,
              keepalive_enabled: '${{ needs.evaluate.outputs.keepalive_enabled }}',
              autofix_enabled: '${{ needs.evaluate.outputs.autofix_enabled }}',
              agent_type: '${{ needs.evaluate.outputs.agent_type }}',
              trace: '${{ needs.evaluate.outputs.trace }}',
              // Agent run result - check which agent ran
              run_result: runResult,
              // Agent output details for visibility
              agent_exit_code: agentExitCode,
              agent_changes_made: agentChangesMade,
              agent_commit_sha: agentCommitSha,
              agent_files_changed: agentFilesChanged,
              agent_summary: process.env.AGENT_SUMMARY || '',
              // LLM analysis details for task completion reporting
              llm_provider: llmProvider,
              llm_model: llmModel,
              llm_confidence: llmConfidence,
              llm_analysis_run: llmAnalysisRun,
            };
            await updateKeepaliveLoopSummary({ github, context, core, inputs });

      # Mint KEEPALIVE_APP token for rate limit notification
      # This has a separate rate limit pool from GITHUB_TOKEN
      - name: Mint KEEPALIVE_APP token
        id: keepalive_app_token
        if: |
          failure() &&
          steps.update-summary.outputs.rate_limit_hit == 'true' &&
          env.KEEPALIVE_APP_ID != '' &&
          env.KEEPALIVE_APP_PRIVATE_KEY != ''
        uses: actions/create-github-app-token@v2
        continue-on-error: true
        env:
          KEEPALIVE_APP_ID: ${{ secrets.KEEPALIVE_APP_ID }}
          KEEPALIVE_APP_PRIVATE_KEY: ${{ secrets.KEEPALIVE_APP_PRIVATE_KEY }}
        with:
          app-id: ${{ secrets.KEEPALIVE_APP_ID }}
          private-key: ${{ secrets.KEEPALIVE_APP_PRIVATE_KEY }}
          owner: ${{ github.repository_owner }}

      # Handle rate limit failures by notifying the PR with KEEPALIVE_APP token
      # This token has a separate rate limit pool (5000/hr) from the exhausted GITHUB_TOKEN
      - name: Notify PR of rate limit failure
        if: |
          failure() &&
          steps.update-summary.outputs.rate_limit_hit == 'true' &&
          steps.keepalive_app_token.outputs.token != ''
        uses: actions/github-script@v8
        with:
          github-token: ${{ steps.keepalive_app_token.outputs.token }}
          script: |
            const {
              postRateLimitNotification
            } = require('./.github/scripts/keepalive_loop.js');

            const prNumber = Number('${{ steps.update-summary.outputs.pr_number }}') || 0;
            const errorMessage = '${{ steps.update-summary.outputs.rate_limit_error }}';
            const resetTime = '${{ steps.update-summary.outputs.rate_limit_reset }}';
            const remaining = Number(
              '${{ steps.update-summary.outputs.rate_limit_remaining }}'
            ) || 0;
            const action =
              '${{ steps.update-summary.outputs.action }}' ||
              '${{ needs.evaluate.outputs.action }}';
            const reason =
              '${{ steps.update-summary.outputs.reason }}' ||
              '${{ needs.evaluate.outputs.reason }}';

            if (!prNumber) {
              core.warning('No PR number available for rate limit notification');
              return;
            }

            core.info(`Attempting to notify PR #${prNumber} about rate limit`);

            const result = await postRateLimitNotification({
              github,
              context,
              core,
              prNumber,
              errorMessage,
              resetTime,
              remaining,
              action,
              reason,
            });

            if (result.skipped) {
              core.info('Rate limit notification skipped (recent notification exists)');
            } else if (result.posted || result.labeled) {
              core.info(
                `Rate limit notification: posted=${result.posted}, labeled=${result.labeled}`
              );
            } else {
              core.warning(`Failed to notify PR: ${result.error}`);
            }
